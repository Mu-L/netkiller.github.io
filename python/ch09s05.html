<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>9.5. GPU</title><link rel="stylesheet" type="text/css" href="docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="index.html" title="Netkiller Python 手札" /><link rel="up" href="ai.html" title="第 9 章 AI 相关" /><link rel="prev" href="ch09s04.html" title="9.4. 向量数据处理" /><link rel="next" href="NumPy/index.html" title="9.6. NumPy" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">9.5. GPU</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ch09s04.html">上一页</a> </td><th width="60%" align="center">第 9 章 AI 相关</th><td width="20%" align="right"> <a accesskey="n" href="NumPy/index.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id3243"></a>9.5. GPU</h2></div></div></div>
	
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1002"></a>9.5.1. 检测显卡</h3></div></div></div>
		
		<pre class="programlisting">
			
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)			
			
		</pre>
		<p>输出结果是 cpu 表示当前环境使用的的是 cpu 而不是 GPU</p>
		<pre class="screen">
		
D:\workspace\netkiller\.venv\Scripts\python.exe D:\workspace\netkiller\test\duda.py 
cpu
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1003"></a>9.5.2. 检测硬件</h3></div></div></div>
		
		<p>使用 nvidia-smi 命令检测显卡，是否支持 CUDA</p>
		<pre class="screen">
		
PS C:\Users\neo&gt; nvidia-smi
Sun Nov 17 12:29:15 2024
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 546.67                 Driver Version: 546.67       CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3050 ...  WDDM  | 00000000:02:00.0 Off |                  N/A |
| N/A   54C    P0               8W /  50W |      0MiB /  6144MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
PS C:\Users\neo&gt;	
		
		</pre>
		<p>这里可以看到当前显卡是支持 CUDA Version: 12.3</p>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1004"></a>9.5.3. 安装CUDA开发包</h3></div></div></div>
		
		<p>下载 cuda 开发包 <a class="ulink" href="https://developer.nvidia.com/" target="_top">https://developer.nvidia.com/</a></p>
		<p>release-notes <a class="ulink" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" target="_top">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html</a></p>
		<p>历史版本 <a class="ulink" href="https://developer.nvidia.com/cuda-toolkit-archive" target="_top">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1005"></a>9.5.4. 检验安装</h3></div></div></div>
		
		<p>检查 CUDA 版本</p>
		<pre class="screen">
		
PS C:\Users\neo&gt; nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Sep_12_02:55:00_Pacific_Daylight_Time_2024
Cuda compilation tools, release 12.6, V12.6.77
Build cuda_12.6.r12.6/compiler.34841621_0
		
		</pre>
		<p>查询设备</p>
		<pre class="screen">
		
PS C:\Users\neo&gt; &amp; 'C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\extras\demo_suite\deviceQuery.exe'
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\extras\demo_suite\deviceQuery.exe Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "NVIDIA GeForce RTX 3050 6GB Laptop GPU"
  CUDA Driver Version / Runtime Version          12.6 / 12.6
  CUDA Capability Major/Minor version number:    8.6
  Total amount of global memory:                 6144 MBytes (6441926656 bytes)
  (20) Multiprocessors, (128) CUDA Cores/MP:     2560 CUDA Cores
  GPU Max Clock rate:                            990 MHz (0.99 GHz)
  Memory Clock rate:                             5501 Mhz
  Memory Bus Width:                              96-bit
  L2 Cache Size:                                 1572864 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               zu bytes
  Total amount of shared memory per block:       zu bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  1536
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          zu bytes
  Texture alignment:                             zu bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)
  Device supports Unified Addressing (UVA):      Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.6, CUDA Runtime Version = 12.6, NumDevs = 1, Device0 = NVIDIA GeForce RTX 3050 6GB Laptop GPU
Result = PASS
PS C:\Users\neo&gt;		
		
		</pre>
		<p>带宽测试</p>
		<pre class="screen">
		
PS C:\Users\neo&gt; &amp; 'C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\extras\demo_suite\bandwidthTest.exe'
[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: NVIDIA GeForce RTX 3050 6GB Laptop GPU
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     5971.0

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     6413.3

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     101343.0

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
PS C:\Users\neo&gt;		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1006"></a>9.5.5. pytorch 安装</h3></div></div></div>
		
		<p>CUDA 开发包安装正确，但是 pytorch 代码 torch.cuda.is_available() 始终返回 False 无法使用 CUDA</p>
		<pre class="programlisting">
		
import torch
print(torch.__version__)
print(torch.cuda.is_available())		
		
		</pre>
		<p>输出结果</p>
		<pre class="screen">
		
D:\workspace\netkiller\.venv\Scripts\python.exe D:\workspace\netkiller\test\duda.py 
2.5.1+cpu
False
		
		</pre>
		<p>问出出在，你安装 pytorch 的时候没有检测到 cuda 系统便默认给你安装 cpu 版本，解决方法是重新安装 cuda 版本的 pytorch</p>
		<p>进入这个页面 https://pytorch.org/get-started/locally/ 选择你 CUDA 版本的 pytorch</p>
		<pre class="screen">
		
(.venv) PS D:\workspace\netkiller&gt; pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
Looking in indexes: https://download.pytorch.org/whl/cu124
Requirement already satisfied: torch in d:\workspace\netkiller\.venv\lib\site-packages (2.5.1)
Requirement already satisfied: torchvision in d:\workspace\netkiller\.venv\lib\site-packages (0.20.1)
Collecting torchaudio
  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-win_amd64.whl (4.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 7.3 MB/s eta 0:00:00
Requirement already satisfied: filelock in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (3.16.1)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (4.12.2)
Requirement already satisfied: networkx in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (3.1.4)
Requirement already satisfied: fsspec in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (2024.10.0)
Requirement already satisfied: setuptools in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (75.3.0)
Requirement already satisfied: sympy==1.13.1 in d:\workspace\netkiller\.venv\lib\site-packages (from torch) (1.13.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in d:\workspace\netkiller\.venv\lib\site-packages (from sympy==1.13.1-&gt;torch) (1.3.0)
Requirement already satisfied: numpy in d:\workspace\netkiller\.venv\lib\site-packages (from torchvision) (2.0.2)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in d:\workspace\netkiller\.venv\lib\site-packages (from torchvision) (11.0.0)
Collecting torch
  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-win_amd64.whl (2510.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 GB 13.6 MB/s eta 0:00:00
Requirement already satisfied: MarkupSafe&gt;=2.0 in d:\workspace\netkiller\.venv\lib\site-packages (from jinja2-&gt;torch) (3.0.2)
Installing collected packages: torch, torchaudio
  Attempting uninstall: torch
    Found existing installation: torch 2.5.1
    Uninstalling torch-2.5.1:
      Successfully uninstalled torch-2.5.1
Successfully installed torch-2.5.1+cu124 torchaudio-2.5.1+cu124
		
		</pre>
		<p>再次验证</p>
		<pre class="programlisting">
		
import torch
print(torch.__version__)
print(torch.cuda.is_available())

D:\workspace\netkiller\.venv\Scripts\python.exe D:\workspace\netkiller\test\duda.py 
2.5.1+cu124
True
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1007"></a>9.5.6. NVIDIA cuDNN</h3></div></div></div>
		
		<p><a class="ulink" href="https://developer.nvidia.cn/cudnn" target="_top">https://developer.nvidia.cn/cudnn</a></p>
		<p>下载解压</p>
		<pre class="screen">
		
将 C:\Users\neo\Downloads\cudnn-windows-x86_64-9.5.1.17_cuda12-archive.zip\cudnn-windows-x86_64-9.5.1.17_cuda12-archive 下面的三个目录，复制到
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6
		
		</pre>
	</div>
</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ch09s04.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="ai.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="NumPy/index.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">9.4. 向量数据处理 </td><td width="20%" align="center"><a accesskey="h" href="index.html">起始页</a></td><td width="40%" align="right" valign="top"> 9.6. NumPy</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>