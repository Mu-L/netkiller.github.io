<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>23.2. 数据输入与输出</title><link rel="stylesheet" type="text/css" href="../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../index.html" title="Netkiller Python 手札" /><link rel="up" href="index.html" title="第 23 章 Pandas - Python Data Analysis Library" /><link rel="prev" href="index.html" title="第 23 章 Pandas - Python Data Analysis Library" /><link rel="next" href="pandas.DataFrame.html" title="23.3. 数据帧(DataFrame)" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">23.2. 数据输入与输出</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="index.html">上一页</a> </td><th width="60%" align="center">第 23 章 Pandas - Python Data Analysis Library</th><td width="20%" align="right"> <a accesskey="n" href="pandas.DataFrame.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id4984"></a>23.2. 数据输入与输出</h2></div></div></div>
		
		<p>我们都知道 Pandas 是做数据分析的，Pandas 在做数据分析之前需要加载数据，加载数据的方法有很多种，数据来源渠道也很多。例如数据可以从 HTML页面中的表格，Excel，JSON，CSV以及关系型数据库等等。</p>
		
<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1286"></a>23.2.1. Pandas 处理 HTML</h3></div></div></div>
	
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1284"></a>23.2.1.1. HTML 表格处理</h4></div></div></div>
		
		<p>工作中，我们常常需要提取HTML网页中的表格数据，多少会用到爬虫技术。</p>
		<p>例如使用 requests 下载网页，然后使用HTML萃取工具，将HTML页面内部table表格中的数据提出去来。这种方法比较复杂，今天介绍的是 Pandas 读取网页中的表格，难度几乎是傻瓜级别的。</p>
		<p>在不使用爬虫的情况下，这种方式是最佳选择。</p>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1275"></a>安装依赖包</h5></div></div></div>
			
			<pre class="screen">
		
pip install lxml		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1276"></a>read_html 参数详解</h5></div></div></div>
			
			<p>read_html() 可以萃取 HTML table 标签中的数据。</p>
			<p>pandas.read_html(io, match='.+', flavor=None, header=None, index_col=None, skiprows=None, attrs=None, parse_dates=False, tupleize_cols=None, thousands=', ', encoding=None, decimal='.', converters=None, na_values=None, keep_default_na=True, displayed_only=True)</p>
			<p>详细参数</p>
			<pre class="screen">
		
io： 		str, path object 或 file-like objectURL，file-like对象或包含HTML的原始字符串。请注意，lxml仅接受http，ftp和文件url协议。如果您的网址以'https'您可以尝试删除's'。
match： 		str 或 compiled regular expression, 可选参数将返回包含与该正则表达式或字符串匹配的文本的表集。除非HTML非常简单，否则您可能需要在此处传递非空字符串。默认为“。+”(匹配任何非空字符串)。默认值将返回页面上包含的所有表。此值转换为正则表达式，以便Beautiful Soup和lxml之间具有一致的行为。
flavor： 	str 或 None要使用的解析引擎。 ‘bs4’和‘html5lib’彼此同义，它们都是为了向后兼容。默认值None尝试使用lxml解析，如果失败，它会重新出现bs4+html5lib。
header： 	int 或 list-like 或 None, 可选参数该行(或MultiIndex)用于创建列标题。
index_col： int 或 list-like 或 None, 可选参数用于创建索引的列(或列列表)。
skiprows： 	int 或 list-like 或 slice 或 None, 可选参数解析列整数后要跳过的行数。从0开始。如果给出整数序列或切片，将跳过该序列索引的行。请注意，单个元素序列的意思是“跳过第n行”，而整数的意思是“跳过n行”。
attrs： 		dict 或 None, 可选参数这是属性的词典，您可以传递该属性以用于标识HTML中的表。在传递给lxml或Beautiful Soup之前，不会检查它们的有效性。但是，这些属性必须是有效的HTML表属性才能正常工作。例如， attrs = {'id': 'table'} 是有效的属性字典，因为‘id’ HTML标记属性是任何HTML标记的有效HTML属性，这个文件。 attrs = {'asdf': 'table'} 不是有效的属性字典，因为‘asdf’即使是有效的XML属性，也不是有效的HTML属性。可以找到有效的HTML 4.01表属性这里。可以找到HTML 5规范的工作草案这里。它包含有关现代Web表属性的最新信息。
parse_dates： bool, 可选参数参考read_csv()更多细节。
thousands： 	str, 可选参数用来解析成千上万个分隔符。默认为','。
encoding： 	str 或 None, 可选参数用于解码网页的编码。默认为NoneNone保留先前的编码行为，这取决于基础解析器库(例如，解析器库将尝试使用文档提供的编码)。
decimal： 	str, 默认为 ‘.’可以识别为小数点的字符(例如，对于欧洲数据，请使用“，”)。
converters： dict, 默认为 None用于在某些列中转换值的函数的字典。键可以是整数或列标签，值是采用一个输入参数，单元格(而非列)内容并返回转换后内容的函数。
na_values： 	iterable, 默认为 None自定义NA值。
keep_default_na： bool, 默认为 True如果指定了na_values并且keep_default_na为False，则默认的NaN值将被覆盖，否则将附加它们。
displayed_only： bool, 默认为 True是否应解析具有“display:none”的元素。
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1277"></a>从文本变量中提取数据</h5></div></div></div>
			
			<pre class="programlisting">
		
import pandas as pd

html = """
&lt;table border="1"&gt;
  &lt;tr&gt;
    &lt;th&gt;Month&lt;/th&gt;
    &lt;th&gt;Savings&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;January&lt;/td&gt;
    &lt;td&gt;$100&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
"""
data = pd.read_html(html)[0]

print(data)
		
			</pre>
			<p>提取多个表格</p>
			<pre class="programlisting">
		
import pandas as pd

html = """
&lt;table border="1"&gt;
  &lt;tr&gt;&lt;th&gt;月份&lt;/th&gt;&lt;th&gt;节约&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;一月&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;table border="1"&gt;
  &lt;tr&gt;&lt;th&gt;月份&lt;/th&gt;&lt;th&gt;节约&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;二月&lt;/td&gt;&lt;td&gt;200&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
"""
dfs = pd.read_html(html)
print("发现HTML表格数量：%s" % len(dfs))
for data in dfs:
    print(data)
		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1278"></a>从文件获取表格数据</h5></div></div></div>
			
			<p>准备 table.html 文件</p>
			<pre class="screen">
		
&lt;table border="1"&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Month&lt;/th&gt;
            &lt;th&gt;Savings&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;

    &lt;tfoot&gt;
        &lt;tr&gt;
            &lt;td&gt;Sum&lt;/td&gt;
            &lt;td&gt;$180&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tfoot&gt;

    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;January&lt;/td&gt;
            &lt;td&gt;$100&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;February&lt;/td&gt;
            &lt;td&gt;$80&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;		
		
			</pre>
			<pre class="programlisting">
		
import pandas as pd

# 错误方法
html = open('table.html', 'r').read()
data = pd.read_html(html)[0]
print(data)

# 正确方法
data = pd.read_html('table.html')[0]
print(data)
		
		
			</pre>
		</div>

		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1279"></a>从网址获取表格数据</h5></div></div></div>
			
			<p>获取页面中所有table的数据</p>
			<pre class="programlisting">
		
import pandas as pd

url = "http://www.stats.gov.cn/tjsj/zxfb/202103/t20210330_1815829.html"
data = pd.read_html(url)

print(data)
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1280"></a>处理多个表格</h5></div></div></div>
			
			<p>多个 table 会返回一个数组，通过数组下标可以读取指定表格。</p>
			<pre class="programlisting">
		
import pandas as pd

url = "http://www.stats.gov.cn/tjsj/zxfb/202103/t20210330_1815829.html"
data = pd.read_html(url)[1]

print(data)		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1281"></a>获取指定属性的表格</h5></div></div></div>
			
			<p>通过 id 属性，精确提取指定表格中的数据。</p>
			<pre class="programlisting">
		
import pandas as pd

html = """
&lt;table id="first"&gt;
  &lt;tr&gt;&lt;th&gt;姓名&lt;/th&gt;&lt;th&gt;性别&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;张三&lt;/td&gt;&lt;td&gt;男&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;table id="second"&gt;
  &lt;tr&gt;&lt;th&gt;姓名&lt;/th&gt;&lt;th&gt;性别&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;李四&lt;/td&gt;&lt;td&gt;男&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
"""
data = pd.read_html(html, attrs={'id': 'second'})
print(data[0])
		
		
			</pre>
			<p>获取 html table 标签 id 属性为 oTable 的表格数据 </p>
			<pre class="programlisting">
		
import pandas as pd

url = "http://fund.eastmoney.com/fund.html"
data = pd.read_html(url,attrs = {'id': 'oTable'})

print(data)		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1282"></a>结合 Xpath 使用</h5></div></div></div>
			
			<p>HTML 属性，只有 id 是唯一的，其他属性都允许重复使用，例如 class，所以使用 class 会选中多张 HTML 表格。</p>
			<pre class="programlisting">
		
data = pd.read_html(text, attrs={'class': 'netkiller'})
print(len(data))		
		
			</pre>
			<p>我的做法是使用 xpath 精准匹配，为什么部用数组下标了，因为页面的变化很可能造成数字顺序错乱。</p>
			<pre class="programlisting">
		
import pandas as pd
from lxml import etree

text = """
&lt;table class="netkiller"&gt;
  &lt;tr&gt;&lt;th&gt;姓名&lt;/th&gt;&lt;th&gt;性别&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;张三&lt;/td&gt;&lt;td&gt;男&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;table class="netkiller"&gt;
  &lt;tr&gt;&lt;th&gt;姓名&lt;/th&gt;&lt;th&gt;性别&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;李四&lt;/td&gt;&lt;td&gt;男&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
"""

html = etree.HTML(text)
result = html.xpath('//table[@class="netkiller"][last()]')
text = etree.tostring(result[0], encoding='utf-8').decode('utf-8')

data = pd.read_html(text)
print(data[0])
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1283"></a>指定编码</h5></div></div></div>
			
			<p>目前仍有部分中文网站使用 GB2312和GBK编码，遇到输出乱码的情况，使用encoding指定编码即可。</p>
			<p>建议：中文建议使用 GB18030，GB18038 包含了中日韩三国字符集，也就是说GB18030 是涵盖 GB2312和GBK的。</p>
			<pre class="programlisting">
		
import pandas as pd

url = "http://www.tianqihoubao.com/weather/top/shenzhen.html"
data = pd.read_html(url, encoding="GB18030")
print(data[0])
		
		
			</pre>

		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1285"></a>23.2.1.2. 使用 Dominate 生成 HTML</h4></div></div></div>
		
		<pre class="programlisting">
		
import dominate
from dominate.tags import *
import time
import os
import pandas as pd

os.chdir(os.path.dirname(__file__))

df = pd.read_excel("2022年6月17 Excle.xlsx", '6月17', usecols="A:R")

print("=" * 20, '打印表头列名', "=" * 20)
header = df.columns[4:].tolist()
print(header)

print("=" * 20, '价格', "=" * 20)
price = df.iloc[0][4:].fillna('').to_dict()
print(price)

print("行：{0}".format(df.index.size))
print("列：{0}".format(df.columns.size))

doc = dominate.document(title='Dominate your HTML')
with doc:
    with div(id='content'):
        for index, row in df.iterrows():
            # print(row.to_dict())
            t = row[1:].fillna(0).to_dict()
            if t['合计'] == 0:
                continue
            br()
            with table(id=index, border=1, cellspacing="0", cellpadding="0", width='50%'):
                caption('亲！本期团购清单如下：{0}'.format(
                    time.strftime('%Y-%m-%d', time.localtime())))
                h = tr(align="center")
                b = tr(align="center")
                thprice = tr(align="center")
                for key, value in t.items():
                    # print(value)
                    # print(t)
                    # if not value.isnull():
                    if value != 0:
                        h.add(th(key))
                        b.add(td(value))
                        if key in price.keys():
                            thprice.add(td(price[key]))
                        elif key == '几期':
                            thprice.add(td('单价'))
                        else:
                            thprice.add(td(''))
                thead().add(h)
                thead().add(thprice)
                tbody().add(b)
                # tfoot().add(p)

with open('doc.html', 'w') as file:
    file.write(doc.render())
# print(doc)
		
		
		</pre>
	</div>
	
</div>
		
<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="pandas.excel"></a>23.2.2. Excel 处理</h3></div></div></div>
	
	<p>本节主要介绍和excel的交互。</p>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1287"></a>23.2.2.1. 安装依赖库</h4></div></div></div>
		
		<pre class="screen">
		
neo@MacBook-Pro-Neo ~ % pip install openpyxl		
		
		</pre>

	</div>

	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1288"></a>23.2.2.2. 创建 Excel 文档</h4></div></div></div>
		
		<pre class="programlisting">
			
from pandas import DataFrame

data = {
    'name': ['Neo', 'Tom', 'Jerry'],
    'age': [11, 12, 13],
    'gender': ['Y', 'Y', 'N']
}
df = DataFrame(data)
df.to_excel('netkiller.xlsx')			
			
		</pre>
		<p>写入指定工作表</p>
		<pre class="programlisting">
			
from pandas import DataFrame

data = {
    '姓名': ['Neo', 'Tom', 'Jerry'],
    '年龄': [11, 12, 13],
    '性别': ['Y', 'Y', 'N']
}
df = DataFrame(data)
df.to_excel('neo.xlsx', sheet_name='我的工作表')			
			
		</pre>
		<p>设置 sheet_name 参数将数据写入指定的工作表</p>

		<p>startrow=2 从第几行开始写入, index=False 关闭序号列, header=False 不写入表头</p>
		<pre class="programlisting">
			
from pandas import DataFrame

data = {
    '姓名': ['Neo', 'Tom', 'Jerry'],
    '年龄': [11, 12, 13],
    '性别': ['Y', 'Y', 'N']
}
df = DataFrame(data)
df.to_excel('neo.xlsx', sheet_name='我的工作表',
            startrow=2, index=False, header=False)
			
			
		</pre>
		<p>写入多个工作表</p>
		<pre class="programlisting">
			
import pandas as pd

data = pd.DataFrame(
    {
        '姓名': ['Neo', 'Tom', 'Jerry'],
        '年龄': [11, 12, 13],
        '性别': ['Y', 'Y', 'N']
    }
)
excel = pd.ExcelWriter("sheet.xlsx")
data.to_excel(excel, sheet_name="Sheet1", index=False)
data.to_excel(excel, sheet_name="Sheet2", index=False)
data.to_excel(excel, sheet_name="Sheet3", index=False)
excel.save()
excel.close()			
			
		</pre>
		<p>向Excel中追加工作表</p>
		<pre class="programlisting">
		
# 追加工作表，首先创建 Excel 文件
with pd.ExcelWriter("sheet1.xlsx") as writer:
    data.to_excel(writer, sheet_name="Sheet1", index=False)
    data.to_excel(writer, sheet_name="Sheet2", index=False)
    data.to_excel(writer, sheet_name="Sheet3", index=False)
    	
    	
append = pd.DataFrame(
    {
        '姓名': ['Neo', 'Tom', 'Jerry'],
        '年龄': [11, 12, 13],
        '性别': ['Y', 'Y', 'N']
    }
)
# 默认ExcelWriter是覆盖模式，需要使用 mode='a' 参数，才能Excel文件中增加工作表
with pd.ExcelWriter("sheet1.xlsx", mode='a', engine='openpyxl') as writer:
    append.to_excel(writer, sheet_name="Sheet4", index=False)
    append.to_excel(writer, sheet_name="Sheet5", index=False)
		
		

		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1290"></a>23.2.2.3. 读取 Excel 文件</h4></div></div></div>
		
		<p>read_excel() 参数详解：</p>
		<pre class="screen">
			
加载函数为read_excel(),其具体参数如下。

read_excel(io, sheetname=0, header=0, skiprows=None, skip_footer=0, index_col=None,names=None, parse_cols=None, parse_dates=False,date_parser=None,na_values=None,thousands=None, convert_float=True, has_index_names=None, converters=None,dtype=None, true_values=None, false_values=None, engine=None, squeeze=False, **kwds)

常用参数解析：
io : string, path object ; excel 路径。
sheetname : string, int, mixed list of strings/ints, or None, default 0 返回多表使用sheetname=[0,1],若sheetname=None是返回全表 
header : int, list of ints, default 0 指定列表头，默认0，即取第一行，数据没有表头设定
skiprows : list-like,Rows to skip at the beginning，跳过指定行数的数据
skip_footer : int,default 0, 省略从尾部数的行数据，默认是 0
index_col : int, list of ints, default None 指定列为索引列
names : array-like, default None, 指定列的名字。		
			
		</pre>
		<pre class="programlisting">
		
#!/usr/bin/python3
# -*- coding: UTF-8 -*-
import pandas as pd
# 默认读取第一个工作表
df = pd.read_excel("团购2021.xlsx")
data = df.head()  # 默认读取前5行的数据
print("当前默认工作表：\n{0}".format(data))  # 格式化输出
		
		</pre>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1289"></a>读取指定列</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd

df = pd.read_excel("../netkiller.xlsx")
print(df.head())
print("=" * 50)
# 读取B～E列的数据
df = pd.read_excel("../netkiller.xlsx", index_col=False, usecols="B:E")
print(df)
			
			</pre>
		</div>
	</div>

	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1296"></a>23.2.2.4. 工作表</h4></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1291"></a>显示所有工作表</h5></div></div></div>
			
			<p>获取Excel文件中的工作表</p>
			<pre class="programlisting">
			
import pandas as pd
xls = pd.ExcelFile("团购2021.xlsx")
sheet_names = xls.sheet_names
print(sheet_names)
			
			</pre>
			<p>打开默认工作表</p>
			<pre class="programlisting">
			
import pandas as pd			
df = pd.read_excel("团购2021.xlsx", None)
print(df.keys())
for k,v in df.items():
    print(k)
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1292"></a>打开工作表</h5></div></div></div>
			
			<p>打开指定工作表</p>
			<pre class="programlisting">
			
#!/usr/bin/python3
# -*- coding: UTF-8 -*-
import pandas as pd

file_path = r'团购.xlsx'
df = pd.read_excel(file_path, sheet_name="3月2日", header=1) 
			
			</pre>
			<p>打开 Excel 并返回指定列数据</p>
			<pre class="programlisting">
		
import pandas as pd
sheet = pd.read_excel(io="new.xlsx", usecols=['name'])
print(sheet)		
		
			</pre>
			<p>打开多个工作表</p>
			<pre class="programlisting">
			
import pandas as pd
sheet = pd.read_excel(io="测试数据.xlsx", sheet_name=[0, 1])
print(sheet[0])
			
			</pre>
			<div class="example"><a id="id1492"></a><p class="title"><strong>例 23.1. Pandas 打开工作表的四种方法</strong></p><div class="example-contents">
				
				<pre class="programlisting">
				
import pandas as pd

# 打开一张工作表
df = pd.read_excel("sheet1.xlsx", sheet_name="Sheet1")
print(df)

# 指定并打开多张工作表
df = pd.read_excel("sheet1.xlsx", sheet_name=["Sheet1", "Sheet2", "Sheet3"])
for sheet, data in df.items():
    print("=" * 20, sheet, "=" * 20)
    print(data)

# 使用数字索引打开多张工作表
df = pd.read_excel("sheet1.xlsx", sheet_name=[0, 1, 2])
for sheet, data in df.items():
    print("=" * 20, sheet, "=" * 20)
    print(data)

# 使用 ExcelFile 对象打开多个工作表
sheet = {}
with pd.ExcelFile("sheet1.xlsx") as xls:
    sheet["Sheet1"] = pd.read_excel(
        xls, "Sheet1", index_col=None, na_values=["NA"])
    sheet["Sheet2"] = pd.read_excel(xls, "Sheet2", index_col=1)

for sheet, data in sheet.items():
    print("=" * 20, sheet, "=" * 20)
    print(data)
				
				</pre>
			</div></div><br class="example-break" />
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1293"></a>合并工作表</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd
sheet = pd.read_excel("测试.xlsx", sheet_name=[1, 0])
st = pd.concat(sheet,ignore_index = True)
			
			</pre>
			<p></p>
			<pre class="programlisting">
			
import pandas as pd
sheet = pd.read_excel("sheet1.xlsx", sheet_name=[1, 0])
df = pd.concat(sheet, ignore_index=True)
print(df)
df.to_excel('merge.xlsx', index=False)
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1294"></a>打开工作表，指定返回列数据</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd

df = pd.read_excel("../netkiller.xlsx", index_col=False, usecols="B,C:E")
print("=" * 20, "读取B,C:E列的数据", "=" * 20)
print(df.head())

# 读取B～E列的数据
df = pd.read_excel("../netkiller.xlsx", index_col=False, usecols="B:E")
print("=" * 20, "读取B～E列的数据", "=" * 20)
print(df)		

df = pd.read_excel("netkiller.xlsx", index_col=False, usecols=[1, 2, 3])
print("=" * 20, "读取[1, 2, 3]列的数据", "=" * 20)
print(df)	
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1295"></a>跳过不需要的数据</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd
from pandas import DataFrame
xlsx = 'skip.xlsx'
data = {
    '姓名': ['张三', '李四', '王五', '牛七', '马八', '赵九'],
    '年龄': [11, 12, 13, 14, 15, 17],
    '性别': ['Y', 'Y', 'N', 'Y', 'N', 'Y']
}
df = DataFrame(data)
df.to_excel(xlsx, index=True, index_label='序号')

df = pd.read_excel(xlsx, skiprows=[1, 3, 4])
print("跳过数据 [1, 3, 4]：\n{0}".format(df))

df = pd.read_excel(xlsx, skiprows=3)
print("跳过前3条数据：\n{0}".format(df))

df = pd.read_excel(xlsx, skipfooter=2)
print("从尾部剪掉1条数据：\n{0}".format(df))

			
			</pre>
			<p></p>
			<pre class="screen">
			
跳过数据 [1, 3, 4]：
   序号  姓名  年龄 性别
0   1  李四  12  Y
1   4  马八  15  N
2   5  赵九  17  Y
跳过 top10 数据：
   2  王五  13  N
0  3  牛七  14  Y
1  4  马八  15  N
2  5  赵九  17  Y
从尾部剪掉1条数据：
   序号  姓名  年龄 性别
0   0  张三  11  Y
1   1  李四  12  Y
2   2  王五  13  N
3   3  牛七  14  Y			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1305"></a>23.2.2.5. 数据操作</h4></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1297"></a>打印头部/尾部数据</h5></div></div></div>
			
			<p>仅查看数据示例时常用</p>
			<pre class="programlisting">
			
print(df.head())
print(df.tail())
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1298"></a>打印列标题</h5></div></div></div>
			
			<pre class="programlisting">
			
print(sheet.columns)			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1299"></a>打印行</h5></div></div></div>
			
			<pre class="programlisting">
			
print(sheet.index)			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1300"></a>描述数据</h5></div></div></div>
			
			<pre class="programlisting">
			
print(sheet.describe())			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1301"></a>修改 Excel 数据</h5></div></div></div>
			
			<pre class="programlisting">
		
import pandas as pd
from pandas import DataFrame

file_path = r'new.xlsx'
df = pd.read_excel(file_path)

df['gender'][df['gender'] == 'N'] = 'Female'
df['gender'][df['gender'] == 'Y'] = 'Male'

print(df)

DataFrame(df).to_excel(
    file_path, sheet_name='Sheet1', index=False, header=True)
		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1302"></a>新增行/列</h5></div></div></div>
			
			<pre class="programlisting">
		
import pandas as pd
from pandas import DataFrame

file_path = r'new.xlsx'
df = pd.read_excel(file_path)

# 新增一列
df['ctime'] = None

# 新增一行
df.loc[4] = [3, 'Alice', 20, 'Female',  '2021-5-11']

print(df)

DataFrame(df).to_excel(
    file_path, sheet_name='Sheet2', index=False, header=True)
		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1303"></a>数据筛选</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd
sheet = pd.read_excel("工资表.xlsx", usecols=['工资'])
high_salary = sheet[sheet['工资'] &gt; 10000]
middle_salary = sheet[(sheet['工资'] &gt;= 8000) &amp; (sheet['工资'] &lt;=10000)]
low_salary = sheet[sheet['工资'] &lt; 8000]
			
			</pre>
			<pre class="programlisting">
			
high_salary = sheet[(sheet['工资'] &gt;= 8000) &amp; (sheet['工资'] &lt;=10000)][['姓名','工资']]			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1304"></a>数据排序</h5></div></div></div>
			

		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1306"></a>23.2.2.6. Excel 设置项</h4></div></div></div>
		
		<pre class="programlisting">
		
import numpy as np
import pandas as pd
pd.set_option('max_columns', 10)
pd.set_option('max_rows', 20)
# 禁用科学计数法
pd.set_option('display.float_format', lambda x: '%.2f' % x) 
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1307"></a>23.2.2.7. 大数据写入Excel问题</h4></div></div></div>
		
		<p>df.to_excel 导出大数据会出现 Excle 表格损坏或没有数据的情况</p>
		<pre class="screen">
		
df = pd.read_sql_query(text(sqlOrder), engine.connect())
df.to_excel("{yesterday}.xlsx".format(yesterday=yesterday), sheet_name='Sheet1', index=False)		
		
		</pre>
		<p>解决方案</p>
		<pre class="screen">
		
	df = pd.read_sql_query(text(query), connect)
    with pd.ExcelWriter(xlsxfile) as writer:
        df.to_excel(writer, sheet_name=platform_name.replace(':',''), index=False)
		
		</pre>
	</div>
</div>
<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="pandas.csv"></a>23.2.3. Pandas 读写 CSV 文件</h3></div></div></div>
	

	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1308"></a>23.2.3.1. 将数据保存到CSV文件</h4></div></div></div>
		
		<pre class="programlisting">
		
import pandas as pd

months=[202001,202002,202003,202004,202005,202006,202007,202008,202009,202010,202011,202012]

for month in months:
    print(month)
    weather = pd.read_html(f'http://www.tianqihoubao.com/lishi/wanzhou/month/{month}.html', encoding='gb18030', header=0)[0]
    print(weather)
    weather.to_csv(f'/tmp/{month}天气预报数据.csv', mode='a+', index=False, header=False)		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1309"></a>23.2.3.2. 写入表头列名</h4></div></div></div>
		
		<p>header=True</p>
		<pre class="programlisting">
		
df.to_csv(f'/tmp/{month}天气预报数据.csv', mode='a+', index=False, header=True)		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1310"></a>23.2.3.3. 分隔符</h4></div></div></div>
		
		<pre class="programlisting">
		
dt.to_csv('C:/Users/think/Desktop/Result.csv',sep='?')	
dt.to_csv('C:/Users/think/Desktop/Result.csv',sep=':')	
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1311"></a>23.2.3.4. 格式化</h4></div></div></div>
		
		<pre class="programlisting">
		
# 格式 float_format: Format string for floating point numbers
# 保留两位小数
dt.to_csv('/tmp/neo.csv',float_format='%.2f') 
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1312"></a>23.2.3.5. 指定列输出</h4></div></div></div>
		
		<pre class="programlisting">
		
# cols: Columns to write (default None)
dt.to_csv('C:/Users/think/Desktop/Result.csv',columns=['name']) 	
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1313"></a>23.2.3.6. 留行索引</h4></div></div></div>
		
		<pre class="programlisting">
		
# index:  whether to write row (index) names (default True)
dt.to_csv('/tmp/neo.csv',index=0) 		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1314"></a>23.2.3.7. 替换空值</h4></div></div></div>
		
		<pre class="programlisting">
		
# na_rep: A string representation of a missing value (default ‘’)
dt.to_csv('/tmp/neo.csv',na_rep='NA') 		
		
		</pre>
		<p>替换NaN(dropna,fillna,isnull)</p>
		<pre class="programlisting">
		
import pandas as pd
import numpy as np

a = np.arange(25, dtype=float).reshape((5, 5))
# print(len(a))
for i in range(len(a)):
    a[i, :i] = np.nan
a[3, 0] = 25.0
df = pd.DataFrame(data=a, columns=list('ABCDE'))
print('-'*20, '原始数据', '-'*20)
print(df)

print('-'*20, '填充0', '-'*20)
print(df.fillna(value=0))

print('-'*20, '向后填充', '-'*20)
print(df.fillna(method='pad'))

print('-'*20, '向前填充', '-'*20)
print(df.fillna(method='backfill'))

print('-'*20, '用字典填充', '-'*20)
values = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
print(df.fillna(value=values))

print('-'*20, '只替换第1个NaN值', '-'*20)
print(df.fillna(method='pad', limit=1))
	
		
		</pre>
		<p>输出结果</p>
		<pre class="screen">
		
-------------------- 原始数据 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1   NaN  6.0   7.0   8.0   9.0
2   NaN  NaN  12.0  13.0  14.0
3  25.0  NaN   NaN  18.0  19.0
4   NaN  NaN   NaN   NaN  24.0
-------------------- 填充0 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1   0.0  6.0   7.0   8.0   9.0
2   0.0  0.0  12.0  13.0  14.0
3  25.0  0.0   0.0  18.0  19.0
4   0.0  0.0   0.0   0.0  24.0
-------------------- 向后填充 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1   0.0  6.0   7.0   8.0   9.0
2   0.0  6.0  12.0  13.0  14.0
3  25.0  6.0  12.0  18.0  19.0
4  25.0  6.0  12.0  18.0  24.0
-------------------- 向前填充 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1  25.0  6.0   7.0   8.0   9.0
2  25.0  NaN  12.0  13.0  14.0
3  25.0  NaN   NaN  18.0  19.0
4   NaN  NaN   NaN   NaN  24.0
-------------------- 用字典填充 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1   0.0  6.0   7.0   8.0   9.0
2   0.0  1.0  12.0  13.0  14.0
3  25.0  1.0   2.0  18.0  19.0
4   0.0  1.0   2.0   3.0  24.0
-------------------- 只替换第1个NaN值 --------------------
      A    B     C     D     E
0   0.0  1.0   2.0   3.0   4.0
1   0.0  6.0   7.0   8.0   9.0
2   NaN  6.0  12.0  13.0  14.0
3  25.0  NaN  12.0  18.0  19.0
4  25.0  NaN   NaN  18.0  24.0		
		
		</pre>
	</div>
</div>	
		
<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1320"></a>23.2.4. Pandas SQL</h3></div></div></div>
	
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1317"></a>23.2.4.1. 建立数据库链接</h4></div></div></div>
		

		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1315"></a>sqlite3</h5></div></div></div>
			
			<pre class="programlisting">
			
import pandas as pd
from pandas import DataFrame
import sqlite3
con = sqlite3.connect(":memory:")

data = DataFrame({
    '姓名': ['张三', '李四', '王五'],
    '年龄': [11, 12, 13],
    '性别': ['Y', 'Y', 'N']
})

data.to_sql("data", con)
table = pd.read_sql_query("SELECT * FROM data", con)
print(table)			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1316"></a>SQLAlchemy</h5></div></div></div>
			
			<p>安装依赖库</p>
			<pre class="screen">
		
neo@MacBook-Pro-Neo ~ % pip install sqlalchemy		
		
			</pre>
			<p>创建链接引擎参考实例</p>
			<pre class="programlisting">
		
from sqlalchemy import create_engine

engine = create_engine("postgresql://scott:tiger@localhost:5432/mydatabase")

engine = create_engine("mysql+mysqldb://scott:tiger@localhost/foo")

engine = create_engine("oracle://scott:tiger@127.0.0.1:1521/sidname")

engine = create_engine("mssql+pyodbc://mydsn")

# sqlite://&lt;nohostname&gt;/&lt;path&gt;
# where &lt;path&gt; is relative:
engine = create_engine("sqlite:///foo.db")

# or absolute, starting with a slash:
engine = create_engine("sqlite:////absolute/path/to/foo.db")		
		
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1319"></a>23.2.4.2. DataFrame数据写入到数据库</h4></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1318"></a>分批写入数据</h5></div></div></div>
			
			<p>DataFrame 结果集很大，写入时间过程很长，容易产生错误，这时可以使用 chunksize 切割数据，分批写入。</p>
			<pre class="programlisting">
		
from sqlalchemy import create_engine
import pandas as pd
from pandas import DataFrame

engine = create_engine("sqlite:///:memory:")

data = DataFrame({
    '姓名': ['张三', '李四', '王五'],
    '年龄': [11, 12, 13],
    '性别': ['Y', 'Y', 'N']
})

data.to_sql("data", engine, chunksize=1000)

table = pd.read_sql_query("SELECT * FROM data", engine)
print(table)		
		
			</pre>
		</div>

	</div>
</div>
	</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="index.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="pandas.DataFrame.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">第 23 章 Pandas - Python Data Analysis Library </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 23.3. 数据帧(DataFrame)</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>