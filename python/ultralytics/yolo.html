<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>11.4. YOLO</title><link rel="stylesheet" type="text/css" href="../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../index.html" title="Netkiller Python 手札" /><link rel="up" href="index.html" title="第 11 章 Ultralytics" /><link rel="prev" href="ultralytics.task.html" title="11.3. Task 任务" /><link rel="next" href="ch11s05.html" title="11.5. ONNX(Open Neural Network Exchange) 开放神经网络交换格式" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">11.4. YOLO</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ultralytics.task.html">上一页</a> </td><th width="60%" align="center">第 11 章 Ultralytics</th><td width="20%" align="right"> <a accesskey="n" href="ch11s05.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="yolo"></a>11.4. YOLO</h2></div></div></div>
	
	<div class="orderedlist"><p class="title"><strong>目标检测任务</strong></p><ol class="orderedlist" type="1"><li class="listitem">YOLO11：用于经典的目标检测任务。</li><li class="listitem">YOLO11-seg：用于实例分割，识别和分割图像中的对象。</li><li class="listitem">YOLO11-pose：用于关键点姿态估计，即确定人体的关键点（如关节位置）。</li><li class="listitem">YOLO11-obb：用于定向检测，可以识别并确定具有方向性物体的边界框（例如倾斜的目标物体）。</li><li class="listitem">YOLO11-cls：用于分类，负责对图像中的对象进行类别识别。</li></ol></div>
	<div class="orderedlist"><p class="title"><strong>模型规格</strong></p><ol class="orderedlist" type="1"><li class="listitem">YOLOv8 Nano 非常小 YOLOv8n</li><li class="listitem">YOLOv8 Small 小 YOLOv8s</li><li class="listitem">YOLOv8 Medium 中 YOLOv8m</li><li class="listitem">YOLOv8 Large 大 YOLOv8l</li><li class="listitem">YOLOv8 X（Extra Large） 非常大 YOLOv8x</li></ol></div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1047"></a>11.4.1. labels 文件格式</h3></div></div></div>
		
		<p>x,y是目标的中心坐标，width,height是目标的宽和高。</p>
		<pre class="screen">
		
&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;		
		
		</pre>
		<p>VOC与YOLO之间的格式转换</p>
		<pre class="programlisting">
		
# size是原图的（w,h), box是坐标

def voc_to_yolo(size, box):
    dw = 1./size[0]
    dh = 1./size[1]
    x = (box[0] + box[1])/2.0
    y = (box[2] + box[3])/2.0
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    return (x,y,w,h)
 
def yolo_to_voc(size, box):
    x = box[0] * size[0]
    w = box[2] * size[0]
    y = box[1] * size[1]
    h = box[3] * size[1]
    xmin = int(x - w/2)
    xmax = int(x + w/2)
    ymin = int(y - h/2)
    ymax = int(y + h/2)
    return (xmin, ymin, xmax, ymax)
		
		
		</pre>
	</div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1059"></a>11.4.2. 模型训练</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO
# 指定模型
mode = YOLO('yolo11n-seg.pt')
# 让模型开始训练
mode.train(data='dataset.yaml',workers=0,epochs=10,batch=10)
# 验证模型
mode.val()		
		
		</pre>

		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1048"></a>11.4.2.1. 输出结果</h4></div></div></div>
			
			<pre class="screen">
			
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
     64/100     0.679G     0.5564     0.5321      1.084          9        320: 100%|██████████| 231/231 [00:25&lt;00:00,  8.97it/s]
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:05&lt;00:00,  6.49it/s]
                   all       1068       1068      0.958      0.943      0.984      0.944			
			
			</pre>
			<p>Epoch GPU_mem box_loss cls_loss dfl_loss Instances Size</p>
			<div class="glosslist"><dl><dt><span class="glossterm">Epoch</span></dt><dd class="glossdef"><p>训练过程中的迭代次数，在机器学习和深度学习中，一个epoch是训练过程中的一个完整周期，包括了训练数据集中的所有样本，以逐渐优化其性能。
						</p></dd><dt><span class="glossterm">GPU_mem</span></dt><dd class="glossdef"><p>GPU显存的使用情况，也就是图形处理器在训练过程中所使用的显存量。</p></dd><dt><span class="glossterm">box_loss</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">cls_loss</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">dfl_loss</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">Instances</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">Size</span></dt><dd class="glossdef"></dd></dl></div>
			<p>Class Images Instances Box(P R mAP50 mAP50-95):</p>
			<div class="glosslist"><p class="title"><strong></strong></p><dl><dt><span class="glossterm">Class</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">Images</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">Instances</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">P</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">R</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">mAP50</span></dt><dd class="glossdef"></dd><dt><span class="glossterm">mAP50-95</span></dt><dd class="glossdef"></dd></dl></div>

		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1058"></a>11.4.2.2. 训练结果</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1049"></a>weights 文件夹</h5></div></div></div>
				
				<p>打开 weights 文件夹里面有两个文件，分别是：best.pt和last.pt。</p>
				<p>best.pt 是整个训练过程中，性能最好的模型权重文件。</p>
				<p>last.pt 是最后一次训练的模型权重文件。</p>
				<p>一般我们选择 best.pt 文件，用于生产环境。</p>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1050"></a>args.yaml 文件</h5></div></div></div>
				
				<pre class="screen">
				
task: detect
mode: train
model: tongue.yaml
data: datasets/test/YOLODataset/dataset.yaml
epochs: 100
time: null
patience: 100
batch: 16
imgsz: 320
save: true
save_period: -1
cache: false
device: 0
workers: 8
project: null
name: train9
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: true
opset: null
workspace: null
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
copy_paste_mode: flip
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: D:\workspace\netkiller\runs\detect\train
				
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1051"></a>confusion_matrix.png / confusion_matrix_normalized.png
				</h5></div></div></div>
				
				<p>混淆矩阵的归一化版本</p>
			</div>

			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1052"></a>P_curve.png / R_curve.png/ PR_curve.png /F1_curve.png</h5></div></div></div>
				
				<div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">P_curve.png 每个 label 的精度</li><li class="listitem">R_curve.png 每个 label 的召回率</li><li class="listitem">PR_curve.png 精度与召回互相妥协的曲线。范围 0.0 ~ 1.0 越接近 1.0 效果越好。
					</li></ol></div>
			</div>

			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1053"></a>labels.jpg / labels_correlogram.jpg</h5></div></div></div>
				
				<p>labels.jpg 分类标签的分布</p>
				<p></p>
			</div>

			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1054"></a>results.png / results.csv</h5></div></div></div>
				
				<p>先看前三列是 loss
					损失率图表，X轴表示训练轮次，Y轴表示损失值。推理结果和人工标注的答案之间的差异，称为“损失”。损失越小越好，损失为0则说明推理和正确答案之间没有差异，即预测100%命中。
				</p>
				<div class="orderedlist"><p class="title"><strong>train 训练集，val 验证集</strong></p><ol class="orderedlist" type="1"><li class="listitem">train/box_loss和val/box_loss</li><li class="listitem">train/cls_loss和val/cls_loss</li><li class="listitem">train/dfl_loss和val/dfl_loss</li></ol></div>
				<div class="orderedlist"><p class="title"><strong>精度/召回率</strong></p><ol class="orderedlist" type="1"><li class="listitem">metric/precision(B) 精度</li><li class="listitem">metrics/recall(B) 召回率</li></ol></div>
				<p>mAP50是重合度以50%为界限的平均精度。而mAP50-95则是IoU阈值从50%到95%范围内的平均值</p>
				<p>X轴是训练轮次，Y表示精度，取值0.0 ~ 1.0（100%）越接近1.0效果越好。</p>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1055"></a>train_batch0.jpg</h5></div></div></div>
				
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1056"></a>val_batch0_labels.jpg</h5></div></div></div>
				
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id1057"></a>val_batch0_pred.jpg</h5></div></div></div>
				
			</div>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1060"></a>11.4.3. 模型评估</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO
# ---------- 加载模型 ----------
model = YOLO('runs/detect/train/weights/best.pt')
# ---------- 模型评估 ----------
model.val(data='captcha/images/YOLODataset/dataset.yaml')
		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1065"></a>11.4.4. 模型预测</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO

# 加载预训练的YOLOv11n模型
model = YOLO("yolo11n.pt")  # yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11x.pt

# 对'bus.jpg'图像进行推理，并获取结果 https://ultralytics.com/images/bus.jpg
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    result.show()  # 显示结果型的架构
    print(boxes)
    print(probs)		
		
		</pre>
		<p>换一个模型，试试 yolo11n-seg.pt</p>
		<pre class="programlisting">
		
from ultralytics import YOLO

model = YOLO("yolo11n-seg.pt")
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    print(boxes)
    print(probs)
    result.show()  # 显示结果型的架构		
		
		</pre>

		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1061"></a>11.4.4.1. predict 参数</h4></div></div></div>
			
			<pre class="programlisting">
			
from yolov8 import YOLO
 
# 加载预训练模型
model = YOLO('yolov8.pt')
 
# 执行预测
results = model.predict(
    source='path/to/image.jpg',  # 输入源，可以是图像路径、视频路径、摄像头索引等
    conf=0.5,                    # 置信度阈值，滤除低于该置信度的检测结果。
    iou=0.45,                    # NMS的交并比阈值，用于消除重叠的检测框。
    device='cuda',               # 使用GPU
    imgsz=(640, 640),            # 输入图像的尺寸，可以是单个整数（长宽相等）或元组（长和宽）。
    half=False,                  # 不使用半精度浮点数
    save_txt=True,               # 保存预测结果为文本文件
    save_conf=True,              # 在保存的文本文件中包含置信度
    save_crop=False,             # 不保存裁剪后的检测结果
    save_img=True,               # 保存带有检测框的图像
    classes=[0, 1, 2],           # 仅检测指定的类
    agnostic_nms=False,          # 不使用类别无关的NMS
    augment=False,               # 不使用数据增强
    visualize=False,             # 不可视化特征图
    project='runs/detect',       # 保存预测结果的项目目录
    name='exp',                  # 保存预测结果的子目录名称
    exist_ok=False,              # 不允许项目目录存在
    line_thickness=3,            # 绘制检测框的线条粗细
    hide_labels=False,           # 显示检测框的标签
    hide_conf=False              # 显示检测框的置信度
)
 
# 输出预测结果
print(results)
			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1062"></a>11.4.4.2. 返回结果</h4></div></div></div>
			
			<p>返回结果通常包含以下主要属性和方法：</p>
			<div class="literallayout"><p><br />
			<br />
1.boxes: 包含检测到的边界框信息的对象。<br />
2.scores: 包含每个检测目标的置信度分数。<br />
3.classes: 包含每个检测目标的类别索引。<br />
4.masks: 如果使用实例分割模型，包含分割掩码。<br />
5.keypoints: 如果使用关键点检测模型，包含关键点信息。<br />
6.orig_img: 原始输入图像。<br />
7.plot(): 用于可视化检测结果的方法。			<br />
			<br />
			</p></div>
			<p>boxes: </p>
			<div class="literallayout"><p><br />
			<br />
1.boxes.xyxy: 返回每个检测目标的边界框坐标，格式为 [x_min, y_min, x_max, y_max]。<br />
2.boxes.conf: 返回每个检测目标的置信度分数。<br />
3.boxes.cls: 返回每个检测目标的类别索引。			<br />
			<br />
			</p></div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1063"></a>11.4.4.3. 提取标签</h4></div></div></div>
			
			<pre class="programlisting">
			
from ultralytics import YOLO

# 加载模型
# model = YOLO("yolo11n.pt")
# model = YOLO('weights/last.pt')
model = YOLO('weights/best.pt')

# 模型预测，save=True 的时候表示直接保存yolov8的预测结果
results = model('images/0_5902.png')

# View results
for result in results:
    # 处理结果
    boxes = result.boxes  # 边界框结果
    masks = result.masks  # 分割掩码结果
    names = result.names
    keypoints = result.keypoints  # 关键点检测结果
    probs = result.probs  # 分类概率结果
    obb = result.obb  # 方向边界框结果（OBB）
    print(boxes)
    for box in boxes:
        print(names[int(box.cls)])
    result.show()  # 显示结果			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1064"></a>11.4.4.4. 保存识别图像</h4></div></div></div>
			
			<pre class="programlisting">
			
@app.post("/netkiller")
async def netkiller(file: bytes = File()):
    try:
        filename = f"tmp/{uuid.uuid4()}.png"
        print(filename)
        with open(filename, "wb") as f:
            f.write(file)

        results = model(filename) # , conf=0.45

        for result in results:
            boxes = result.boxes  # 获取边界框信息
            # probs = result.probs  # 获取分类概率
            names = result.names
            data = result.boxes.data
            print(boxes)
            # print(probs)
            if names is not None:
                labels = []
                for box in boxes:
                    label = names[int(box.cls)]
                    labels.append(label)
                    print(label)
                # result.show()  # 显示结果型的架构
                result.save(filename="tmp/test.png")

            if boxes is not None:
                image = Image.open(filename)
                # x0, y0, x1, y1 = map(int, boxes.xyxy[0])
                crop = tuple(map(int, boxes.xyxy[0]))

                region = image.crop(crop)
                region.save('tmp/neo.jpg')

            return {"label": labels}
    except Exception as e:
        log.error(e)
    return {"label": None}			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1068"></a>11.4.5. 模型导出</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1066"></a>11.4.5.1. onnx 格式</h4></div></div></div>
			
			<pre class="screen">
			
(.venv) neo@Neo-Mac-mini netkiller % pip install onnx onnxslim -i https://pypi.tuna.tsinghua.edu.cn/simple		
			
			</pre>
			<pre class="programlisting">
			
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="onnx")

# 预测看下效果
onnx_model = YOLO("yolo11n.onnx", task="detect")
results = onnx_model("https://ultralytics.com/images/bus.jpg")
results[0].show()		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1067"></a>11.4.5.2. engine 格式</h4></div></div></div>
			
			<pre class="programlisting">
			
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="engine")
tensorrt_model = YOLO("yolo11n.engine", task="detect")
results = tensorrt_model("https://ultralytics.com/images/bus.jpg")
results[0].show()			
			
			</pre>
		</div>

	</div>
</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ultralytics.task.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ch11s05.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">11.3. Task 任务 </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 11.5. ONNX(Open Neural Network Exchange) 开放神经网络交换格式</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>