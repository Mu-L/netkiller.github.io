<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>第 16 章 PyTorch</title><link rel="stylesheet" type="text/css" href="../../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../../index.html" title="Netkiller Python 手札" /><link rel="up" href="../index.html" title="部分 IV. 人工智能 AI" /><link rel="prev" href="../tensorflow.html" title="15.3. tensorflow" /><link rel="next" href="ch16s02.html" title="16.2. 显卡" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">第 16 章 PyTorch</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="../tensorflow.html">上一页</a> </td><th width="60%" align="center">部分 IV. 人工智能 AI</th><td width="20%" align="right"> <a accesskey="n" href="ch16s02.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a id="index"></a>第 16 章 PyTorch</h2></div></div></div><div class="toc"><p><strong>目录</strong></p><dl class="toc"><dt><span class="section"><a href="index.html#id1097">16.1. 安装 torch</a></span></dt><dd><dl><dt><span class="section"><a href="index.html#torchinfo">16.1.1. torchinfo</a></span></dt></dl></dd><dt><span class="section"><a href="ch16s02.html">16.2. 显卡</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html">16.3. Tensor 张量</a></span></dt><dd><dl><dt><span class="section"><a href="pytorch.tensor.html#id1098">16.3.1. 创建静态 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1099">16.3.2. 创建连续数列的 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1100">16.3.3. 创建0数据的 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1101">16.3.4. 判断变量是否为 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1102">16.3.5. 统计 Tensor 中的元素数量</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1103">16.3.6. 创建对角线为1的 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1104">16.3.7. 将 numpy 转换成 tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1105">16.3.8. 切分</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1106">16.3.9. 均匀分布数列</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1107">16.3.10. 正态分布数列</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1108">16.3.11. 随机数列</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#torch.arange">16.3.12. arange 创建等差数列</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1109">16.3.13. 获取最小值和最大值的索引</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1110">16.3.14. 连接两个 Tensor</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1111">16.3.15. 数据切块</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1112">16.3.16. 通过索引下标选择数据</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1113">16.3.17. 分割</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1114">16.3.18. 矩阵转换</a></span></dt><dt><span class="section"><a href="pytorch.tensor.html#id1115">16.3.19. 矩阵运算</a></span></dt></dl></dd><dt><span class="section"><a href="ch16s04.html">16.4. Dataset</a></span></dt><dt><span class="section"><a href="ch16s05.html">16.5. DataLoader</a></span></dt><dd><dl><dt><span class="section"><a href="ch16s05.html#id1116">16.5.1. 显示数据集中的图片</a></span></dt></dl></dd><dt><span class="section"><a href="ch16s06.html">16.6. Module</a></span></dt><dt><span class="section"><a href="torchvision.html">16.7. torchvision</a></span></dt><dd><dl><dt><span class="section"><a href="torchvision.html#id1117">16.7.1. 安装 torchvision</a></span></dt><dt><span class="section"><a href="torchvision.html#transforms">16.7.2. transforms 数据转换</a></span></dt><dt><span class="section"><a href="torchvision.html#models">16.7.3. models 加载模型</a></span></dt><dt><span class="section"><a href="torchvision.html#datasets">16.7.4. datasets 数据加载</a></span></dt></dl></dd><dt><span class="section"><a href="tensorboard.html">16.8. tensorboard</a></span></dt></dl></div>
	
	<div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id1097"></a>16.1. 安装 torch</h2></div></div></div>
		
		<pre class="programlisting">
			
pip install --upgrade pip
pip install torch torchvision numpy
			
		</pre>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="torchinfo"></a>16.1.1. torchinfo</h3></div></div></div>
			
			<pre class="screen">
			
pip install torchinfo
			
			</pre>
			<pre class="programlisting">
			
    from torchinfo import summary

    summary(mymodel)						
			
			</pre>
			<pre class="screen">
			
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
mymodel                                  --
├─Sequential: 1-1                        --
│    └─Conv2d: 2-1                       640
│    └─ReLU: 2-2                         --
│    └─MaxPool2d: 2-3                    --
├─Sequential: 1-2                        --
│    └─Conv2d: 2-4                       73,856
│    └─ReLU: 2-5                         --
│    └─MaxPool2d: 2-6                    --
├─Sequential: 1-3                        --
│    └─Conv2d: 2-7                       295,168
│    └─ReLU: 2-8                         --
│    └─MaxPool2d: 2-9                    --
├─Sequential: 1-4                        --
│    └─Conv2d: 2-10                      1,180,160
│    └─ReLU: 2-11                        --
│    └─MaxPool2d: 2-12                   --
├─Sequential: 1-5                        --
│    └─Flatten: 2-13                     --
│    └─Linear: 2-14                      62,918,656
│    └─Dropout: 2-15                     --
│    └─ReLU: 2-16                        --
│    └─Linear: 2-17                      589,968
=================================================================
Total params: 65,058,448
Trainable params: 65,058,448
Non-trainable params: 0
=================================================================			
			
			</pre>
		</div>
	</div>
	
	


	
	

	
	

	
</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="../tensorflow.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="../index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ch16s02.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">15.3. tensorflow </td><td width="20%" align="center"><a accesskey="h" href="../../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 16.2. 显卡</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>