<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>20.5. 结巴中文分词</title><link rel="stylesheet" type="text/css" href="../../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../../index.html" title="Netkiller Python 手札" /><link rel="up" href="index.html" title="第 20 章 自然语言处理" /><link rel="prev" href="ch20s04.html" title="20.4. 常用的 Python 分词库" /><link rel="next" href="wordcloud.html" title="20.6. wordcloud" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://edu.51cto.com/lecturer/1703915.html">51CTO学院</a> | <a xmlns="" href="https://edu.csdn.net/lecturer/6423">CSDN程序员研修院</a> | <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> | <a xmlns="" href="https://cloud.tencent.com/developer/column/2078">腾讯云社区</a> | <a xmlns="" href="https://yq.aliyun.com/u/netkiller/">阿里云栖社区</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">20.5. 结巴中文分词</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ch20s04.html">上一页</a> </td><th width="60%" align="center">第 20 章 自然语言处理</th><td width="20%" align="right"> <a accesskey="n" href="wordcloud.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> ｜ <a href="https://www.zhihu.com/club/1241768772601950208">多维度架构</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="jieba"></a>20.5. 结巴中文分词</h2></div></div></div>
	
	<p>
		<a class="ulink" href="https://github.com/fxsjy/jieba" target="_top">https://github.com/fxsjy/jieba</a>
	</p>
	<p>安装</p>
	<pre class="screen">
		
pip install jieba
pip install paddlepaddle
		
	</pre>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528201488"></a>20.5.1. 分词演示</h3></div></div></div>
		
		<pre class="programlisting">
		
# encoding=utf-8
import jieba
import paddle
paddle.enable_static()
jieba.enable_paddle()  # 启动paddle模式。 
strs = ["我来到北京清华大学", "乒乓球拍卖完了", "中国科学技术大学"]
for str in strs:
    seg_list = jieba.cut(str, use_paddle=True)  # 使用paddle模式
    print("Paddle Mode: " + '/'.join(list(seg_list)))

seg_list = jieba.cut("我来到北京清华大学", cut_all=True)
print("Full Mode: " + "/ ".join(seg_list))  # 全模式

seg_list = jieba.cut("我来到北京清华大学", cut_all=False)
print("Default Mode: " + "/ ".join(seg_list))  # 精确模式

seg_list = jieba.cut("他来到了网易杭研大厦")  # 默认是精确模式
print(", ".join(seg_list))

seg_list = jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在日本京都大学深造")  # 搜索引擎模式
print(", ".join(seg_list))
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528200256"></a>20.5.2. 日志设置</h3></div></div></div>
		
		<pre class="programlisting">
		
import jieba
import logging
logger = logging.getLogger()
# 配置 logger 禁止输出无用的信息
jieba.default_logger = logger

text = "他来到了网易杭研大厦"

words = jieba.cut(text)
print(", ".join(words))
print("-" * 50)
# 将 “杭研大厦”，“他来到了” 词频优先
jieba.suggest_freq('杭研大厦', True)
jieba.suggest_freq('他来到了', True)
words = jieba.cut(text)
print(", ".join(words))
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528197712"></a>20.5.3. 返回 generator</h3></div></div></div>
		
		<p>默认 cut 返回 generator</p>
		<pre class="programlisting">
		
# encoding=utf-8
import jieba
import paddle

segs = jieba.cut("转载请与作者联系，同时请务必标明文章原始出处和作者信息及本声明。")
print(type(segs))
print(", ".join(segs))		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528195808"></a>20.5.4. 返回 list</h3></div></div></div>
		
		<pre class="programlisting">
		
# encoding=utf-8
import jieba
import paddle

segs = jieba.lcut("转载请与作者联系，同时请务必标明文章原始出处和作者信息及本声明。")
print(type(segs))
print(", ".join(segs))		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528194352"></a>20.5.5. 精准模式与全模式比较</h3></div></div></div>
		
		<pre class="programlisting">
		
# encoding=utf-8
import jieba
import paddle
text = "转载请与作者联系，同时请务必标明文章原始出处和作者信息及本声明。"
segs = jieba.cut(text)  # 精准模式
print(", ".join(segs))
print("=" * 50)
segs = jieba.cut(text, cut_all=True)  # 全模式
print(", ".join(segs))
		
		</pre>
		<p>输出结果</p>
		<pre class="screen">
		
neo@MacBook-Pro-Neo ~/workspace/python/jieba % python3.9 /Users/neo/workspace/python/jieba/lcut.py
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/2f/jfnljdpn1t1dj_f61z2s8bwm0000gn/T/jieba.cache
Loading model cost 0.787 seconds.
Prefix dict has been built successfully.
转载, 请, 与, 作者, 联系, ，, 同时, 请, 务必, 标明, 文章, 原始, 出处, 和, 作者, 信息, 及本, 声明, 。
==================================================
转载, 请, 与, 作者, 联系, ，, 同时, 请, 务必, 标明, 明文, 文章, 原始, 出处, 和, 作者, 信息, 及, 本, 声明, 。		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528191936"></a>20.5.6. 精准模式与搜索引擎模式比较</h3></div></div></div>
		
		<pre class="programlisting">
		
# encoding=utf-8
import jieba
import paddle
text = "小明硕士毕业于中国科学院计算所，后在日本京都大学深造"
segs = jieba.cut(text)  # 精准模式
print(", ".join(segs))
print("=" * 50)
searchs = jieba.cut_for_search(text)  # 搜索引擎模式
print(", ".join(searchs))
		
		</pre>
		<p>输出结果</p>
		<pre class="screen">
		
neo@MacBook-Pro-Neo ~/workspace/python/jieba % python3.9 /Users/neo/workspace/python/jieba/search.py
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/2f/jfnljdpn1t1dj_f61z2s8bwm0000gn/T/jieba.cache
Loading model cost 0.807 seconds.
Prefix dict has been built successfully.
小明, 硕士, 毕业, 于, 中国科学院, 计算所, ，, 后, 在, 日本京都大学, 深造
==================================================
小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造	
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528188880"></a>20.5.7. 词性标注</h3></div></div></div>
		
		<pre class="screen">
		
标签	含义		标签	含义		标签	含义		标签	含义
n	普通名词	f	方位名词	s	处所名词	t	时间
nr	人名		ns	地名		nt	机构名	nw	作品名
nz	其他专名	v	普通动词	vd	动副词	vn	名动词
a	形容词	ad	副形词	an	名形词	d	副词
m	数量词	q	量词		r	代词		p	介词
c	连词		u	助词		xc	其他虚词	w	标点符号
PER	人名		LOC	地名		ORG	机构名	TIME	时间
		
		
		</pre>
		<p></p>
		<pre class="programlisting">
		
import jieba
import jieba.posseg as pseg
import paddle
words = pseg.cut("我爱北京天安门")  # jieba默认模式
for word, flag in words:
    print('%s %s' % (word, flag))

print("="*40)

paddle.enable_static()
jieba.enable_paddle()  # 启动paddle模式。
words = pseg.cut("我爱北京天安门", use_paddle=True)  # paddle模式
for word, flag in words:
    print('%s %s' % (word, flag))
		
		
		</pre>
		<p></p>
		<pre class="screen">
		
neo@MacBook-Pro-Neo ~/workspace/python % python3.9 /Users/neo/workspace/python/jieba/seg.py
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/2f/jfnljdpn1t1dj_f61z2s8bwm0000gn/T/jieba.cache
Loading model cost 0.753 seconds.
Prefix dict has been built successfully.
我 r
爱 v
北京 ns
天安门 ns
========================================
Paddle enabled successfully......
我 r
爱 v
北京 LOC
天安门 LOC		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528184320"></a>20.5.8. 词典管理</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm302528183680"></a>20.5.8.1. 添加/删除词语</h4></div></div></div>
			

			<pre class="programlisting">
		
import jieba

text = "他来到了网易杭研大厦"

words = jieba.cut(text, HMM=False)
print(", ".join(words))
print("-" * 50)
jieba.add_word('杭研大厦')  # 将 “杭研大厦” 添加到词典
jieba.add_word('来到了')  # 将 “来到了” 添加到词典
words = jieba.cut(text, HMM=False)
print(", ".join(words))
print("-" * 50)
jieba.del_word('深圳')  # 将 “深圳” 从词典中删除
words = jieba.cut("我爱深圳", HMM=False)
print(", ".join(words))
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm302528181712"></a>20.5.8.2. 用户词典</h4></div></div></div>
			
			<p>自定义词典</p>
			<pre class="programlisting">
			
import jieba

jieba.load_userdict('dict.txt') # 载入用户词典
seg_list = jieba.cut("他来到了网易杭研大厦", HMM=False)  
print(", ".join(seg_list))

			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm302528180000"></a>20.5.8.3. 自定义词库</h4></div></div></div>
			
			<p>分词系统默认使用自带的词库，load_userdict 是在默认词库的基础上做加法操作。</p>
			<p>set_dictionary 是设置默认基础词库。</p>
			<pre class="programlisting">
			
# encoding=utf-8
import jieba
jieba.set_dictionary('dict.txt')
seg_list = jieba.cut("转载请与作者联系，同时请务必标明文章原始出处和作者信息及本声明。")
print(seg_list)
print(", ".join(seg_list))			
			
			</pre>
			<p>dict.txt</p>
			<pre class="programlisting">
			
请务必 12 n
作者信息 10 n			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528176592"></a>20.5.9. 抽取文本标签</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm302528175920"></a>20.5.9.1. 提取标签</h4></div></div></div>
			
			<pre class="screen">
		
方法参数：
jieba.analyse.extract_tags(sentence, topK=5, withWeight=True, allowPOS=())
参数说明：
sentence 需要提取的字符串，必须是str类型，不能是list
topK 提取前多少个关键字
withWeight 是否返回每个关键词的权重
allowPOS是允许的提取的词性，默认为allowPOS=‘ns’, ‘n’, ‘vn’, ‘v’，提取地名、名词、动名词、动词	
		
			</pre>
			<pre class="programlisting">
			
file = open('article.txt', 'r', encoding='utf-8')
contents = file.read()
print(jieba.analyse.extract_tags(sentence=contents, topK=20, allowPOS=('ns', 'n')))			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm302528173584"></a>20.5.9.2. 基于 TextRank 算法的关键词抽取</h4></div></div></div>
			
			<pre class="programlisting">
			
import jieba.analyse
import jieba
import os

os.chdir('jieba')
file = open('article.txt', 'r', encoding='utf-8')
contents = file.read()
print(jieba.analyse.textrank(sentence=contents, topK=20, allowPOS=('ns', 'n')))			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm302528171936"></a>20.5.10. 返回词语在原文的起止位置</h3></div></div></div>
		
		<pre class="programlisting">
		
import jieba
import logging
logger = logging.getLogger()
jieba.default_logger = logger
text = u'大和服装饰品有限公司'
result = jieba.tokenize(text)
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0], tk[1], tk[2]))
print("-" * 50)
result = jieba.tokenize(text, mode='search')  # 搜索模式
for tk in result:
    print("word %s\t\t start: %d \t\t end:%d" % (tk[0], tk[1], tk[2]))
		
		
		</pre>
		<p></p>
		<pre class="screen">
		
		
		
		</pre>
	</div>
</div><div xmlns="" id="SOHUCS"></div><script xmlns="" charset="utf-8" type="text/javascript" src="https://cy-cdn.kuaizhan.com/upload/changyan.js"></script><script xmlns="" type="text/javascript">
			window.changyan.api.config({
			appid: 'cyvwjQUG3',
			conf: 'prod_ef966242df3d8b5acb1e0ee9fc01cafe'
			});
</script><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ch20s04.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="wordcloud.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">20.4. 常用的 Python 分词库 </td><td width="20%" align="center"><a accesskey="h" href="../../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 20.6. wordcloud</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>