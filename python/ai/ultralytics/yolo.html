<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>11.4. YOLO</title><link rel="stylesheet" type="text/css" href="../../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../../index.html" title="Netkiller Python 手札" /><link rel="up" href="index.html" title="第 11 章 Ultralytics" /><link rel="prev" href="ultralytics.task.html" title="11.3. Task 任务" /><link rel="next" href="ch11s05.html" title="11.5. ONNX(Open Neural Network Exchange) 开放神经网络交换格式" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">11.4. YOLO</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ultralytics.task.html">上一页</a> </td><th width="60%" align="center">第 11 章 Ultralytics</th><td width="20%" align="right"> <a accesskey="n" href="ch11s05.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="yolo"></a>11.4. YOLO</h2></div></div></div>
	
	<div class="orderedlist"><p class="title"><strong>目标检测任务</strong></p><ol class="orderedlist" type="1"><li class="listitem">YOLO11：用于经典的目标检测任务。</li><li class="listitem">YOLO11-seg：用于实例分割，识别和分割图像中的对象。</li><li class="listitem">YOLO11-pose：用于关键点姿态估计，即确定人体的关键点（如关节位置）。</li><li class="listitem">YOLO11-obb：用于定向检测，可以识别并确定具有方向性物体的边界框（例如倾斜的目标物体）。</li><li class="listitem">YOLO11-cls：用于分类，负责对图像中的对象进行类别识别。</li></ol></div>
	<div class="orderedlist"><p class="title"><strong>模型规格</strong></p><ol class="orderedlist" type="1"><li class="listitem">YOLOv8 Nano	非常小	YOLOv8n</li><li class="listitem">YOLOv8 Small	小	YOLOv8s</li><li class="listitem">YOLOv8 Medium	中	YOLOv8m</li><li class="listitem">YOLOv8 Large	大	YOLOv8l</li><li class="listitem">YOLOv8 X（Extra Large）	非常大	YOLOv8x</li></ol></div>
	
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1047"></a>11.4.1. labels 文件格式</h3></div></div></div>
		
		<p>x,y是目标的中心坐标，width,height是目标的宽和高。</p>
		<pre class="screen">
		
&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;		
		
		</pre>
		<p>VOC与YOLO之间的格式转换</p>
		<pre class="programlisting">
		
# size是原图的（w,h), box是坐标

def voc_to_yolo(size, box):
    dw = 1./size[0]
    dh = 1./size[1]
    x = (box[0] + box[1])/2.0
    y = (box[2] + box[3])/2.0
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    return (x,y,w,h)
 
def yolo_to_voc(size, box):
    x = box[0] * size[0]
    w = box[2] * size[0]
    y = box[1] * size[1]
    h = box[3] * size[1]
    xmin = int(x - w/2)
    xmax = int(x + w/2)
    ymin = int(y - h/2)
    ymax = int(y + h/2)
    return (xmin, ymin, xmax, ymax)
		
		
		</pre>
	</div>
	
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1048"></a>11.4.2. 模型训练</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO
# 指定模型
mode = YOLO('yolo11n-seg.pt')
# 让模型开始训练
mode.train(data='dataset.yaml',workers=0,epochs=10,batch=10)
# 验证模型
mode.val()		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1049"></a>11.4.3. 模型评估</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO
# ---------- 加载模型 ----------
model = YOLO('runs/detect/train/weights/best.pt')
# ---------- 模型评估 ----------
model.val(data='captcha/images/YOLODataset/dataset.yaml')
		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1054"></a>11.4.4. 模型预测</h3></div></div></div>
		
		<pre class="programlisting">
		
from ultralytics import YOLO

# 加载预训练的YOLOv11n模型
model = YOLO("yolo11n.pt")  # yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11x.pt

# 对'bus.jpg'图像进行推理，并获取结果 https://ultralytics.com/images/bus.jpg
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    result.show()  # 显示结果型的架构
    print(boxes)
    print(probs)		
		
		</pre>
		<p>换一个模型，试试 yolo11n-seg.pt</p>
		<pre class="programlisting">
		
from ultralytics import YOLO

model = YOLO("yolo11n-seg.pt")
results = model.predict("https://ultralytics.com/images/bus.jpg", save=True, imgsz=320, conf=0.5)

# 处理返回的结果
for result in results:
    boxes = result.boxes  # 获取边界框信息
    probs = result.probs  # 获取分类概率
    print(boxes)
    print(probs)
    result.show()  # 显示结果型的架构		
		
		</pre>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1050"></a>11.4.4.1. predict 参数</h4></div></div></div>
			
			<pre class="programlisting">
			
from yolov8 import YOLO
 
# 加载预训练模型
model = YOLO('yolov8.pt')
 
# 执行预测
results = model.predict(
    source='path/to/image.jpg',  # 输入源，可以是图像路径、视频路径、摄像头索引等
    conf=0.5,                    # 置信度阈值，滤除低于该置信度的检测结果。
    iou=0.45,                    # NMS的交并比阈值，用于消除重叠的检测框。
    device='cuda',               # 使用GPU
    imgsz=(640, 640),            # 输入图像的尺寸，可以是单个整数（长宽相等）或元组（长和宽）。
    half=False,                  # 不使用半精度浮点数
    save_txt=True,               # 保存预测结果为文本文件
    save_conf=True,              # 在保存的文本文件中包含置信度
    save_crop=False,             # 不保存裁剪后的检测结果
    save_img=True,               # 保存带有检测框的图像
    classes=[0, 1, 2],           # 仅检测指定的类
    agnostic_nms=False,          # 不使用类别无关的NMS
    augment=False,               # 不使用数据增强
    visualize=False,             # 不可视化特征图
    project='runs/detect',       # 保存预测结果的项目目录
    name='exp',                  # 保存预测结果的子目录名称
    exist_ok=False,              # 不允许项目目录存在
    line_thickness=3,            # 绘制检测框的线条粗细
    hide_labels=False,           # 显示检测框的标签
    hide_conf=False              # 显示检测框的置信度
)
 
# 输出预测结果
print(results)
			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1051"></a>11.4.4.2. 返回结果</h4></div></div></div>
			
			<p>返回结果通常包含以下主要属性和方法：</p>
			<div class="literallayout"><p><br />
			<br />
1.boxes: 包含检测到的边界框信息的对象。<br />
2.scores: 包含每个检测目标的置信度分数。<br />
3.classes: 包含每个检测目标的类别索引。<br />
4.masks: 如果使用实例分割模型，包含分割掩码。<br />
5.keypoints: 如果使用关键点检测模型，包含关键点信息。<br />
6.orig_img: 原始输入图像。<br />
7.plot(): 用于可视化检测结果的方法。			<br />
			<br />
			</p></div>
			<p>boxes: </p>
			<div class="literallayout"><p><br />
			<br />
1.boxes.xyxy: 返回每个检测目标的边界框坐标，格式为 [x_min, y_min, x_max, y_max]。<br />
2.boxes.conf: 返回每个检测目标的置信度分数。<br />
3.boxes.cls: 返回每个检测目标的类别索引。			<br />
			<br />
			</p></div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1052"></a>11.4.4.3. 提取标签</h4></div></div></div>
			
			<pre class="programlisting">
			
from ultralytics import YOLO

# 加载模型
# model = YOLO("yolo11n.pt")
# model = YOLO('weights/last.pt')
model = YOLO('weights/best.pt')

# 模型预测，save=True 的时候表示直接保存yolov8的预测结果
results = model('images/0_5902.png')

# View results
for result in results:
    # 处理结果
    boxes = result.boxes  # 边界框结果
    masks = result.masks  # 分割掩码结果
    names = result.names
    keypoints = result.keypoints  # 关键点检测结果
    probs = result.probs  # 分类概率结果
    obb = result.obb  # 方向边界框结果（OBB）
    print(boxes)
    for box in boxes:
        print(names[int(box.cls)])
    result.show()  # 显示结果			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1053"></a>11.4.4.4. 保存识别图像</h4></div></div></div>
			
			<pre class="programlisting">
			
@app.post("/netkiller")
async def netkiller(file: bytes = File()):
    try:
        filename = f"tmp/{uuid.uuid4()}.png"
        print(filename)
        with open(filename, "wb") as f:
            f.write(file)

        results = model(filename) # , conf=0.45

        for result in results:
            boxes = result.boxes  # 获取边界框信息
            # probs = result.probs  # 获取分类概率
            names = result.names
            data = result.boxes.data
            print(boxes)
            # print(probs)
            if names is not None:
                labels = []
                for box in boxes:
                    label = names[int(box.cls)]
                    labels.append(label)
                    print(label)
                # result.show()  # 显示结果型的架构
                result.save(filename="tmp/test.png")

            if boxes is not None:
                image = Image.open(filename)
                # x0, y0, x1, y1 = map(int, boxes.xyxy[0])
                crop = tuple(map(int, boxes.xyxy[0]))

                region = image.crop(crop)
                region.save('tmp/neo.jpg')

            return {"label": labels}
    except Exception as e:
        log.error(e)
    return {"label": None}			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id1057"></a>11.4.5. 模型导出</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1055"></a>11.4.5.1. onnx 格式</h4></div></div></div>
			
			<pre class="screen">
			
(.venv) neo@Neo-Mac-mini netkiller % pip install onnx onnxslim -i https://pypi.tuna.tsinghua.edu.cn/simple		
			
			</pre>
			<pre class="programlisting">
			
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="onnx")

# 预测看下效果
onnx_model = YOLO("yolo11n.onnx", task="detect")
results = onnx_model("https://ultralytics.com/images/bus.jpg")
results[0].show()		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id1056"></a>11.4.5.2. engine 格式</h4></div></div></div>
			
			<pre class="programlisting">
			
from ultralytics import YOLO

model = YOLO("yolo11n.pt")
model.export(format="engine")
tensorrt_model = YOLO("yolo11n.engine", task="detect")
results = tensorrt_model("https://ultralytics.com/images/bus.jpg")
results[0].show()			
			
			</pre>
		</div>

	</div>
</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ultralytics.task.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ch11s05.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">11.3. Task 任务 </td><td width="20%" align="center"><a accesskey="h" href="../../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 11.5. ONNX(Open Neural Network Exchange) 开放神经网络交换格式</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>