<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>13.3. Transformer 和 Transforms 区别</title><link rel="stylesheet" type="text/css" href="../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="php,pear,pecl,phar, python, , " /><link rel="home" href="../index.html" title="Netkiller Python 手札" /><link rel="up" href="index.html" title="第 13 章 Transformer" /><link rel="prev" href="ch13s02.html" title="13.2. Transformer 和 Vision Transformer 最大区别是什么？" /><link rel="next" href="ch13s04.html" title="13.4. Swin Transformer" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">简体中文</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> | <a xmlns="" href="/journal/index.html">杂文</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">13.3. Transformer 和 Transforms 区别</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ch13s02.html">上一页</a> </td><th width="60%" align="center">第 13 章 Transformer</th><td width="20%" align="right"> <a accesskey="n" href="ch13s04.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id4177"></a>13.3. Transformer 和 Transforms 区别</h2></div></div></div>
		
		<p>学习人工智能避免不了会接触到 transformer 和 transforms
			开始以为是一个东西，结果发现是两个完全不同的东西。
		</p>
		<p>Transformer 是一种基于自注意力机制（self - attention
			mechanism）的神经网络架构。它主要用于处理序列数据，如自然语言处理中的句子。Transformer
			架构摒弃了传统的循环神经网络（RNN）和卷积神经网络（CNN）在序列处理中的一些局限。例如在机器翻译任务中，Transformer
			架构的模型（如著名的 BERT、GPT 系列）能够很好地理解句子中单词之间的语义关系，通过多头注意力机制（Multi - Head
			Attention）并行地计算序列中每个位置与其他位置的关联程度。
		</p>
		<p>Transforms
			是PyTorch类库中的一个模块，transforms通常是指一系列的数据转换操作。这些操作主要用于对图像数据进行预处理，例如调整图像的大小（Resize）、将图像转换为张量（ToTensor）、对图像进行归一化（Normalize）等。以图像分类任务为例，在将图像输入到卷积神经网络之前，需要通过transforms对图像进行预处理，使得图像数据符合网络的输入要求，提高模型的性能和训练效率。
		</p>
	</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ch13s02.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ch13s04.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">13.2. Transformer 和 Vision Transformer 最大区别是什么？ </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 13.4. Swin Transformer</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>