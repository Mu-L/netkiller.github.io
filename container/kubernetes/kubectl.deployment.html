<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>5.8. 部署管理</title><link rel="stylesheet" type="text/css" href="../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="qmeu,kvm,xen,openvz, docker, coreos,docker-compose, kubernetes,kubeadmin,kubectl, netkiller-devops" /><link rel="home" href="../index.html" title="Netkiller Container 手札" /><link rel="up" href="kubectl.html" title="第 5 章 Kubernetes 集群管理" /><link rel="prev" href="kubectl.serviceaccount.html" title="5.7. serviceaccount" /><link rel="next" href="kubectl.logs.html" title="5.9. 查看 pod 日志" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> |
		<a xmlns="" href="//netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="/journal/index.html">杂文</a> |
	    <a xmlns="" href="https://github.com/netkiller">Github</a> |
	    <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> |
   	    <a xmlns="" href="https://edu.51cto.com/lecturer/1703915.html">51CTO学院</a> |
	    <a xmlns="" href="https://edu.csdn.net/lecturer/6423">CSDN程序员研修院</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://cloud.tencent.com/developer/column/2078">腾讯云社区</a> |
	    <a xmlns="" href="https://yq.aliyun.com/u/netkiller/">阿里云栖社区</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">5.8. 部署管理</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="kubectl.serviceaccount.html">上一页</a> </td><th width="60%" align="center">第 5 章 Kubernetes 集群管理</th><td width="20%" align="right"> <a accesskey="n" href="kubectl.logs.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> ｜ <a href="https://www.zhihu.com/club/1241768772601950208">多维度架构</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="kubectl.deployment"></a>5.8. 部署管理</h2></div></div></div>
		
		<pre class="screen">
		
kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
kubectl get pods --namespace=kube-system		
		
		</pre>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="kubectl.pods"></a>5.8.1. Pod 管理</h3></div></div></div>
			
			<p>Pod 状态说明</p>
			<div class="itemizedlist"><p class="title"><strong>Pod 状态：</strong></p><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">
					Pending：Pod已经被创建，但还没有完成调度，或者说有一个或多个镜像正处于从远程仓库下载的过程。处在这个阶段的Pod可能正在写数据到etcd中、调度、pull镜像或启动容器。
				</li><li class="listitem">
					Pending：Pod已经被创建，但还没有完成调度，或者说有一个或多个镜像正处于从远程仓库下载的过程。处在这个阶段的Pod可能正在写数据到etcd中、调度、pull镜像或启动容器。
				</li><li class="listitem">Running：该Pod已经绑定到了一个节点上，Pod中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。
				</li><li class="listitem">Succeeded：Pod中的所有的容器已经正常的执行后退出，并且不会自动重启，一般会是在部署job的时候会出现。
				</li><li class="listitem">Failed：Pod中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。
				</li><li class="listitem">Unkonwn：APIServer无法正常获取到Pod对象的状态信息，通常是由于其无法与所在工作节点的kubelet通信所致。
				</li></ul></div>
			<p>Pod 错误的详细的说明</p>
			<pre class="screen">
		
状态						描述
CrashLoopBackOff		容器退出，kubelet正在将它重启
InvalidImageName		无法解析镜像名称
ImageInspectError		无法校验镜像
ErrImageNeverPull		策略禁止拉取镜像
ImagePullBackOff		正在重试拉取
RegistryUnavailable		连接不到镜像中心
ErrImagePull			通用的拉取镜像出错
CreateContainerConfigError	不能创建kubelet使用的容器配置
CreateContainerError	创建容器失败
m.internalLifecycle.PreStartContainer	执行hook报错
RunContainerError		启动容器失败
PostStartHookError		执行hook报错
ContainersNotInitialized	容器没有初始化完毕
ContainersNotRead		容器没有准备完毕
ContainerCreating		容器创建中
PodInitializing	pod 	初始化中
DockerDaemonNotReady	docker还没有完全启动
NetworkPluginNotReady	网络插件还没有完全启动		
		
			</pre>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm40101756080"></a>5.8.1.1. 查看 POD 状态</h4></div></div></div>
				
				<p></p>
				<pre class="screen">
			
kubectl get pod &lt;pod-name&gt; -o wide		
kubectl get pods --all-namespaces			
			
				</pre>
				<p>查看默认命名空间下的 pod</p>
				<pre class="screen">
			 
[root@localhost ~]# kubectl get pod
NAME                              READY   STATUS    RESTARTS   AGE
hello-minikube-5c856cbf98-6vfvp   1/1     Running   0          6m59s
			
				</pre>
				<p>查看所有命名空间下的 Pod</p>
				<pre class="screen">
						
[root@localhost ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE
default       hello-minikube-5c856cbf98-6vfvp        1/1     Running   1          4d18h
kube-system   coredns-86c58d9df4-2rfqf               1/1     Running   51         4d18h
kube-system   coredns-86c58d9df4-wkb7l               1/1     Running   49         4d18h
kube-system   etcd-minikube                          1/1     Running   12         4d18h
kube-system   kube-addon-manager-minikube            1/1     Running   11         4d18h
kube-system   kube-apiserver-minikube                1/1     Running   74         4d18h
kube-system   kube-controller-manager-minikube       1/1     Running   31         4d18h
kube-system   kube-proxy-brrdd                       1/1     Running   1          4d18h
kube-system   kube-scheduler-minikube                1/1     Running   31         4d18h
kube-system   kubernetes-dashboard-ccc79bfc9-dxcq2   1/1     Running   7          4d17h
kube-system   storage-provisioner                    1/1     Running   2          4d18h		
		
				</pre>
				<pre class="screen">
			
iMac:~ neo$ kubectl get pods --output=wide
NAME                        READY   STATUS             RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATES
registry-65854b565b-bkhvq   0/1     ImagePullBackOff   0          18m   172.17.0.4   minikube   &lt;none&gt;           &lt;none&gt;
			
			
				</pre>
				<p>查看pod标签</p>
				<pre class="screen">
			
kubectl get pods --show-labels			
			
				</pre>
				<p>查看指定标签的pod</p>
				<pre class="screen">
			
kubectl get pods -l run=nginx			
			
				</pre>
				<p>指定命名空间</p>
				<pre class="screen">
		
[root@localhost ~]# kubectl get pod --namespace=kube-system
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-86c58d9df4-2rfqf               1/1     Running   0          40m
coredns-86c58d9df4-wkb7l               1/1     Running   0          40m
etcd-minikube                          1/1     Running   0          40m
kube-addon-manager-minikube            1/1     Running   0          41m
kube-apiserver-minikube                1/1     Running   2          40m
kube-controller-manager-minikube       1/1     Running   6          40m
kube-proxy-brrdd                       1/1     Running   0          40m
kube-scheduler-minikube                1/1     Running   5          41m
kubernetes-dashboard-ccc79bfc9-dxcq2   1/1     Running   5          16m
storage-provisioner                    1/1     Running   0          39m		
		
				</pre>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idm40101748768"></a>格式化输出</h5></div></div></div>
					
					<pre class="screen">
			
neo@Netkiller-iMac ~&gt; kubectl get pods -l app=nacos -o jsonpath='{.items[0].metadata.name}'
nacos-0⏎   			
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idm40101746560"></a>查看 pod 下面容器</h5></div></div></div>
					
					<p></p>
					<pre class="screen">
			
root@logging ~# kubectl --kubeconfig=/home/prod/.kube/config -n netkiller get pod neo-6787cfcb9-8s8pp -o jsonpath="{.spec.containers[*].name}"
filebeat neo  
			
					</pre>
				</div>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm40101755824"></a>5.8.1.2. 运行 POD</h4></div></div></div>
				
				<pre class="screen">
			
iMac:kubernetes neo$ kubectl run registry --image=registry:latest			
			
				</pre>
				<p></p>
				<pre class="screen">
			
kubectl run busybox --image=busybox --command -- ping www.netkiller.cn			
			
				</pre>
				<p></p>
				<pre class="screen">
			
kubectl run nginx --replicas=3 --labels="app=example" --image=nginx:latest --port=80			
			
				</pre>
				<p></p>
				<pre class="screen">
			
kubectl run busybox --rm=true --image=busybox --restart=Never -it			
			
				</pre>
			</div>

			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm40101741696"></a>5.8.1.3. 删除 pod</h4></div></div></div>
				
				<pre class="screen">
			
kubectl delete -n default pod registry	
kubectl delete -n default pod counter			
			
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="kubectl.describe"></a>5.8.1.4. 查看 Pod 的事件</h4></div></div></div>
				
				<pre class="screen">
		
kubectl describe pod &lt;pod-name&gt; 		
		
				</pre>
				<pre class="screen">
		
iMac:~ neo$ kubectl describe pod springboot
Name:         springboot
Namespace:    default
Priority:     0
Node:         minikube/192.168.64.2
Start Time:   Mon, 21 Sep 2020 16:17:03 +0800
Labels:       run=springboot
Annotations:  &lt;none&gt;
Status:       Pending
IP:           
IPs:          &lt;none&gt;
Containers:
  springboot:
    Container ID:   
    Image:          127.0.0.1:5000/netkiller/config:latest
    Image ID:       
    Port:           8888/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fhfn8 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-fhfn8:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-fhfn8
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  80s   default-scheduler  Successfully assigned default/springboot to minikube
  Normal  Pulling    79s   kubelet            Pulling image "127.0.0.1:5000/netkiller/config:latest"		
		
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idm40101738560"></a>5.8.1.5. Taint（污点）和 Toleration（容忍）</h4></div></div></div>
				
				<p>其目的是分配 pod 在集群间的调度，Taint 和 toleration 相互配合，可以用来避免 pod
					被分配到某个节点上。这跟节点亲和性作用相反。
				</p>
				<p>给 node 节点设置 label，通过给 pod 设置 nodeSelector 将 pod 调度到匹配标签的节点上。
				</p>
				<p>如果设置 toleration 应用于 pod 上，则表示 pod 可以被调度到 taint 的节点上。</p>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idm40101736176"></a>Taint（污点）设置</h5></div></div></div>
					
					<p>设置污点: kubectl taint node [node] key=value:[effect]</p>
					<div class="orderedlist"><p class="title"><strong>effect 参数</strong></p><ol class="orderedlist" type="1"><li class="listitem">NoSchedule ：不能被调度。</li><li class="listitem">PreferNoSchedule：尽量不要调度。</li><li class="listitem">NoExecute：不允许该节点有 Pod。</li></ol></div>
					<p>在 shenzhen 节点上设置Taint，键为key，值为value，effect是NoSchedule。</p>
					<pre class="screen">
				
kubectl taint nodes shenzhen key=value:NoSchedule
				
					</pre>
					<p>这意味着除非pod只有明确声明toleration可以容忍这个Taint，否则就不会被调度到该节点。</p>
					<pre class="screen">
				
apiVersion: v1
kind: Pod
metadata:
  name: pod-taints
spec:
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"
  containers:
    - name: pod-taints
      image: busybox:latest				
				
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idm40101730912"></a>Toleration（容忍）调度</h5></div></div></div>
					
					<p>key 存在即可匹配</p>
					<pre class="screen">
				
spec:
  tolerations:
  - key: "key"
    operator: "Exists"
    effect: "NoSchedule"				
				
					</pre>
					<p>key 必须存在，并且值等 value</p>
					<pre class="screen">
				
spec:
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"				
				
					</pre>
					<p>在pod上设置多个toleration：</p>
					<pre class="screen">
				
spec:				
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoSchedule"
  - key: "key2"
    operator: "Equal"
    value: "value2"
    effect: "NoExecute"				
				
					</pre>
					<p>如果给node加上Taint
						effect=NoExecute的，该节点上的没有设置toleration的pod都会被立刻驱逐，设置
						tolerationSeconds 后会给 Pod 一个宽限期。
					</p>
					<pre class="screen">
				
spec:		
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"
    tolerationSeconds: 3600
				
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="idm40101726128"></a>使用场景</h5></div></div></div>
					
					<p>例如有些节点上挂了SSD，给redis,mongodb,mysql 使用，有些节点上安装了显卡GPU。就可以使用 taint
					</p>
					<pre class="screen">
				
kubectl taint nodes shenzhen special=true:NoSchedule
kubectl taint nodes guangdong special=true:PreferNoSchedule				
				
					</pre>
				</div>
			</div>
			<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="Pod"></a>5.8.1.6. Pod</h4></div></div></div>
				
				<pre class="screen">
		
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c, 'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']		
		
				</pre>
				<p>创建 pod</p>
				<pre class="screen">
		
iMac:kubernetes neo$ kubectl create -f pod.yaml 
pod/counter created

iMac:kubernetes neo$ kubectl logs counter
0: Sun Oct  4 12:32:44 UTC 2020
1: Sun Oct  4 12:32:45 UTC 2020
2: Sun Oct  4 12:32:46 UTC 2020
3: Sun Oct  4 12:32:47 UTC 2020
4: Sun Oct  4 12:32:48 UTC 2020
5: Sun Oct  4 12:32:49 UTC 2020
6: Sun Oct  4 12:32:50 UTC 2020
7: Sun Oct  4 12:32:51 UTC 2020
8: Sun Oct  4 12:32:52 UTC 2020
9: Sun Oct  4 12:32:53 UTC 2020
		
				</pre>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.spec.containers.imagePullPolicy"></a>容器编排</h5></div></div></div>
					
					<div class="section"><div class="titlepage"><div><div><h6 class="title"><a id="imagePullPolicy "></a>镜像拉取策略</h6></div></div></div>
						
						<p>imagePullPolicy: Always 总是拉取</p>
						<p>imagePullPolicy: IfNotPresent 默认值,本地有则使用本地镜像,不拉取</p>
						<p>imagePullPolicy: Never 只使用本地镜像，从不拉取</p>
					</div>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.spec.hostAliases"></a>指定主机名</h5></div></div></div>
					
					<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: hostaliases-pod
spec:
  restartPolicy: Never
  hostAliases:
  - ip: "127.0.0.1"
    hostnames:
    - "foo.local"
    - "bar.local"
  - ip: "10.1.2.3"
    hostnames:
    - "foo.remote"
    - "bar.remote"
  containers:
  - name: cat-hosts
    image: busybox
    command:
    - cat
    args:
    - "/etc/hosts"			
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.spec.containers.env"></a>环境变量</h5></div></div></div>
					
					<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: envars-fieldref
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ "sh", "-c"]
      args:
      - while true; do
          echo -en '\n';
          printenv NODE_NAME POD_NAME POD_NAMESPACE;
          printenv POD_IP POD_SERVICE_ACCOUNT;
          sleep 10;
        done;
      env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: POD_SERVICE_ACCOUNT
          valueFrom:
            fieldRef:
              fieldPath: spec.serviceAccountName
  restartPolicy: Never			
			
					</pre>
					<p></p>
					<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: envars-resourcefieldref
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox:1.24
      command: [ "sh", "-c"]
      args:
      - while true; do
          echo -en '\n';
          printenv CPU_REQUEST CPU_LIMIT;
          printenv MEM_REQUEST MEM_LIMIT;
          sleep 10;
        done;
      resources:
        requests:
          memory: "32Mi"
          cpu: "125m"
        limits:
          memory: "64Mi"
          cpu: "250m"
      env:
        - name: CPU_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: requests.cpu
        - name: CPU_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: limits.cpu
        - name: MEM_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: requests.memory
        - name: MEM_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: limits.memory
  restartPolicy: Never			
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.spec.containers.readinessProbe"></a>健康状态检查</h5></div></div></div>
					
					<p>就绪探针</p>
					<pre class="screen">
			
        readinessProbe: 
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 10         #10s之后开始第一次探测
          periodSeconds: 5                #第一次探测之后每隔5s探测一次			
			
					</pre>
					<p></p>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.spec.securityContext"></a>securityContext</h5></div></div></div>
					
					<div class="section"><div class="titlepage"><div><div><h6 class="title"><a id="idm40101709408"></a>sysctls</h6></div></div></div>
						
						<p></p>
						<pre class="screen">
				
kubelet --allowed-unsafe-sysctls \
  'kernel.msg*,net.core.somaxconn' ...				
				
						</pre>
						<pre class="screen">
				
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
spec:
  securityContext:
    sysctls:
    - name: kernel.shm_rmid_forced
      value: "0"
    - name: net.core.somaxconn
      value: "1024"
    - name: kernel.msgmax
      value: "65536"				
				
						</pre>
					</div>
					<div class="section"><div class="titlepage"><div><div><h6 class="title"><a id="idm40101707344"></a>runAsUser</h6></div></div></div>
						
						<p>allowPrivilegeEscalation 表示是否继承父进程权限，runAsUser 表示使用 UID 1000 的用户运行</p>
						<pre class="screen">
				
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000
  containers:
  - name: sec-ctx-demo
    image: busybox:latest
    securityContext:
      runAsUser: 1000
      allowPrivilegeEscalation: false				
				
						</pre>
						<pre class="screen">
				
   spec:
     securityContext:
        runAsUser: 1000
        fsGroup: 2000
        runAsNonRoot: true				
				
						</pre>
					</div>

					<div class="section"><div class="titlepage"><div><div><h6 class="title"><a id="idm40101704896"></a>security.alpha.kubernetes.io/sysctls</h6></div></div></div>
						
						<p>security.alpha.kubernetes.io/sysctls</p>
						<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
  annotations:
    security.alpha.kubernetes.io/sysctls: kernel.shm_rmid_forced=1
spec:			
			
						</pre>
						<p>unsafe-sysctls</p>
						<pre class="screen">
			
apiVersion: v1
kind: Pod
metadata:
  name: sysctl-example
  annotations:
    security.alpha.kubernetes.io/unsafe-sysctls: net.core.somaxconn=65535                 #使用unsafe sysctl，设置最大连接数
spec:
  securityContext:
    privileged: true                                                                      #开启privileged权限			
			
						</pre>
					</div>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.nodeName"></a>nodeName 选择节点</h5></div></div></div>
					
					<p>首先查看节点名称</p>
					<pre class="screen">
			
[root@master ~]# kubectl get node
NAME      STATUS   ROLES                  AGE     VERSION
agent-1   Ready    &lt;none&gt;                 2d13h   v1.24.4+k3s1
master    Ready    control-plane,master   2d13h   v1.24.4+k3s1
agent-2   Ready    &lt;none&gt;                 13h     v1.24.4+k3s1			
			
					</pre>
					<p>使用 nodeName: master 选择节点</p>
					<pre class="screen">
			
metadata:
  name: redis
  labels:
    app: redis
spec:
  replicas: 1
  serviceName: redis
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
        - name: redis
          image: redis:latest
          ports:
            - containerPort: 6379
          volumeMounts:
            - name: data
              mountPath: /data
            - name: config
              mountPath: /usr/local/etc/redis.conf
              subPath: redis.conf
          livenessProbe:
            tcpSocket:
              port: 6379
            initialDelaySeconds: 60
            failureThreshold: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            tcpSocket:
              port: 6379
            initialDelaySeconds: 5
            failureThreshold: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: redis
        - name: config
          configMap:
            name: redis
      nodeName: master
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: longhorn
        resources:
          requests:
            storage: 2Gi
apiVersion: apps/v1
kind: StatefulSet			
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.nodeSelector"></a>nodeSelector 选择节点</h5></div></div></div>
					
					<p>首先给节点打标签，例如 disk-type=ssd</p>
					<pre class="screen">
			
[root@master ~]# kubectl label nodes agent-1 disk-type=ssd
node/agent-1 labeled			
			
					</pre>
					<p>查看标签</p>
					<pre class="screen">
			
[root@master ~]# kubectl get node --show-labels
NAME         STATUS   ROLES    AGE   VERSION   LABELS
master   Ready    master   42d   v1.17.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master,kubernetes.io/os=linux,node-role.kubernetes.io/master=
agent-1   Ready    &lt;none&gt;   42d   v1.17.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disk-type=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=agent-1,kubernetes.io/os=linux
agent-2   Ready    &lt;none&gt;   42d   v1.17.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=agent-2,kubernetes.io/os=linux			
			
					</pre>
					<p></p>
					<pre class="screen">
			
apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox
  labels:
    app: busybox
spec:
  replicas: 5
  selector:
    matchLabels:
      app: busybox
  template:
    metadata:
      labels:
        app: busybox
    spec:
      containers:
      - name: busybox
        image: busybox
        imagePullPolicy: IfNotPresent
        ports:
          - containerPort: 80
      # 指定标签节点
      nodeSelector:
        disk-type: ssd			
			
					</pre>
					<p>删除标签</p>
					<pre class="screen">
			
[root@master ~]# kubectl label nodes agent-1 disk-type-
node/agent-1 unlabeled		
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.nodeAffinity"></a>nodeAffinity 选择节点</h5></div></div></div>
					
					<pre class="screen">
			
nodeAffinity可对应的两种策略：
preferredDuringScheduling(IgnoredDuringExecution / RequiredDuringExecution) 软策略
requiredDuringScheduling(IgnoredDuringExecution / RequiredDuringExecution) 硬策略

operator 表达式
In: label的值在某个列表中
NotIn：label的值不在某个列表中
Exists：某个label存在
DoesNotExist：某个label不存在
Gt：label的值大于某个值（字符串比较）
Lt：label的值小于某个值（字符串比较）
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.taint"></a>Taint（污点）和 Toleration（容忍）</h5></div></div></div>
					
					<pre class="screen">
			
			
			
					</pre>
				</div>
				<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="pod.strategy"></a>strategy</h5></div></div></div>
					
					<p>滚动升级策略:</p>
					<p>超过期望的Pod数量:1</p>
					<p>不可用Pod最大数量:0</p>
					<pre class="screen">
			
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
			
					</pre>
					<pre class="screen">
			
  strategy:
      type: RollingUpdate
      rollingUpdate: {
        maxUnavailable: 25%
        maxSurge: 25%
			
					</pre>
				</div>
			</div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="kubectl.expose"></a>5.8.2. expose</h3></div></div></div>
			
			<p></p>
			<pre class="screen">
		
kubectl expose deployment nginx --port=88 --target-port=80 --type=NodePort --name=nginx-service	
kubectl describe service nginx-service	
		
			</pre>
			<pre class="screen">
		
将服务暴露出去，在服务前面加一个负载均衡，因为pod可能分布在不同的结点上。 
–port：暴露出去的端口 
–type=NodePort：使用结点+端口方式访问服务 
–target-port：容器的端口 
–name：创建service指定的名称		
		
			</pre>
			<pre class="screen">
		
kubectl expose deployment nginx --port=80 --target-port=8080 --type=NodePort
kubectl expose deployment nginx --port=80 --target-port=8080 --type=LoadBalancer	
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm40101684080"></a>5.8.3. </h3></div></div></div>
			
			<pre class="screen">
		
kubectl create deployment registry --image=registry:latest
kubectl get deploy		
		
			</pre>
		</div>


		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm40101683056"></a>5.8.4. 删除 deployment</h3></div></div></div>
			
			<pre class="screen">
			
kubectl delete deployment hello-minikube			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="kubectl.scale"></a>5.8.5. 资源管理</h3></div></div></div>
			
			<pre class="screen">
		
kubectl scale -n default deployment nginx --replicas=1	
kubectl scale deployment springbootdemo --replicas=4	
kubectl scale deployment nginx --replicas=10	
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="kubectl.rollout"></a>5.8.6. rollout</h3></div></div></div>
			
			<p>查看发布历史</p>
			<pre class="screen">
		
kubectl rollout history deployment/nginx		
		
			</pre>
			<p>指定版本号</p>
			<pre class="screen">
		
kubectl rollout history deployment/nginx --revision=3		
		
			</pre>
			<p>查看部署状态</p>
			<pre class="screen">
		
kubectl rollout status deployment/nginx		
		
			</pre>
			<p>回滚到上一个版本</p>
			<pre class="screen">
		
kubectl rollout undo deployment/nginx-deployment		
		
			</pre>
			<p>回滚到指定版本</p>
			<pre class="screen">
		
kubectl rollout undo deployment/nginx-deployment --to-revision=3		
		
			</pre>
		</div>
	</div><div xmlns="" id="SOHUCS"></div><script xmlns="" charset="utf-8" type="text/javascript" src="https://cy-cdn.kuaizhan.com/upload/changyan.js"></script><script xmlns="" type="text/javascript">
window.changyan.api.config({
appid: 'cyvwjQUG3',
conf: 'prod_ef966242df3d8b5acb1e0ee9fc01cafe'
});
</script><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="kubectl.serviceaccount.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="kubectl.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="kubectl.logs.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">5.7. serviceaccount </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 5.9. 查看 pod 日志</td></tr></table></div><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11694057-1', 'auto');
  ga('send', 'pageview');

</script><script xmlns="" async="async">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script xmlns="" async="async">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script></body></html>