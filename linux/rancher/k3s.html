<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>107.5.Â K3s</title><link rel="stylesheet" type="text/css" href="../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><meta name="keywords" content="&#10;&#9;&#9;&#9;&#9;bash,bunzip2,busybox,bzcat,bzcmp,bzdiff,bzegrep,bzexe,bzfgrep,bzgrep,bzip2,bzip2recover,bzless,bzmore,cat,chgrp,chmod,chown,chvt,cp,cpio,dash,date,dbus-cleanup-sockets,dbus-daemon,dbus-uuidgen,dd,df,dir,dmesg,dnsdomainname,domainname,dumpkeys,echo,ed,egrep,false,fgconsole,fgrep,fuser,fusermount,grep,gunzip,gzexe,gzip,hostname,ip,kbd_mode,kill,less,lessecho,lessfile,lesskey,lesspipe,ln,loadkeys,login,ls,lsmod,mkdir,mknod,mktemp,more,mount,mountpoint,mt,mt-gnu,mv,nano,nc,nc.openbsd,netcat,netstat,nisdomainname,ntfs-3g,ntfs-3g.probe,ntfs-3g.secaudit,ntfs-3g.usermap,open,openvt,pidof,ping,ping6,plymouth,ps,pwd,rbash,readlink,rm,rmdir,rnano,run-parts,sed,setfont,setupcon,sh,sh.distrib,sleep,static-sh,stty,su,sync,tailf,tar,tempfile,touch,true,ulockmgr_server,umount,uname,uncompress,unicode_start,vdir,which,ypdomainname,zcat,zcmp,zdiff,zegrep,zfgrep,zforce,zgrep,zless,zmore,znew,,/sbin/:,acpi_available,apm_available,apparmor_parser,badblocks,blkid,blockdev,bootlogd,cfdisk,crda,ctrlaltdel,debugfs,depmod,dhclient,dhclient3,dhclient-script,dmsetup,dosfsck,dosfslabel,dump,dumpe2fs,e2fsck,e2image,e2label,e2undo,ethtool,fdisk,findfs,fsck,fsck.cramfs,fsck.ext2,fsck.ext3,fsck.ext4,fsck.ext4dev,fsck.minix,fsck.msdos,fsck.nfs,fsck.vfat,fstab-decode,getty,halt,hdparm,hwclock,ifconfig,ifdown,ifquery,ifup,init,initctl,insmod,insserv,installkernel,ip,ip6tables,ip6tables-restore,ip6tables-save,ipmaddr,iptables,iptables-restore,iptables-save,iptunnel,isosize,iwconfig,iwevent,iwgetid,iwlist,iwpriv,iwspy,kbdrate,killall5,ldconfig,ldconfig.real,logsave,losetup,lsmod,MAKEDEV,mii-tool,mkdosfs,mke2fs,mkfs,mkfs.bfs,mkfs.cramfs,mkfs.ext2,mkfs.ext3,mkfs.ext4,mkfs.ext4dev,mkfs.minix,mkfs.msdos,mkfs.vfat,mkhomedir_helper,mkswap,modinfo,modprobe,mountall,mount.fuse,mount.nfs,mount.nfs4,mount.ntfs,mount.ntfs-3g,nameif,on_ac_power,pam_tally,parted,partprobe,pivot_root,plipconfig,plymouthd,pmap_dump,pmap_set,portmap,poweroff,rarp,raw,rdump,reboot,regdbdump,reload,resize2fs,restart,restore,rfkill,rmmod,route,rpc.statd,rrestore,rtacct,rtmon,runlevel,sfdisk,shadowconfig,showmount,shutdown,slattach,sm-notify,ss,start,startpar,start-stop-daemon,status,stop,sulogin,swapoff,swapon,switch_root,sysctl,tc,telinit,tune2fs,udevadm,udevd,umount.nfs,umount.nfs4,unix_chkpwd,unix_update,upstart-udev-bridge,ureadahead,wipefs,wpa_action,wpa_cli,wpa_supplicant&#10;&#9;&#9;&#9;, &#10;&#9;&#9;&#9;&#9;a2p,acyclic,addftinfo,addpart,afmtodit,animate,anytopnm,apg,apgbfm,apport-bug,apport-cli,apport-collect,apport-unpack,apropos,apt-cache,apt-cdrom,apt-config,apt-extracttemplates,apt-ftparchive,apt-get,aptitude,aptitude-create-state-bundle,aptitude-run-state-bundle,apt-key,apt-mark,apt-sortpkgs,arch,arping,asciitopgm,at,atktopbm,atq,atrm,awk,base64,basename,bashbug,batch,bc,bcomps,bconsole,bdftopcf,bdftops,bdftruncate,bioradtopgm,bmptopnm,bmptoppm,brushtopbm,bsd-mailx,bsd-write,byobu,byobu-config,byobu-export,byobu-janitor,byobu-launch,byobu-launcher,byobu-launcher-install,byobu-launcher-uninstall,byobu-reconnect-sockets,byobu-select-profile,byobu-select-session,byobu-status,byobu-status-detail,c2ph,cal,calendar,captoinfo,catchsegv,catman,cautious-launcher,ccomps,chage,chattr,chcon,check-bios-nx,check-language-support,chem,chfn,chkdupexe,chrt,chsh,circo,ckbcomp,ck-history,ck-launch-session,ck-list-sessions,cksum,clear,clear_console,cmp,cmuwmtopbm,codepage,col,colcrt,colrm,column,comm,compare,compose,composite,config_data,conjure,convert,corelist,cpan,cpan2dist,cpanp,cpanp-run-perl,cpp,cpp-4.4,createrepo,c_rehash,crontab,csplit,ctstat,curl,curlftpfs,cut,dbilogstrip,dbiprof,dbiproxy,dbmmanage,dbus-monitor,dbus-send,ddate,deallocvt,debconf,debconf-apt-progress,debconf-communicate,debconf-copydb,debconf-escape,debconf-set-selections,debconf-show,defoma,defoma-app,defoma-font,defoma-hints,defoma-id,defoma-psfont-installer,defoma-subst,defoma-user,delpart,dh_bash-completion,dh_installdefoma,dh_installxmlcatalogs,dh_pycentral,dh_pysupport,dialog,diff,diff3,diffimg,dig,dijkstra,dircolors,dirname,display,do-release-upgrade,dot,dot2gxl,dotlockfile,dotty,dpkg,dpkg-deb,dpkg-divert,dpkg-query,dpkg-split,dpkg-statoverride,dpkg-trigger,dprofpp,du,dumphint,dumpkeys,dvipdf,easy_install,easy_install-2.6,edit,editor,eject,enc2xs,encode_keychange,env,envsubst,eps2eps,epsffit,eqn,eqn2graph,ex,expand,expiry,expr,extractres,eyuvtoppm,factor,faillog,fallocate,fc-cache,fc-cat,fc-list,fc-match,fc-query,fc-scan,fdp,fiascotopnm,file,find,find2perl,findsmb,fitstopnm,fixdlsrps,fixfmps,fixmacps,fixproc,fixpsditps,fixpspps,fixscribeps,fixtpps,fixwfwps,fixwpps,fixwwps,flock,flow-capture,flow-cat,flow-dscan,flow-expire,flow-export,flow-fanout,flow-filter,flow-gen,flow-header,flow-import,flow-log2rrd,flow-mask,flow-merge,flow-nfilter,flow-print,flow-receive,flow-report,flow-rpt2rrd,flow-rptfmt,flow-send,flow-split,flow-stat,flow-tag,flow-xlate,fmt,fold,font2c,fontconfig-voodoo,fonttosfnt,fping,fping6,free,fribidi,from,fstopgm,ftp,funzip,g3topbm,gawk,gc,gdiffmk,gdk-pixbuf-query-loaders,gemtopbm,gemtopnm,gendiff,geqn,GET,getafm,getconf,getent,getkeycodes,getopt,gettext,gettext.sh,ghostscript,giftopnm,ginstall-info,gio-querymodules,git,git-receive-pack,git-shell,git-upload-archive,git-upload-pack,gmetric,gnokii,gnuplot,gnuplot-nox,gouldtoppm,gpasswd,gpg,gpgsplit,gpgv,gpg-zip,gpic,grap2graph,grn,grodvi,groff,groffer,grog,grolbp,grolj4,grops,grotty,groups,grub-bin2h,grub-editenv,grub-fstest,grub-mkelfimage,grub-mkfont,grub-mkimage,grub-mkisofs,grub-mkpasswd-pbkdf2,grub-mkrelpath,grub-mkrescue,grub-script-check,gs,gsbj,gsdj,gsdj500,gslj,gslp,gsnd,gstat,gtbl,gtk-query-immodules-2.0,gtk-update-icon-cache,gvcolor,gvimtutor,gvpack,gvpr,gxditview,gxl2dot,h2ph,h2xs,hd,head,HEAD,helpztags,hexdump,hipstopgm,host,hostid,hpftodit,htdbm,htdigest,htpasswd,i386,icontopbm,iconv,id,identify,igawk,ilbmtoppm,imgtoppm,import,includeres,indexer,indxbib,info,infobrowser,infocmp,infokey,infotocap,innochecksum,innotop,install,install-info,instmodsh,ionice,iostat,ipcmk,ipcrm,ipcs,ipmicmd,ipmilan,ipmish,ipmitool,ipmi_ui,iptables-xml,join,jpegtopnm,killall,kvm-ok,l4p-tmpl,landscape-sysinfo,last,lastb,lastlog,lcf,ldd,leaftoppm,lefty,less,lessecho,lessfile,lesskey,lesspipe,lexgrog,libnetcfg,line,link,linux32,linux64,linux-boot-prober,lispmtopgm,lkbib,lneato,lnstat,loadkeys,loadunimap,locale,localedef,locate,lockfile-check,lockfile-create,lockfile-remove,lockfile-touch,logger,logname,look,lookbib,lorder,lsattr,lsb_release,lscpu,lshw,lsof,lspci,lspgpot,lsusb,ltrace,lwp-download,lwp-dump,lwp-mirror,lwp-request,lwp-rget,lzcat,lzma,macptopbm,mail,Mail,mail-lock,mailq,mail-touchlock,mail-unlock,mailx,make,make-memtest86+-boot-floppy,make_method,man,mandb,manhole,manpath,mapscrn,mawk,mcookie,md5sum,md5sum.textutils,mdatopbm,memcached,mesg,mgrtopbm,mkfifo,mkfontdir,mkfontscale,mk_modmap,mktap,mlocate,mmroff,modifyrepo,mogrify,montage,motd+shell,mpstat,msql2mysql,mtr,mtvtoppm,munin-check,munin-cron,munindoc,mutt,mutt_dotlock,myisamchk,myisam_ftdump,myisamlog,myisampack,my_print_defaults,mysql,mysqlaccess,mysqladmin,mysqlanalyze,mysqlbinlog,mysqlbug,mysqlcheck,mysql_client_test,mysql_client_test_embedded,mysql_convert_table_format,mysqld_multi,mysqld_safe,mysqldump,mysqldumpslow,mysql_find_rows,mysql_fix_extensions,mysql_fix_privilege_tables,mysqlhotcopy,mysqlimport,mysql_install_db,mysqloptimize,mysqlrepair,mysqlreport,mysql_secure_installation,mysql_setpermission,mysqlshow,mysqlslap,mysqltest,mysqltest_embedded,mysql_tzinfo_to_sql,mysql_upgrade,mysql_waitpid,mysql_zap,mytop,namei,nano,nawk,ncal,ncat,ncftp,ncftp3,ncftpbatch,ncftpbookmarks,ncftpget,ncftpls,ncftpput,ncftpspooler,ncurses5-config,ncursesw5-config,ndiff,neato,neotoppm,neqn,net,netkit-ftp,net.samba3,net-snmp-config,netstat-nat,newaliases,newgrp,ngettext,nice,nl,nmap,nmblookup,nmblookup.samba3,nmon,nohup,nop,nroff,nslookup,nstat,nsupdate,od,oldfind,omshell,on_ac_power,openipmicmd,openipmish,openssl,openssl-vulnkey,os-prober,pager,palmtopnm,pamcut,pamdeinterlace,pamdice,pamfile,pamoil,pamstack,pamstretch,pamstretch-gen,paperconf,parsechangelog,partx,passwd,paste,patch,pathchk,pbmclean,pbmlife,pbmmake,pbmmask,pbmpage,pbmpscale,pbmreduce,pbmtext,pbmtextps,pbmto10x,pbmtoascii,pbmtoatk,pbmtobbnbg,pbmtocmuwm,pbmtoepsi,pbmtoepson,pbmtog3,pbmtogem,pbmtogo,pbmtoicon,pbmtolj,pbmtomacp,pbmtomda,pbmtomgr,pbmtonokia,pbmtopgm,pbmtopi3,pbmtoplot,pbmtoppa,pbmtopsg3,pbmtoptx,pbmtowbmp,pbmtox10bm,pbmtoxbm,pbmtoybm,pbmtozinc,pbmupc,pcimodules,pcretest,pcxtoppm,pdb,pdb2.6,pdb3,pdb3.1,pdf2dsc,pdf2ps,pdfopt,pdfroff,pear,peardev,pecl,peekfd,perl,perl5.10.1,perlbug,perldoc,perlivp,perlthanks,perror,pf2afm,pfbtopfa,pfbtops,pfc,pftp,pg,pgawk,pgmbentley,pgmcrater,pgmedge,pgmenhance,pgmhist,pgmkernel,pgmnoise,pgmnorm,pgmoil,pgmramp,pgmslice,pgmtexture,pgmtofs,pgmtolispm,pgmtopbm,pgmtoppm,pgrep,php,php5,pi1toppm,pi3topbm,pic,pic2graph,pico,piconv,pidstat,pinky,pip,pjtoppm,pkill,pl2pm,plog,pmap,pngtopnm,pnmalias,pnmarith,pnmcat,pnmcolormap,pnmcomp,pnmconvol,pnmcrop,pnmcut,pnmdepth,pnmenlarge,pnmfile,pnmflip,pnmgamma,pnmhisteq,pnmhistmap,pnmindex,pnminterp,pnminterp-gen,pnminvert,pnmmargin,pnmmontage,pnmnlfilt,pnmnoraw,pnmnorm,pnmpad,pnmpaste,pnmpsnr,pnmquant,pnmremap,pnmrotate,pnmscale,pnmscalefixed,pnmshear,pnmsmooth,pnmsplit,pnmtile,pnmtoddif,pnmtofiasco,pnmtofits,pnmtojpeg,pnmtopalm,pnmtoplainpnm,pnmtopng,pnmtops,pnmtorast,pnmtorle,pnmtosgi,pnmtosir,pnmtotiff,pnmtotiffcmyk,pnmtoxwd,pod2html,pod2latex,pod2man,pod2text,pod2usage,podchecker,podselect,poff,pon,POST,post-grohtml,ppm3d,ppmbrighten,ppmchange,ppmcie,ppmcolormask,ppmcolors,ppmdim,ppmdist,ppmdither,ppmfade,ppmflash,ppmforge,ppmhist,ppmlabel,ppmmake,ppmmix,ppmnorm,ppmntsc,ppmpat,ppmquant,ppmquantall,ppmqvga,ppmrainbow,ppmrelief,ppmshadow,ppmshift,ppmspread,ppmtoacad,ppmtobmp,ppmtoeyuv,ppmtogif,ppmtoicr,ppmtoilbm,ppmtojpeg,ppmtoleaf,ppmtolj,ppmtomap,ppmtomitsu,ppmtompeg,ppmtoneo,ppmtopcx,ppmtopgm,ppmtopi1,ppmtopict,ppmtopj,ppmtopuzz,ppmtorgb3,ppmtosixel,ppmtotga,ppmtouil,ppmtowinicon,ppmtoxpm,ppmtoyuv,ppmtoyuvsplit,ppmtv,pr,preconv,pre-grohtml,prename,print,printafm,printenv,printerbanner,printf,prove,prtstat,prune,ps2ascii,ps2epsi,ps2pdf,ps2pdf12,ps2pdf13,ps2pdf14,ps2pdfwr,ps2ps,ps2ps2,ps2txt,psbook,psed,psfaddtable,psfgettable,psfstriptable,psfxtable,psidtopgm,psmerge,psnup,psresize,psselect,pstopnm,pstops,pstree,pstree.x11,pstruct,ptar,ptardiff,ptx,pwdx,py3_compilefiles,pycentral,pyclean,pycompile,py_compilefiles,pydoc,pydoc2.6,pydoc3,pydoc3.1,pygettext,pygettext2.6,pygettext3,pygettext3.1,pyhtmlizer,python,python2,python2.6,python3,python3.1,pyversions,qrttoppm,rasttopnm,rawtopgm,rawtoppm,rcp,red,refer,rename,rename.ul,renice,replace,report-hw,reset,resolveip,resolve_stack_dump,rev,rgb3toppm,rgrep,rletopnm,rlogin,rmcp_ping,roff2dvi,roff2html,roff2pdf,roff2ps,roff2text,roff2x,routef,routel,rpcclient,rpcinfo,rpm,rpm2cpio,rpmbuild,rpmdb,rpmgraph,rpmquery,rpmsign,rpmverify,rrdcgi,rrdtool,rrdupdate,rsh,rsync,rtstat,runcon,run-mailcap,rview,rvim,s2p,sadf,sar,sar.sysstat,savelog,sbigtopgm,sccmap,scp,screen,screendump,screen-launcher,screen-profiles-status,script,scriptreplay,sdiff,search,searchd,see,select-editor,sendsms,sensible-browser,sensible-editor,sensible-pager,sensors,sensors-conf-convert,seq,service,setarch,setkeycodes,setleds,setlogcons,setmetamode,setpci,setsid,setterm,sftp,sg,sgitopnm,sha1sum,sha224sum,sha256sum,sha384sum,sha512sum,shasum,showchar,showconsolefont,showkey,shred,shuf,sirtopnm,skill,slabtop,sldtoppm,slogin,smbcacls,smbclient,smbcquotas,smbget,smbpasswd,smbspool,smbtar,smbtree,smime_keys,snice,snmpbulkget,snmpbulkwalk,snmpconf,snmpdelta,snmpdf,snmpget,snmpgetnext,snmpinform,snmpkey,snmpnetstat,snmpset,snmpstatus,snmptable,snmptest,snmptranslate,snmptrap,snmpusm,snmpvacm,snmpwalk,soelim,solterm,sort,spctoppm,spelldump,splain,split,splitfont,sputoppm,ssh,ssh-add,ssh-agent,ssh-argv0,ssh-copy-id,sshfs,ssh-keygen,ssh-keyscan,ssh-vulnkey,st4topgm,stat,strace,stream,sudo,sudoedit,sum,svn,svnadmin,svnauthz-validate,svndumpfilter,svnlook,svnmucc,svn-populate-node-origins-index,svnserve,svnsync,svnversion,tabs,tac,tail,tap2deb,tap2rpm,tapconvert,tasksel,taskset,tbl,tee,telnet,telnet.netkit,test,testparm,testparm.samba3,tfmtodit,tgatoppm,thinkjettopbm,tic,tifftopnm,time,tload,toe,top,touch,tput,tr,tracepath,tracepath6,traceroute6,traceroute6.iputils,traptoemail,tred,trial,troff,truncate,tset,tsort,tty,twistd,twopi,tzselect,ubuntu-bug,ubuntu-support-status,ucf,ucfq,ucfr,ucs2any,ul,unattended-upgrade,unattended-upgrades,unexpand,unflatten,unicode_stop,uniq,unlink,unlzma,unshare,unzip,unzipsfx,update-alternatives,updatedb,updatedb.mlocate,update-mime-database,update-mime-database.real,update-pciids,update-perl-sax-parsers,uptime,usb-devices,users,uuidgen,vi,view,vim,vim.basic,vimdiff,vim.tiny,vimtutor,vmstat,volname,w,w3m,w3mman,wall,watch,wbmptopbm,wc,webalizer,webazolver,wftopfa,wget,whatis,whereis,which,whiptail,who,whoami,winicontoppm,wpa_passphrase,w.procps,write,www-browser,X11,x86_64,x86_64-linux-gnu-cpp,x86_64-linux-gnu-cpp-4.4,xargs,xauth,xbmtopbm,ximtoppm,xpmtoppm,xsubpp,xtotroff,xvminitoppm,xwdtopnm,xxd,ybmtopbm,yes,yuvsplittoppm,yuvtoppm,zabbix_get,zdump,zeisstopnm,zipgrep,zipinfo,zsoelim,,/usr/sbin/:,a2dismod,a2dissite,a2enmod,a2ensite,aa-audit,aa-autodep,aa-complain,aa-decode,aa-enforce,aa-genprof,aa-logprof,aa-status,aa-unconfined,ab,accessdb,addgroup,add-shell,adduser,apache2,apache2ctl,apparmor_status,arp,arpd,atd,audit,autodep,bacula-console,bacula-fd,bandwidthd,bcrelay,biosdecode,brctl,bsmtp,btraceback,chat,check_forensic,checkgid,chgpasswd,chpasswd,chroot,ck-log-system-restart,ck-log-system-start,ck-log-system-stop,complain,console-kit-daemon,cpgr,cppw,cron,cytune,dbconfig-generate-include,dbconfig-load-include,defoma-reconfigure,delgroup,deluser,dmidecode,dpkg-divert,dpkg-preconfigure,dpkg-reconfigure,dpkg-statoverride,e2freefrag,enforce,ethtool,exicyclog,exigrep,exim,exim4,exim_checkaccess,exim_convert4r4,exim_dbmbuild,exim_dumpdb,exim_fixdb,exim_lock,eximstats,exim_tidydb,exinext,exipick,exiqgrep,exiqsumm,exiwhat,fancontrol,fdformat,filefrag,genprof,gmetad,gmond,gnokiid,groupadd,groupdel,groupmod,grpck,grpconv,grpunconv,grub-install,grub-mkconfig,grub-mkdevicemap,grub-probe,grub-reboot,grub-set-default,grub-setup,gss_clnt_send_err,gss_destroy_creds,htcacheclean,httxt2dbm,iconvconfig,install-info,install-sgmlcatalog,invoke-rc.d,ip6tables-apply,ipmievd,iptables-apply,irqbalance,isadump,isaset,laptop-detect,ldattach,libgraphviz4-config-update,locale-gen,login.radius,logprof,logresolve,logrotate,lsusb,make-ssl-cert,mgnokiidev,mkinitramfs,mkinitramfs-kpkg,mklost+found,munin-node,munin-node-configure,munin-run,mysqld,mysqlmanager,nagios3,nagios3stats,newusers,nfsstat,nologin,ntop,ntpd,ntpdate,ntpdate-debian,openntpd,openvpn,openvpn-vulnkey,ownership,pam-auth-update,pam_getenv,paperconfig,popcon-largest-unused,popularity-contest,pppconfig,pppd,pppdump,pppoeconf,pppoe-discovery,pppstats,pptpctrl,pptpd,pwck,pwconv,pwmconfig,pwunconv,radacct,radexample,radlogin,radstatus,ramsize,rdev,readprofile,remove-shell,rmail,rmt,rmt-dump,rmt-tar,rootflags,rotatelogs,rpcdebug,rpc.gssd,rpc.idmapd,rsmtp,rsyslogd,rtcwake,runq,safe_finger,sendmail,sensors-detect,service,setvesablank,snmpd,snmptrapd,spine,split-logfile,sshd,syslog2eximlog,tcpd,tcpdchk,tcpdmatch,tcpdump,try-from,tunelp,tzconfig,ufw,unconfined,update-alternatives,update-bootsystem-insserv,update-ca-certificates,update-catalog,update-exim4.conf,update-exim4.conf.template,update-exim4defaults,update-fonts-alias,update-fonts-dir,update-fonts-scale,update-gdkpixbuf-loaders,update-grub,update-grub2,update-gtk-immodules,update-icon-caches,update-inetd,update-info-dir,update-initramfs,update-locale,update-mime,update-pangox-aliases,update-passwd,update-python-modules,update-rc.d,update-rc.d-insserv,update-usbids,update-xmlcatalog,upgrade-from-grub-legacy,useradd,userdel,usermod,uuidd,validlocale,vcstime,vidmode,vigr,vipw,visudo,vpddecode,vsftpd,xl2tpd,zabbix_server,zic&#10;&#9;&#9;&#9;, CentOS, Piranha, NFS, &#10;&#9;&#9;&#9;&#9;arch,awk,basename,bash,cat,cgclassify,cgcreate,cgdelete,cgexec,cgget,cgset,chgrp,chmod,chown,cp,cpio,cut,dash,date,dd,df,dmesg,dnsdomainname,domainname,dumpkeys,echo,egrep,env,ex,false,fgrep,find,gawk,grep,gtar,gunzip,gzip,hostname,ipcalc,iptables-xml,kbd_mode,kill,link,ln,loadkeys,login,ls,lscgroup,lssubsys,mkdir,mknod,mktemp,more,mount,mountpoint,mv,mybash,netstat,nice,nisdomainname,ping,ping6,plymouth,ps,pwd,raw,readlink,rm,rmdir,rpm,rvi,rview,sed,setfont,sh,shell.sh,sleep,sort,stty,su,sync,tar,taskset,touch,tracepath,tracepath6,true,umount,uname,unicode_start,unicode_stop,unlink,usleep,vi,view,ypdomainname,zcat,,/sbin/:,addpart,agetty,arp,arping,audispd,auditctl,auditd,aureport,ausearch,autrace,badblocks,blkid,blockdev,cbq,cfdisk,cgclear,cgconfigparser,cgrulesengd,chkconfig,clock,consoletype,crda,ctrlaltdel,debugfs,delpart,depmod,dracut,dumpe2fs,e2fsck,e2image,e2label,e2undo,ether-wake,ethtool,fdisk,findfs,fixfiles,fsck,fsck.cramfs,fsck.ext2,fsck.ext3,fsck.ext4,fsck.ext4dev,fsfreeze,fstab-decode,fuser,genhostid,getkey,grub,grubby,grub-install,grub-md5-crypt,grub-terminfo,halt,hwclock,ifcfg,ifconfig,ifdown,ifenslave,ifrename,ifup,init,initctl,insmod,insmod.static,install-info,installkernel,ip,ip6tables,ip6tables-multi,ip6tables-restore,ip6tables-save,ipmaddr,iptables,iptables-multi,iptables-restore,iptables-save,iptunnel,iw,iwconfig,iwevent,iwgetid,iwlist,iwpriv,iwspy,killall5,ldconfig,load_policy,logsave,losetup,lsinitrd,lsmod,lspci,MAKEDEV,matchpathcon,mii-diag,mii-tool,mingetty,mke2fs,mkfs,mkfs.cramfs,mkfs.ext2,mkfs.ext3,mkfs.ext4,mkfs.ext4dev,mkhomedir_helper,mkinitrd,mkswap,modinfo,modprobe,mount.nfs,mount.nfs4,mount.tmpfs,nameif,netreport,new-kernel-pkg,nologin,pam_console_apply,pam_tally2,pam_timestamp_check,partx,pidof,pivot_root,plipconfig,plymouthd,poweroff,ppp-watch,rdisc,reboot,regdbdump,reload,resize2fs,restart,restorecon,rmmod,route,rpcbind,rpc.statd,rsyslogd,rtmon,runlevel,runuser,scsi_id,securetty,service,setfiles,setpci,setregdomain,setsysfont,sfdisk,shutdown,slattach,sln,start,start_udev,status,stop,sulogin,sushell,swapoff,swapon,switch_root,sysctl,tc,telinit,tune2fs,udevadm,udevd,umount.nfs,umount.nfs4,unix_chkpwd,unix_update,weak-modules,wipefs&#10;&#9;&#9;&#9;, &#10;&#9;&#9;&#9;&#9;a2p,ab,aclocal,aclocal-1.11,addftinfo,addr2line,airdaemon,apropos,ar,as,attr,aulast,aulastlog,ausyscall,autoconf,autoheader,autom4te,automake,automake-1.11,autoreconf,autoscan,autoupdate,awk,base64,bashbug-64,berkeley_db_svc,bunzip2,bzcat,bzcmp,bzdiff,bzgrep,bzip2,bzip2recover,bzless,bzmore,c++,c2ph,c89,c99,cal,captoinfo,catchsegv,cc,c++filt,chacl,chage,chattr,chcon,checkmodule,checkpolicy,chfn,chrt,chsh,chvt,cjpeg,cksum,clear,cloog,cmp,col,colcrt,colrm,column,comm,consolehelper,convertcfg,cpp,crontab,csplit,curl,curl-config,cut,cxpm,db_archive,db_checkpoint,db_codegen,db_deadlock,db_dump,db_dump185,db_hotbackup,db_load,db_printlog,db_recover,db_stat,db_upgrade,dbus-binding-tool,db_verify,ddate,deallocvt,diff,diff3,dir,dircolors,dirname,djpeg,dprofpp,du,env,eqn,eqn2graph,erb,ex,expand,expr,factor,faillog,fallocate,fc-cache,fc-cat,fc-list,fc-match,fc-query,fc-scan,fgconsole,file,filedaemon,find,find2perl,fipscheck,fipshmac,flock,floppy,fmt,fold,free,freetype-config,funzip,g++,gawk,gcc,gcov,gdlib-config,gem,gencat,geqn,getconf,getent,getfacl,getfattr,getkeycodes,getopt,gindxbib,glookbib,gmake,gneqn,gnroff,gpasswd,gpg,gpg2,gpg-agent,gpgconf,gpg-connect-agent,gpg-error,gpgkey2ssh,gpgparsemail,gpgsplit,gpgv,gpgv2,gpg-zip,gpic,gprof,grefer,grn,grodvi,groff,groffer,grog,grolbp,grolj4,grops,grotty,groups,gsoelim,gtbl,gtroff,gunzip,gzexe,gzip,h2ph,halt,head,hexdump,hostid,hpftodit,htdbm,htdigest,htpasswd,i386,iconv,id,idn,ifnames,igawk,indxbib,info,infocmp,infokey,infotocap,install,ionice,ipcmk,ipcrm,ipcs,ipmicmd,ipmilan,ipmish,ipmitool,ipmi_ui,irb,isosize,join,jpegtran,kbdrate,kill,killall,last,lastb,lastlog,lchfn,lchsh,ld,ldd,less,lessecho,lesskey,lesspipe.sh,libpng12-config,libpng-config,linux32,linux64,lkbib,loadunimap,locale,localedef,logger,logname,logresolve,look,lookbib,lsattr,lscpu,lua,luac,lzcat,lzcmp,lzdiff,lzegrep,lzfgrep,lzgrep,lzless,lzma,lzmadec,lzmainfo,lzmore,m4,mailq,mailq.postfix,make,man,man2html,manpath,mapscrn,mbchk,mcookie,md5sum,mesg,mini_epn,mkfifo,nagios,nagiostats,namei,neqn,net-snmp-create-v3-user,newaliases,newaliases.postfix,newgrp,new_mini_epn,nl,nm,nohup,nproc,nroff,ntpstat,objcopy,objdump,od,oldfind,open,openipmicmd,openipmish,openssl,openvt,p1.pl,passwd,paste,pathchk,pcregrep,pcretest,peekfd,perl,perl5.10.1,perlbug,perldoc,perlthanks,pfbtops,pgawk,pgrep,phar,phar.phar,php,php-cgi,pic,pic2graph,piconv,pinentry,pinentry-curses,pinky,pkg-config,pkill,pl2pm,plymouth,pmap,pod2html,pod2latex,pod2man,pod2text,pod2usage,podchecker,podselect,post-grohtml,poweroff,ppl-config,pr,pre-grohtml,printenv,printf,protoize,psed,psfaddtable,psfgettable,psfstriptable,psfxtable,pstree,pstree.x11,pstruct,ptx,pwdx,pydoc,python,python2,python2.6,ranlib,rb,rdjpgcom,rdoc,readelf,readlink,reboot,refer,rename,renice,reset,resizecons,rev,rhgb-client,ri,rmail,rmail.postfix,rmcp_ping,rpcgen,rpm2cpio,rpmdb,rpmquery,rpmsign,rpmverify,rsync,ruby,runcon,run-parts,rvim,rx,rz,s2p,sb,scp,script,scriptreplay,sdiff,secon,sedismod,sedispol,semodule_deps,semodule_expand,semodule_link,semodule_package,seq,sequel,setarch,setfacl,setfattr,setkeycodes,setleds,setmetamode,setsid,setterm,setup-nsssysinit.sh,sftp,sg,sha1sum,sha224sum,sha256sum,sha384sum,sha512sum,showconsolefont,showkey,shred,shuf,size,skill,slabtop,slogin,snice,snmpconf,snmpkey,soelim,solterm,splain,split,sprof,sqlite3,ssh,ssh-add,ssh-agent,ssh-copy-id,ssh-keygen,ssh-keyscan,stat,stdbuf,strings,strip,sudo,sudoedit,sum,sx,sxpm,system-config-network,system-config-network-cmd,sz,tabs,tac,tail,tailf,tbl,tee,telnet,test,testrb,tfmtodit,tic,time,timeout,tload,toe,top,tput,tr,troff,truncate,tset,tsort,tty,tzselect,ul,unexpand,uniq,unlzma,unprotoize,unshare,unxz,unzip,unzipsfx,uptime,urlgrabber,users,utmpdump,uuidgen,vdir,vim,vimdiff,vimtutor,vmstat,w,wall,watch,watchgnupg,wc,wget,whatis,whereis,which,whiptail,who,whoami,write,wrjpgcom,x86_64,x86_64-redhat-linux-c++,x86_64-redhat-linux-g++,x86_64-redhat-linux-gcc,xargs,xml2-config,xmlcatalog,xmllint,xmlwf,xxd,xz,xzcat,xzcmp,xzdec,xzdiff,xzegrep,xzfgrep,xzgrep,xzless,xzmore,yaf,yafcollect,yafscii,yes,yum,zcmp,zdiff,zegrep,zfgrep,zforce,zgrep,zip,zipcloak,zipgrep,zipinfo,zipnote,zipsplit,zless,zmore,znew,zsoelim,,/usr/sbin/:,addgnupghome,adduser,alternatives,anacron,apachectl,applygnupgdefaults,arpd,arping,authconfig,authconfig-tui,avcstat,build-locale-archive,cacertdir_rehash,capsh,chpasswd,chroot,clockdiff,cracklib-check,cracklib-format,cracklib-packer,cracklib-unpacker,create-cracklib-dict,crond,e2freefrag,efibootmgr,ethtool,exportfs,fdformat,filefrag,fping,fping6,genhomedircon,getcap,getenforce,getpcaps,getsebool,glibc_post_upgrade.x86_64,groupadd,groupdel,groupmems,groupmod,grpck,grpconv,grpunconv,gss_clnt_send_err,gss_destroy_creds,htcacheclean,httpd,httpd.event,httpd.worker,httxt2dbm,hwclock,iconvconfig,iconvconfig.x86_64,ipmievd,lchage,ldattach,lgroupadd,lgroupdel,lgroupmod,libgcc_post_upgrade,lid,lnewusers,lnstat,load_policy,logrotate,lokkit,lpasswd,lsof,luseradd,luserdel,lusermod,makewhatis,matchpathcon,mkdict,mklost+found,mksock,mountstats,newusers,nfsiostat,nfsstat,nrpe,nstat,ntpd,ntpdate,ntpdc,ntp-keygen,ntpq,ntptime,open_init_pty,packer,pethtool,pifconfig,ping6,pluginviewer,plymouth-set-default-theme,postalias,postcat,postconf,postdrop,postfix,postkick,postlock,postlog,postmap,postmulti,postqueue,postsuper,pwck,pwconv,pwunconv,readprofile,restorecond,rotatelogs,rpcdebug,rpc.gssd,rpc.idmapd,rpcinfo,rpc.mountd,rpc.nfsd,rpc.svcgssd,rtacct,rtcwake,run_init,saslauthd,sasldblistusers2,saslpasswd2,selinuxconlist,selinuxdefcon,selinuxenabled,semodule,sendmail,sendmail.postfix,sestatus,setcap,setenforce,setsebool,showmount,sm-notify,smtp-sink,smtp-source,snmpd,snmptrapd,ss,sshd,start-statd,suexec,system-config-network,system-config-network-cmd,system-config-network-tui,sys-unconfig,tcpdump,tcpslice,testsaslauthd,tickadj,togglesebool,tracepath,tracepath6,tunelp,tzdata-update,update-alternatives,update-pciids,useradd,userdel,userhelper,usermod,usernetctl,vigr,vipw,visudo,zdump,zic&#10;&#9;&#9;&#9;" /><link rel="home" href="../index.html" title="Netkiller Linux ææ­" /><link rel="up" href="index.html" title="ç¬¬Â 107Â ç« Â Rancher - Multi-Cluster Kubernetes Management" /><link rel="prev" href="rancher.cli.html" title="107.4.Â Rancher CLI" /><link rel="next" href="ch107s06.html" title="107.6.Â Rancher Demo" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> | <a xmlns="" href="//netkiller.github.io/">ç®ä½ä¸­æ</a> | <a xmlns="" href="http://netkiller.sourceforge.net/">ç¹ä½ä¸­æ</a> | <a xmlns="" href="/journal/index.html">ææ</a>
		| <a xmlns="" href="https://github.com/netkiller">Github</a> | <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">ç¥ä¹ä¸æ </a> | <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> | <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> | <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> | <a xmlns="" href="//www.netkiller.cn/home/donations.html">æèµ(Donations)</a> | <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">107.5.Â K3s</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="rancher.cli.html">ä¸ä¸é¡µ</a>Â </td><th width="60%" align="center">ç¬¬Â 107Â ç« Â Rancher - Multi-Cluster Kubernetes Management</th><td width="20%" align="right">Â <a accesskey="n" href="ch107s06.html">ä¸ä¸é¡µ</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">ç¥ä¹ä¸æ </a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="k3s"></a>107.5.Â K3s</h2></div></div></div>
	
	<p>autok3s/k3s/k3d ä¸ç§å°è£ï¼å®è£æç®åçæ¯ autok3sï¼å¶æ¬¡æ¯ k3dï¼å¦æåæ¬¢è¸è¾å°±å®è£åç k3sã</p>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="AutoK3s"></a>107.5.1.Â AutoK3s</h3></div></div></div>
		
		<p>https://github.com/cnrancher/autok3s</p>
		<p>æè½½ iptables åæ ¸æ¨¡åï¼å¦å traefik slb å service èµ·ä¸æ¥</p>
		<pre class="screen">
		
modprobe ip_tables		
		
		</pre>
		<pre class="screen">
		
cat &gt; /etc/modules-load.d/k3s.conf &lt;&lt;-EOF
ip_tables
ip_conntrack
br_netfilter
EOF
		
		</pre>
		<p>è®¾ç½®ä¸»æºå</p>
		<pre class="screen">
			
hostnamectl set-hostname master
			
		</pre>
		<p>å®è£ AutoK3s</p>
		<pre class="screen">
			
docker run -itd --name=autok3s --restart=unless-stopped --net=host -v /var/run/docker.sock:/var/run/docker.sock cnrancher/autok3s:v0.5.2
			
		</pre>
		<p>å®è£ AutoK3s å½ä»¤è¡</p>
		<pre class="screen">
		
curl -sS https://rancher-mirror.oss-cn-beijing.aliyuncs.com/autok3s/install.sh  | INSTALL_AUTOK3S_MIRROR=cn sh
		
		</pre>
		<p>é¦æ¬¡è¿è¡</p>
		<pre class="screen">
			
[root@master ~]# autok3s 
? This is the very first time using autok3s,
  would you like to share metrics with us?
  You can always your mind with telemetry command Yes

               ,        , 
  ,------------|'------'|             _        _    _____ 
 / .           '-'    |-             | |      | |  |____ | 
 \\/|             |    |   __ _ _   _| |_ ___ | | __   / / ___
   |   .________.'----'   / _  | | | | __/ _ \| |/ /   \ \/ __|
   |   |        |   |    | (_| | |_| | || (_) |   &lt;.___/ /\__ \
   \\___/        \\___/   \__,_|\__,_|\__\___/|_|\_\____/ |___/

Usage:
  autok3s [flags]
  autok3s [command]

Available Commands:
  completion  Generate completion script
  create      Create a K3s cluster
  delete      Delete a K3s cluster
  describe    Show details of a specific resource
  explorer    Enable kube-explorer for K3s cluster
  help        Help about any command
  join        Join one or more K3s node(s) to an existing cluster
  kubectl     Kubectl controls the Kubernetes cluster manager
  list        Display all K3s clusters
  serve       Run as daemon and serve HTTP/HTTPS request
  ssh         Connect to a K3s node through SSH
  telemetry   Telemetry status for autok3s
  upgrade     Upgrade a K3s cluster to specified version
  version     Display autok3s version

Flags:
  -d, --debug                          Enable log debug level
  -h, --help                           help for autok3s
      --log-flush-frequency duration   Maximum number of seconds between log flushes (default 5s)

Global Environments:
  AUTOK3S_CONFIG  Path to the cfg file to use for CLI requests (default ~/.autok3s)
  AUTOK3S_RETRY   The number of retries waiting for the desired state (default 20)

Use "autok3s [command] --help" for more information about a command.
			
		</pre>
		<p>å¦æä½ æ³å¸è½½å®</p>
		<pre class="screen">
		
Creating uninstall script /usr/local/bin/autok3s-uninstall.sh
kubectl --kubeconfig /etc/rancher/k3s/k3s.yaml get pods --all-namespaces
		
		</pre>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2369"></a>107.5.1.1.Â å½ä»¤è¡åå»ºéç¾¤</h4></div></div></div>
			
			<p>åå»º k3d éç¾¤</p>
			<pre class="screen">
			
autok3s create --provider k3d --master 1 --name test --worker 1 --api-port 0.0.0.0:6443 --image rancher/k3s:v1.21.7-k3s1		
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2370"></a>107.5.1.2.Â ç§æéååº</h4></div></div></div>
			
			<p>æå®ç§æéååº</p>
			<pre class="screen">
			
autok3s create --provider  k3d --master  1 --name  test --worker  1 --api-port  0.0.0.0:6443 --image  rancher/k3s:v1.21.7-k3s1 --registry  https://registry.netkiller.cn		
			
			</pre>
			<p>https://rancher.com/docs/k3s/latest/en/installation/private-registry/</p>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2371"></a>107.5.1.3.Â æ´æ¼ 80/443</h4></div></div></div>
			
			<p>ç»å®¿ä¸»ä¸»æºæ´æ¼ ingress 80/443 ç«¯å£</p>
			<pre class="screen">
			
autok3s create --provider k3d --master 1 --name test --token 0ab46344f7f62488f771f1332feeabf6 --worker 1 --k3s-install-script https://get.k3s.io --api-port 172.18.200.5:6443 --image rancher/k3s:v1.21.7-k3s1 --ports '80:80@loadbalancer' --ports '443:443@loadbalancer'		
			
			</pre>
			<p>éªè¯éç¾¤æ¯å¦å·¥ä½æ­£å¸¸</p>
			<pre class="screen">
				
l
kubectl create service clusterip nginx --tcp=80:80

cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx
  annotations:
    ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
EOF
				
			</pre>
			<p>é»è®¤ ingress å°åæ¯ br ç½æ¡¥ç</p>
			<pre class="screen">
		
[root@master ~]# ip addr | grep  br-
4: br-2ad0dd2291af: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-2ad0dd2291af		
		
			</pre>
			<pre class="screen">
		
# Run kubectl commands inside here
# e.g. kubectl get all
&gt; kubectl get ingress 
NAME    CLASS    HOSTS   ADDRESS                 PORTS   AGE
nginx   &lt;none&gt;   *       172.19.0.2,172.19.0.3   80      4m18s		
		
			</pre>
			<p>æä»¬å·²ç»å° 80/443 æ´æ¼ç»äºå®¿ä¸»ä¸»æºï¼æä»¥å¯ä»¥ç´æ¥ç¨å®¿ä¸»ä¸»æºIPè®¿é® kubernetes éç¾¤</p>
			<pre class="screen">
		
[root@master ~]# curl http://localhost
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2372"></a>107.5.1.4.Â æ©å±æ¬å°å­å¨</h4></div></div></div>
			
			<p>æå¡å¨æ¯OSå®è£å¨ä¸å 256G ç SSD ä¸ï¼é»è®¤æ¬å°å­å¨è·¯å¾æ¯ /var/lib/rancher/k3s/storageï¼æä»¬éè¦æ©å±æ¬å°å­å¨çç©ºé´å®¹éï¼æä¸¤ä¸ªæ¹æ¡ï¼</p>
			<p>å° 1TB ç¡¬çæè½½å° /var/lib/rancher/k3s/storageï¼å¦ä¸ç§æ¹æ¡ï¼ç±äº1TBç¡¬çå·²ç»å¨ä½¿ç¨ï¼å¹¶ä¸æè½½å°äº /opt ç®å½ï¼è¿æ¶æä»¬ä½¿ç¨ --volumes '/opt/kubernetes:/var/lib/rancher/k3s/storage' å° /var/lib/rancher/k3s/storage æè½½å° /opt/kubernetes ç®å½ã</p>
			<pre class="screen">
			
autok3s create --provider k3d --master 1 --name dev --token 7fc4b9a088a3c02ed9f3285359f1d322 --worker 1 --k3s-install-script https://get.k3s.io --api-port 0.0.0.0:26080 --image rancher/k3s:v1.21.7-k3s1 --volumes '/opt/kubernetes:/var/lib/rancher/k3s/storage'			
			
			</pre>
			<p>éç½®èç¹è·¯å¾æ å°ï¼ä¿®æ¹ local-path-config</p>
			<pre class="screen">
			
config.json: |-
        {
                "nodePathMap":[
                {
                        "node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",
                        "paths":["/opt/local-path-provisioner"]
                },
                {
                        "node":"yasker-lp-dev1",
                        "paths":["/opt/local-path-provisioner", "/data1"]
                },
                {
                        "node":"yasker-lp-dev3",
                        "paths":[]
                }
                ]
        }			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2373"></a>107.5.1.5.Â Agent ä»£çå®è£</h4></div></div></div>
			
			<p></p>
			<pre class="screen">
			
hostnamectl set-hostname node1			
			
			</pre>
			<p>æ¥ç Master Token</p>
			<pre class="screen">
			
[docker@master ~]$ docker ps | egrep "k3d.*server" |grep -v lb
12b9c210b858   rancher/k3s:v1.21.7-k3s1   "/bin/k3d-entrypointâ¦"   2 days ago          Up 2 days           k3d-test-server-0

[docker@master ~]$ docker exec -it k3d-test-server-0 cat /var/lib/rancher/k3s/server/node-token
K1083de74aba3f4fe80d744ab2a506d037165f4c475d0ca3636d48a371aac6ef0ac::server:0ab46344f7f62488f771f1332feeabf6
			
			</pre>
			<p>å¨èç¹æå¡å¨å®è£ä»£ç</p>
			<pre class="screen">
			
SERVER=172.18.200.5
TOKEN=K1083de74aba3f4fe80d744ab2a506d037165f4c475d0ca3636d48a371aac6ef0ac::server:0ab46344f7f62488f771f1332feeabf6
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://${SERVER}:6443 K3S_TOKEN=${TOKEN} sh -
systemctl enable k3s-agent
			
			</pre>
			<p>å å¥éç¾¤</p>
			<pre class="screen">
			
K3S_TOKEN="K104fddbe58cad213694b0346db17ae060fc0974e7cfdbb9063aa1309363de16996::server:0ab46344f7f62488f771f1332feeabf6"
K3S_URL="https://172.18.200.5:6443"
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=${K3S_URL} K3S_TOKEN=${K3S_TOKEN} sh -s - --docker				
			
			</pre>
			<p>åå° Master æ¥çèç¹</p>
			<pre class="screen">
			
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1
node1                   Ready    &lt;none&gt;                 117s   v1.24.4+k3s1			
			
			</pre>
			<p>å¦ææ­¤åå·²ç»å®è£äº K3sï¼éè¦æå·¥å å¥ Master</p>
			<pre class="screen">
			
k3s agent --server https://10.12.1.40:6443 --token "K1083de74aba3f4fe80d744ab2a506d037165f4c475d0ca3636d48a371aac6ef0ac::server:0ab46344f7f62488f771f1332feeabf6"
			
			</pre>
			<p>ä¹å¯ä»¥ä¿®æ¹ç¯å¢åééç½®æä»¶</p>
			<pre class="screen">
			
[root@node1 ~]# cat /etc/systemd/system/k3s-agent.service.env
K3S_TOKEN="K1083de74aba3f4fe80d744ab2a506d037165f4c475d0ca3636d48a371aac6ef0ac::server:0ab46344f7f62488f771f1332feeabf6"
K3S_URL="https://172.18.200.5:6443"			
			
			</pre>
			<p></p>
			<pre class="screen">
			
&gt; kubectl describe nodes agent-1 
Name:               agent-1
Roles:              &lt;none&gt;
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/instance-type=k3s
                    beta.kubernetes.io/os=linux
                    egress.k3s.io/cluster=true
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=agent-1
                    kubernetes.io/os=linux
                    node.kubernetes.io/instance-type=k3s
Annotations:        flannel.alpha.coreos.com/backend-data: {"VNI":1,"VtepMAC":"0e:14:1e:7c:fc:e9"}
                    flannel.alpha.coreos.com/backend-type: vxlan
                    flannel.alpha.coreos.com/kube-subnet-manager: true
                    flannel.alpha.coreos.com/public-ip: 172.18.200.51
                    k3s.io/hostname: agent-1
                    k3s.io/internal-ip: 172.18.200.51
                    k3s.io/node-args: ["agent"]
                    k3s.io/node-config-hash: HJIVMRMG74UTQMXBAZD4NLDPY3FZHN7PYGB7RA7CUGXEDUTUTBTQ====
                    k3s.io/node-env:
                      {"K3S_DATA_DIR":"/var/lib/rancher/k3s/data/577968fa3d58539cc4265245941b7be688833e6bf5ad7869fa2afe02f15f1cd2","K3S_TOKEN":"********","K3S_U...
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 06 Sep 2022 17:33:21 +0000
Taints:             &lt;none&gt;
Unschedulable:      false
Lease:
  HolderIdentity:  agent-1
  AcquireTime:     &lt;unset&gt;
  RenewTime:       Wed, 07 Sep 2022 18:40:08 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 07 Sep 2022 18:35:57 +0000   Wed, 07 Sep 2022 03:48:43 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 07 Sep 2022 18:35:57 +0000   Wed, 07 Sep 2022 03:48:43 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 07 Sep 2022 18:35:57 +0000   Wed, 07 Sep 2022 03:48:43 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 07 Sep 2022 18:35:57 +0000   Wed, 07 Sep 2022 03:48:43 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  172.18.200.51
  Hostname:    agent-1
Capacity:
  cpu:                16
  ephemeral-storage:  181197372Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             65237592Ki
  pods:               110
Allocatable:
  cpu:                16
  ephemeral-storage:  176268803344
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             65237592Ki
  pods:               110
System Info:
  Machine ID:                 bfc31b708a794f8bad984bd60770ed0f
  System UUID:                1514a1f0-c451-11eb-8522-ac3ccdeb3900
  Boot ID:                    5c0c8375-220a-4abd-8a6d-7debafc6a331
  Kernel Version:             5.14.0-70.22.1.el9_0.x86_64
  OS Image:                   AlmaLinux 9.0 (Emerald Puma)
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.6.6-k3s1
  Kubelet Version:            v1.24.4+k3s1
  Kube-Proxy Version:         v1.24.4+k3s1
PodCIDR:                      10.42.2.0/24
PodCIDRs:                     10.42.2.0/24
ProviderID:                   k3s://agent-1
Non-terminated Pods:          (11 in total)
  Namespace                   Name                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE
  ---------                   ----                       ------------  ----------  ---------------  -------------  ---
  kube-system                 svclb-traefik-hhvvv        0 (0%)        0 (0%)      0 (0%)           0 (0%)         25h
  default                     nacos-0                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         14h
  default                     nacos-1                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         14h
  default                     elasticsearch-data-1       0 (0%)        0 (0%)      0 (0%)           0 (0%)         36m
  default                     nginx-565785f75c-gmblp     0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m
  default                     nginx-565785f75c-lhhcl     0 (0%)        0 (0%)      0 (0%)           0 (0%)         30m
  default                     nginx-565785f75c-rpc4k     0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m
  default                     nginx-565785f75c-fr2s7     0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m
  default                     nginx-565785f75c-5rjj9     0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m
  default                     nginx-565785f75c-2bc9p     0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m
  default                     quickstart-es-default-0    100m (0%)     100m (0%)   2Gi (3%)         2Gi (3%)       10h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests   Limits
  --------           --------   ------
  cpu                100m (0%)  100m (0%)
  memory             2Gi (3%)   2Gi (3%)
  ephemeral-storage  0 (0%)     0 (0%)
  hugepages-1Gi      0 (0%)     0 (0%)
  hugepages-2Mi      0 (0%)     0 (0%)
Events:              &lt;none&gt;			
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k3s.docker"></a>107.5.2.Â å®è£ K3sï¼Docker æ¨¡å¼ï¼</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2374"></a>107.5.2.1.Â Server</h4></div></div></div>
			
			<p>è®¾ç½®ä¸»æºå</p>
			<pre class="screen">
			
hostnamectl set-hostname master
			
			</pre>
			<p>Docker æ¹å¼å®è£</p>
			<pre class="screen">
			
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - --docker				
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2375"></a>107.5.2.2.Â Agent</h4></div></div></div>
			
			<p>è®¾ç½®ä¸»æºå</p>
			<pre class="screen">
			
hostnamectl set-hostname agent-1			
			
			</pre>
			<p>åå¾ master æ¥ç Token</p>
			<pre class="screen">
			
[root@master ~]# cat /var/lib/rancher/k3s/server/node-token
K10b614928142836a5262a802c0d3056f0047f057c895373651b723697a261b128b::server:1d436565a84f8e4bdd434b17752a2071			
			
			</pre>
			<p>å¨ Agent èç¹æå¡å¨æ§è¡ä¸é¢å½ä»¤ï¼å å¥ master éç¾¤ï¼Docker æ¹å¼ï¼</p>
			<pre class="screen">
			
K3S_TOKEN="K10b614928142836a5262a802c0d3056f0047f057c895373651b723697a261b128b::server:1d436565a84f8e4bdd434b17752a2071"
K3S_URL="https://172.18.200.5:6443"
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=${K3S_URL} K3S_TOKEN=${K3S_TOKEN} sh -s - --docker
			
			</pre>
			<p>åå¾ master æ¥çèç¹</p>
			<pre class="screen">
			
[root@master ~]# kubectl get node -o wide
NAME      STATUS     ROLES                  AGE   VERSION        INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                       KERNEL-VERSION                CONTAINER-RUNTIME
agent-1   Ready      &lt;none&gt;                 2d    v1.24.4+k3s1   172.18.200.51   &lt;none&gt;        AlmaLinux 9.0 (Emerald Puma)   5.14.0-70.22.1.el9_0.x86_64   docker://20.10.17
master    Ready      control-plane,master   2d    v1.24.4+k3s1   172.18.200.5    &lt;none&gt;        AlmaLinux 9.0 (Emerald Puma)   5.14.0-70.22.1.el9_0.x86_64   docker://20.10.17
agent-2   NotReady   &lt;none&gt;                 6s    v1.24.4+k3s1   172.18.200.52   &lt;none&gt;        AlmaLinux 9.0 (Emerald Puma)   5.14.0-70.13.1.el9_0.x86_64   docker://20.10.18			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2376"></a>107.5.2.3.Â å®è£ kube-explorer</h4></div></div></div>
			
			<p>https://github.com/cnrancher/kube-explorer</p>
			<pre class="screen">
			
docker rm -f kube-explorer
docker run -itd --name=kube-explorer --restart=unless-stopped --net=host -v /etc/rancher/k3s/k3s.yaml:/etc/rancher/k3s/k3s.yaml:ro -e KUBECONFIG=/etc/rancher/k3s/k3s.yaml cnrancher/kube-explorer:latest
			
			</pre>
			<p>https://127.0.0.1:9443/dashboard/</p>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k3s.vm"></a>107.5.3.Â å®è£ K3sï¼VM æ¨¡å¼ï¼</h3></div></div></div>
		
		<p>K3S çå®è£æ¹å¼æå¤ç§ï¼å®æ¹æä¾ç k3s-install.shï¼è¿æç¬¬ä¸æ¹ç k3d å k3sup</p>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2377"></a>107.5.3.1.Â Server æå¡å®è£</h4></div></div></div>
			
			<p>è®¾ç½®ä¸»æºå</p>
			<pre class="screen">
			
hostnamectl set-hostname master
			
			</pre>
			<p>è¿è¡å¨èææºä¹ä¸</p>
			<pre class="screen">
			
curl -sfL https://get.k3s.io | sh -			
			
			</pre>
			<p>å½åéå</p>
			<pre class="screen">
			
curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -
systemctl enable k3s
			
			</pre>
			<p>æ¥çèç¹å¯å¨ç¶æ</p>
			<pre class="screen">
			
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1
			
			</pre>
			<p>æ¥çèç¹ Pod ç¶æ</p>
			<pre class="screen">
			
kubectl --kubeconfig /etc/rancher/k3s/k3s.yaml get pods --all-namespaces
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2378"></a>107.5.3.2.Â Agent ä»£çå®è£</h4></div></div></div>
			
			<p>è®¾ç½®ä¸»æºå</p>
			<pre class="screen">
			
hostnamectl set-hostname node1			
			
			</pre>
			<p>æ¥ç Master Token</p>
			<pre class="screen">
			
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1

[root@master ~]# cat /var/lib/rancher/k3s/server/node-token
K1000ba39a142b3712d2ffb1459a63f6a7f58b082aeb53406dab15d8cee0f3c2ff0::server:5713047feb086388c19663f69cccc966
			
			</pre>
			<p>å¨èç¹æå¡å¨å®è£ä»£ç</p>
			<pre class="screen">
			
SERVER=172.18.200.5
TOKEN=K1000ba39a142b3712d2ffb1459a63f6a7f58b082aeb53406dab15d8cee0f3c2ff0::server:5713047feb086388c19663f69cccc966			
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://${SERVER}:6443 K3S_TOKEN=${TOKEN} sh -
systemctl enable k3s-agent
			
			</pre>

			<p>åå° Master æ¥çèç¹</p>
			<pre class="screen">
			
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1
node1                   Ready    &lt;none&gt;                 117s   v1.24.4+k3s1			

[root@master ~]# kubectl get nodes -o wide
NAME      STATUS   ROLES                  AGE   VERSION        INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                       KERNEL-VERSION                CONTAINER-RUNTIME
master    Ready    control-plane,master   22h   v1.24.4+k3s1   172.18.200.5    &lt;none&gt;        AlmaLinux 9.0 (Emerald Puma)   5.14.0-70.22.1.el9_0.x86_64   docker://20.10.17
agent-1   Ready    &lt;none&gt;                 22h   v1.24.4+k3s1   172.18.200.51   &lt;none&gt;        AlmaLinux 9.0 (Emerald Puma)   5.14.0-70.22.1.el9_0.x86_64   docker://20.10.17
			
			</pre>
		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k3d"></a>107.5.4.Â k3d</h3></div></div></div>
		
		<p>k3d is a lightweight wrapper to run k3s (Rancher Labâs minimal
			Kubernetes distribution) in docker.
		</p>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2379"></a>107.5.4.1.Â å®è£ k3d</h4></div></div></div>
			

			<p>Mac å®è£ k3d</p>
			<pre class="screen">
			
Neo-iMac:~ neo$ brew install k3d			
			
			</pre>
			<p>Linux å®è£ k3d</p>
			<span class="command"><strong>wget -q -O -
				https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
			</strong></span>
			<pre class="screen">
			
[root@netkiller ~]# wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
Preparing to install k3d into /usr/local/bin
k3d installed into /usr/local/bin/k3d
Run 'k3d --help' to see what you can do with it.
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2380"></a>107.5.4.2.Â åå»ºéç¾¤</h4></div></div></div>
			
			<p>åå»ºå¹¶å¯å¨éç¾¤</p>
			<pre class="screen">
			
Neo-iMac:~ neo$ k3d cluster create mycluster
INFO[0000] Prep: Network                                
INFO[0000] Created network 'k3d-mycluster'              
INFO[0000] Created volume 'k3d-mycluster-images'        
INFO[0000] Starting new tools node...                   
INFO[0001] Creating node 'k3d-mycluster-server-0'       
INFO[0006] Pulling image 'docker.io/rancher/k3d-tools:5.2.2' 
INFO[0006] Pulling image 'docker.io/rancher/k3s:v1.21.7-k3s1' 
INFO[0016] Starting Node 'k3d-mycluster-tools'          
INFO[0036] Creating LoadBalancer 'k3d-mycluster-serverlb' 
INFO[0041] Pulling image 'docker.io/rancher/k3d-proxy:5.2.2' 
INFO[0057] Using the k3d-tools node to gather environment information 
INFO[0058] Starting cluster 'mycluster'                 
INFO[0058] Starting servers...                          
INFO[0059] Starting Node 'k3d-mycluster-server-0'       
INFO[0078] All agents already running.                  
INFO[0078] Starting helpers...                          
INFO[0079] Starting Node 'k3d-mycluster-serverlb'       
INFO[0087] Injecting '192.168.65.2 host.k3d.internal' into /etc/hosts of all nodes... 
INFO[0087] Injecting records for host.k3d.internal and for 2 network members into CoreDNS configmap... 
INFO[0088] Cluster 'mycluster' created successfully!    
INFO[0088] You can now use it like this:                
kubectl cluster-info			
			
			</pre>
			<p>æ å°80ç«¯å£</p>
			<pre class="screen">
			
k3d cluster create mycluster --api-port 127.0.0.1:6445 --servers 3 --agents 2 --port '80:80@loadbalancer'
			
			</pre>
			<pre class="screen">
			
Neo-iMac:~ neo$ k3d cluster create mycluster --api-port 127.0.0.1:6445 --servers 3 --agents 2 --port '80:80@loadbalancer'
INFO[0000] portmapping '80:80' targets the loadbalancer: defaulting to [servers:*:proxy agents:*:proxy] 
INFO[0000] Prep: Network                                
INFO[0000] Created network 'k3d-mycluster'              
INFO[0000] Created volume 'k3d-mycluster-images'        
INFO[0000] Creating initializing server node            
INFO[0000] Creating node 'k3d-mycluster-server-0'       
INFO[0000] Starting new tools node...                   
INFO[0001] Starting Node 'k3d-mycluster-tools'          
INFO[0002] Creating node 'k3d-mycluster-server-1'       
INFO[0003] Creating node 'k3d-mycluster-server-2'       
INFO[0004] Creating node 'k3d-mycluster-agent-0'        
INFO[0005] Creating node 'k3d-mycluster-agent-1'        
INFO[0005] Creating LoadBalancer 'k3d-mycluster-serverlb' 
INFO[0005] Using the k3d-tools node to gather environment information 
INFO[0007] Starting cluster 'mycluster'                 
INFO[0007] Starting the initializing server...          
INFO[0007] Starting Node 'k3d-mycluster-server-0'       
INFO[0012] Starting servers...                          
INFO[0013] Starting Node 'k3d-mycluster-server-1'
INFO[0045] Starting Node 'k3d-mycluster-server-2'       
INFO[0069] Starting agents...                           
INFO[0070] Starting Node 'k3d-mycluster-agent-1'        
INFO[0070] Starting Node 'k3d-mycluster-agent-0'        
INFO[0081] Starting helpers...                          
INFO[0081] Starting Node 'k3d-mycluster-serverlb'       
INFO[0089] Injecting '192.168.65.2 host.k3d.internal' into /etc/hosts of all nodes... 
INFO[0089] Injecting records for host.k3d.internal and for 6 network members into CoreDNS configmap... 
INFO[0090] Cluster 'mycluster' created successfully!    
INFO[0091] You can now use it like this:                
kubectl cluster-info			
			
			</pre>
			<p>é¤äºä½¿ç¨å½ä»¤ï¼è¿å¯ä»¥ä½¿ç¨ yaml éç½®æä»¶åå»ºéç¾¤</p>
			<pre class="programlisting">
			
apiVersion: k3d.io/v1alpha2
kind: Simple
name: mycluster
servers: 1
agents: 2
kubeAPI:
  hostPort: "6443" # same as `--api-port '6443'`
ports:
  - port: 8080:80  # same as `--port '8080:80@loadbalancer'`
    nodeFilters:
      - loadbalancer
  - port: 8443:443 # same as `--port '8443:443@loadbalancer'`
    nodeFilters:
      - loadbalancer			
			
			</pre>
			<p></p>
			<pre class="screen">
			
$ k3d cluster create --config /path/to/mycluster.yaml			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2381"></a>107.5.4.3.Â æ¥çä¿¡æ¯</h4></div></div></div>
			
			<p></p>
			<pre class="screen">
			
Neo-iMac:~ neo$ k3d cluster list
NAME        SERVERS   AGENTS   LOADBALANCER
mycluster   3/3       2/2      true			
			
			</pre>
			<p>æ¥çéç¾¤ä¿¡æ¯</p>
			<pre class="screen">
			
Neo-iMac:~ neo$ kubectl cluster-info
Kubernetes control plane is running at https://0.0.0.0:60268
CoreDNS is running at https://0.0.0.0:60268/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://0.0.0.0:60268/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
Neo-iMac:~ neo$ 			
			
			</pre>
			<p>æ¥çèç¹</p>
			<pre class="screen">
			
Neo-iMac:~ neo$ kubectl get nodes
NAME                     STATUS   ROLES                  AGE     VERSION
k3d-mycluster-server-0   Ready    control-plane,master   2m10s   v1.21.7+k3s1			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2382"></a>107.5.4.4.Â å é¤éç¾¤</h4></div></div></div>
			
			<p>å é¤éç¾¤</p>
			<pre class="screen">
			
Neo-iMac:~ neo$ k3d cluster delete mycluster
INFO[0000] Deleting cluster 'mycluster'                 
INFO[0002] Deleting cluster network 'k3d-mycluster'     
INFO[0003] Deleting image volume 'k3d-mycluster-images' 
INFO[0003] Removing cluster details from default kubeconfig... 
INFO[0003] Removing standalone kubeconfig file (if there is one)... 
INFO[0003] Successfully deleted cluster mycluster!   			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2384"></a>107.5.4.5.Â æ¼ç¤º</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2383"></a>é¨ç½² nginx</h5></div></div></div>
				
				<pre class="screen">
				
kubectl create deployment nginx --image=nginx:alpine
kubectl create service clusterip nginx --tcp=80:80

cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx
  annotations:
    ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
EOF
				
				</pre>
				<p>æä½æ¼ç¤º</p>
				<pre class="screen">
				
Neo-iMac:~ neo$ kubectl create deployment nginx --image=nginx:alpine
deployment.apps/nginx created
Neo-iMac:~ neo$ kubectl create service clusterip nginx --tcp=80:80
service/nginx created
Neo-iMac:~ neo$ cat &lt;&lt;EOF | kubectl apply -f -
&gt; apiVersion: networking.k8s.io/v1
&gt; kind: Ingress
&gt; metadata:
&gt;   name: nginx
&gt;   annotations:
&gt;     ingress.kubernetes.io/ssl-redirect: "false"
&gt; spec:
&gt;   rules:
&gt;   - http:
&gt;       paths:
&gt;       - path: /
&gt;         pathType: Prefix
&gt;         backend:
&gt;           service:
&gt;             name: nginx
&gt;             port:
&gt;               number: 80
&gt; EOF
ingress.networking.k8s.io/nginx created				
				
				</pre>
				<p>ä½¿ç¨æµè§å¨æèCURLå½ä»¤è®¿é® http://localhost</p>
				<pre class="screen">
				
Neo-iMac:~ neo$ curl http://localhost
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;				
				
				</pre>
			</div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2386"></a>107.5.4.6.Â éç½®æä»¶</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2385"></a>å¯¼åºéç¾¤éç½®æä»¶</h5></div></div></div>
				
				<pre class="screen">
				
Netkiller-iMac:~ neo$ k3d kubeconfig write mycluster
/Users/neo/.k3d/kubeconfig-mycluster.yaml
Netkiller-iMac:~ neo$ cat /Users/neo/.k3d/kubeconfig-mycluster.yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJkakNDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdGMyVnkKZG1WeUxXTmhRREUyTkRFME16WTVNelV3SGhjTk1qSXdNVEEyTURJME1qRTFXaGNOTXpJd01UQTBNREkwTWpFMQpXakFqTVNFd0h3WURWUVFEREJock0zTXRjMlZ5ZG1WeUxXTmhRREUyTkRFME16WTVNelV3V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFUQVZKN01XdVY3dzA5dGZybUswbDAybkxOcjFiaGpXM1hIZEgrQUtCdWEKREFBZ3UrNHF4dVdyNHBkbGpraVNrL3ZZMEJjVWJMZ1RkemJnSEY4UnA1OVpvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVUZ2UXVRTVBjeStrbTFla2pqaUtUCmRoZ1c4TjB3Q2dZSUtvWkl6ajBFQXdJRFJ3QXdSQUlnVGMvZDBHWjN5aWRuZ2dXamZGWnowc0R6V3diVXkzV0IKVmZYamZ1Tis3UjRDSUJ4ZmttSUs1Z1NTL0RNUjltc0VxYUsxZVNGTEl2bHZuNXhaeE53RDJoUlgKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    server: https://127.0.0.1:6445
  name: k3d-mycluster
contexts:
- context:
    cluster: k3d-mycluster
    user: admin@k3d-mycluster
  name: k3d-mycluster
current-context: k3d-mycluster
kind: Config
preferences: {}
users:
- name: admin@k3d-mycluster
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJrVENDQVRlZ0F3SUJBZ0lJVnR3SGsxWDlUam93Q2dZSUtvWkl6ajBFQXdJd0l6RWhNQjhHQTFVRUF3d1kKYXpOekxXTnNhV1Z1ZEMxallVQXhOalF4TkRNMk9UTTFNQjRYRFRJeU1ERXdOakF5TkRJeE5Wb1hEVEl6TURFdwpOakF5TkRJMU0xb3dNREVYTUJVR0ExVUVDaE1PYzNsemRHVnRPbTFoYzNSbGNuTXhGVEFUQmdOVkJBTVRESE41CmMzUmxiVHBoWkcxcGJqQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJCcFNScmNGMW9VQUFCRW4Kb2hZM1haWmpoMUhkNks0eEtXVUpsc3A2blR0UzNFbDJJQjZrUmZIcGNwaDdjQ3NaUnFvV2RsT1MxdlFtNGM3VgplNVZ6aEY2alNEQkdNQTRHQTFVZER3RUIvd1FFQXdJRm9EQVRCZ05WSFNVRUREQUtCZ2dyQmdFRkJRY0RBakFmCkJnTlZIU01FR0RBV2dCVFhrTVpDYnJXVTNKQmxIb0t2Z0F4MDF6TUJUVEFLQmdncWhrak9QUVFEQWdOSUFEQkYKQWlFQTFIQ0M1OUlaS3FieVQ2MExSS2pvcWNWMFJiK3BWZ1FLdU1aR3YxZXFvOGdDSUZFMjB6OTg1ZStnR3dGYQppK3FkenFYQTVKU2FrV05naVE0TUZLcExpVDI3Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlRENDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdFkyeHAKWlc1MExXTmhRREUyTkRFME16WTVNelV3SGhjTk1qSXdNVEEyTURJME1qRTFXaGNOTXpJd01UQTBNREkwTWpFMQpXakFqTVNFd0h3WURWUVFEREJock0zTXRZMnhwWlc1MExXTmhRREUyTkRFME16WTVNelV3V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFTd0c2dk9tay8vL01jNlUwU3BLZm9ERFM1NDNkQnZSdzVZUnNlZmpmWm0KT01BQUNRbkViYS9QY0FGc2ZIUlBWWU9HczRnWTQ3TVlDbzF3L2swV3had3lvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVTE1REdRbTYxbE55UVpSNkNyNEFNCmROY3pBVTB3Q2dZSUtvWkl6ajBFQXdJRFNRQXdSZ0loQUtQcjE3T0lDNk94a1hBYnpxUGl2R0QwZkptVjFmTnIKVFNzc2IvMktWMjh4QWlFQTFEUVlHU2F0V3R6Y2tFdk1JNnYzeTcyQ2hwdDZWMHZUdWNEWWJsOWxRVFU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    client-key-data: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUxjTWt1aW9mTHo1Z1lUZGVrWmlsOEhTZVMzSXVONHVHUGU2VXFxRWJkN0dvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFR2xKR3R3WFdoUUFBRVNlaUZqZGRsbU9IVWQzb3JqRXBaUW1XeW5xZE8xTGNTWFlnSHFSRgo4ZWx5bUh0d0t4bEdxaFoyVTVMVzlDYmh6dFY3bFhPRVhnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=				
				
				</pre>
			</div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2387"></a>107.5.4.7.Â éåç®¡ç</h4></div></div></div>
			
			<p>å¯¼å¥æ¬å°éå</p>
			<pre class="screen">
			
Netkiller-iMac:~ neo$ docker image ls | grep netkiller
netkiller                                                     openjdk8       52e22fa28d43   3 weeks ago    552MB			
			
			</pre>
			<p>å°æ¬å° netkiller:openjdk8 éåå¯¼å¥å° mycluster ä¸­</p>
			<pre class="screen">
			
Netkiller-iMac:~ neo$ k3d image import netkiller:openjdk8 -c mycluster
INFO[0000] Importing image(s) into cluster 'mycluster'  
INFO[0000] Loading 1 image(s) from runtime into nodes... 
INFO[0051] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-0'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-2'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-agent-1'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-1'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-agent-0'... 
INFO[0355] Successfully imported image(s)               
INFO[0355] Successfully imported 1 image(s) into 1 cluster(s) 			
			
			</pre>
		</div>


		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2391"></a>107.5.4.8.Â ç®¡ç k3d éç¾¤</h4></div></div></div>
			
			<pre class="screen">
		
[root@netkiller k3d]# k3d cluster start mycluster		
		
			</pre>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2388"></a>éç½® api-port ç«¯å£</h5></div></div></div>
				
				<pre class="screen">
			
k3d cluster create netkiller --api-port 6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer'
			
				</pre>
				<p></p>
				<pre class="screen">
			
[root@netkiller ~]# cat .kube/config | grep server
    server: https://0.0.0.0:6445
    
[root@netkiller ~]# ss -lnt | grep 6445
LISTEN 0      1024         0.0.0.0:6445       0.0.0.0:*  			
			
				</pre>
				<p></p>
				<pre class="screen">
			
[root@netkiller ~]# firewall-cmd --add-service=http --permanent
success
[root@netkiller ~]# firewall-cmd --add-service=https --permanent
success
[root@netkiller ~]# firewall-cmd --zone=public --add-service=kube-api --permanent  
success			
			
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2389"></a></h5></div></div></div>
				
				<p></p>
				<pre class="screen">
			
k3d cluster create netkiller --api-port 172.16.0.1:6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer' --k3s-arg "--no-deploy=traefik@server:*"
			
				</pre>
				export http_proxy="socks://127.0.0.1:1080"
				export
				https_proxy="socks://127.0.0.1:1080"
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2390"></a>kubectl ç®¡çæå®éç¾¤</h5></div></div></div>
				
				<pre class="screen">
			
export KUBECONFIG="$(k3d kubeconfig write netkiller)"			
			
				</pre>
				<p></p>
				<pre class="screen">
			
[root@netkiller ~]# kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://172.18.200.10:6445
  name: k3d-netkiller
contexts:
- context:
    cluster: k3d-netkiller
    user: admin@k3d-netkiller
  name: k3d-netkiller
current-context: k3d-netkiller
kind: Config
preferences: {}
users:
- name: admin@k3d-netkiller
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED			
			
				</pre>
			</div>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2392"></a>107.5.4.9.Â å®¹å¨éååº</h4></div></div></div>
			
			<pre class="screen">
		
neo@Netkiller-iMac ~&gt; vim ~/.k3d/registries.yaml
mirrors:
  "registry.netkiller.cn":
    endpoint:
      - http://registry.netkiller.cn
		
			</pre>
			<p></p>
			<pre class="screen">
		
neo@Netkiller-iMac ~&gt; k3d cluster create mycluster --api-port 6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer' --registry-config ~/.k3d/registries.yaml		
		
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="traefik"></a>107.5.4.10.Â traefik éç½®</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2393"></a>å¢å  Redis 6379 ç«¯å£</h5></div></div></div>
				

				<pre class="screen">
		
neo@Netkiller-iMac ~&gt; kubectl edit -n kube-system deployment traefik
deployment.apps/traefik edited		
		
				</pre>
				<p></p>
				<pre class="screen">
		
    spec:
      containers:
      - args:
        - --global.checknewversion
        - --global.sendanonymoususage
        - --entrypoints.traefik.address=:9000/tcp
        - --entrypoints.web.address=:8000/tcp
        - --entrypoints.websecure.address=:8443/tcp
        - --entrypoints.redis.address=:6379/tcp
        - --entrypoints.mysql.address=:3306/tcp
        - --entrypoints.mongo.address=:27017/tcp
        - --api.dashboard=true
        - --ping=true
        - --providers.kubernetescrd
        - --providers.kubernetesingress
        - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
        - --entrypoints.websecure.http.tls=true
        image: rancher/library-traefik:2.4.8
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        name: traefik
        ports:
        - containerPort: 9000
          name: traefik
          protocol: TCP
        - containerPort: 8000
          name: web
          protocol: TCP
        - containerPort: 8443
          name: websecure
          protocol: TCP
        - containerPort: 6379
          name: redis
          protocol: TCP
        - containerPort: 3306
          name: mysql
          protocol: TCP
        - containerPort: 27017
          name: mongo
          protocol: TCP		
		
				</pre>
				<p>args å¤å å¥</p>
				<pre class="screen">
		
- --entrypoints.redis.address=:6379/tcp		
		
				</pre>
				<p>ports å¤å å¥</p>
				<pre class="screen">
		
		- containerPort: 6379
          name: redis
          protocol: TCP
		
				</pre>
				<p></p>
				<pre class="screen">
			
[root@netkiller k3d]# k3d cluster edit mycluster --port-add '6379:6379@loadbalancer'			      
			
				</pre>
				<pre class="programlisting">
			
[root@netkiller k3d]# cat redis.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:latest
        ports:
        - containerPort: 6379
          protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
--- 
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRouteTCP
metadata:
  name: redis
spec:
  entryPoints:
    - redis
  routes:
  - match: HostSNI(`*`)
    services:
    - name: redis
      port: 6379			
			
				</pre>
				<pre class="screen">
			
[root@netkiller k3d]# kubectl apply -f redis.yaml
deployment.apps/redis created
service/redis created
ingressroutetcp.traefik.containo.us/redis created

[root@netkiller k3d]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
redis-5c9986b94b-gsctv   1/1     Running   0          6m49s
[root@netkiller k3d]# kubectl exec redis-5c9986b94b-gsctv -it  -- redis-cli
127.0.0.1:6379&gt; set nickname netkiller
OK
127.0.0.1:6379&gt; get nickname
"netkiller"
127.0.0.1:6379&gt;		
127.0.0.1:6379&gt; exit
			
				</pre>
				<p></p>
				<pre class="screen">
			
[root@netkiller k3d]# dnf install redis
[root@netkiller k3d]# redis-cli -h 127.0.0.1
127.0.0.1:6379&gt; get nickname
			
				</pre>
			</div>

		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="k3d.ingress-nginx"></a>107.5.4.11.Â ingress-nginx</h4></div></div></div>
			
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2394"></a>å¸è½½ traefik</h5></div></div></div>
				
				<p>æä»¬å¸æä½¿ç¨ nginx ingressï¼æä»¥éè¦è®² traefik å¸è½½</p>
				<pre class="screen">
			
kubectl -n kube-system delete helmcharts.helm.cattle.io traefik
helm uninstall traefik-crd --namespace kube-system			
			
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2395"></a>å®è£ ingress-nginx</h5></div></div></div>
				
				<p>ingress-nginx:
					https://kubernetes.github.io/ingress-nginx/deploy/
				</p>
				<pre class="screen">
			
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.7.0/deploy/static/provider/cloud/deploy.yaml
			
				</pre>
				<p>ä¿®æ¹éååºå°åï¼å¦åæ æ³ä¸è½½</p>
				<pre class="screen">
			
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml
vim deploy.yaml
:%s:registry.k8s.io/ingress-nginx/:registry.cn-hangzhou.aliyuncs.com/google_containers/:g  			
:%s:registry.cn-hangzhou.aliyuncs.com/google_containers/controller:registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:g

kubectl apply -f deploy.yaml  
			
				</pre>
				<p>svclb-ingress-nginx-controller å¯å¨ä¸èµ·æ¥</p>
				<pre class="screen">
			
neo@MacBook-Pro-Neo-3 ~ [1]&gt; kubectl logs -n kube-system svclb-ingress-nginx-controller-8b62cc7d-qbqtv
Defaulted container "lb-tcp-80" out of: lb-tcp-80, lb-tcp-443
+ trap exit TERM INT
+ echo 10.43.36.160
+ grep -Eq :
+ cat /proc/sys/net/ipv4/ip_forward
+ '[' 1 '!=' 1 ]
+ iptables -t nat -I PREROUTING '!' -s 10.43.36.160/32 -p TCP --dport 80 -j DNAT --to 10.43.36.160:80
iptables v1.8.4 (legacy): can't initialize iptables table `nat': Table does not exist (do you need to insmod?)
Perhaps iptables or your kernel needs to be upgraded.			
			
				</pre>
				<p>è§£å³æ¹æ³</p>
				<pre class="screen">
			
root@netkiller ~ # modprobe ip_tables

root@netkiller ~# lsmod|grep iptable
iptable_nat            16384  2
ip_tables              28672  1 iptable_nat
nf_nat                 53248  4 xt_nat,nft_chain_nat,iptable_nat,xt_MASQUERADE

root@netkiller ~# kubectl get pods --all-namespaces
NAMESPACE       NAME                                            READY   STATUS      RESTARTS         AGE
ingress-nginx   ingress-nginx-admission-create-nqv2f            0/1     Completed   0                6m9s
ingress-nginx   ingress-nginx-admission-patch-m9hcf             0/1     Completed   1                6m9s
kube-system     metrics-server-7cd5fcb6b7-8wrqx                 1/1     Running     3 (6m30s ago)    82m
ingress-nginx   ingress-nginx-controller-75d55647d-nstch        1/1     Running     0                6m9s
kube-system     coredns-d76bd69b-rgvwj                          1/1     Running     3 (6m21s ago)    82m
kube-system     local-path-provisioner-6c79684f77-psmgs         1/1     Running     3 (6m21s ago)    82m
kube-system     svclb-ingress-nginx-controller-8b62cc7d-5lb8d   2/2     Running     12 (3m17s ago)   6m9s
kube-system     svclb-ingress-nginx-controller-8b62cc7d-qbqtv   2/2     Running     12 (3m20s ago)   6m9s
			
				</pre>
			</div>
			<div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id2396"></a>éªè¯å®è£æ¯å¦æ­£ç¡®</h5></div></div></div>
				
				<p>é¨ç½² Nginx Web æå¡å¨ï¼ç¨æ¥æ£æ¥ ingress</p>
				<pre class="screen">
			
Neo-iMac:~ neo$ kubectl create deployment nginx --image=nginx:alpine
deployment.apps/nginx created

Neo-iMac:~ neo$ kubectl create service clusterip nginx --tcp=80:80
service/nginx created			
			
				</pre>
				<p></p>
				<pre class="screen">
			
cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx
  annotations:
    kubernetes.io/ingress.class: nginx
    ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
EOF			
			
				</pre>
			</div>

		</div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k3s.tls"></a>107.5.5.Â TLS è¯ä¹¦</h3></div></div></div>
		
		<pre class="screen">
		
[root@master ~]# ll /var/lib/rancher/k3s/server/tls
total 116
-rw-r--r-- 1 root root 1173 2022-09-08 13:48 client-admin.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-admin.key
-rw-r--r-- 1 root root 1178 2022-09-08 13:48 client-auth-proxy.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-auth-proxy.key
-rw-r--r-- 1 root root  570 2022-09-08 13:48 client-ca.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-ca.key
-rw-r--r-- 1 root root 1165 2022-09-08 13:48 client-controller.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-controller.key
-rw-r--r-- 1 root root 1161 2022-09-08 13:48 client-k3s-cloud-controller.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-k3s-cloud-controller.key
-rw-r--r-- 1 root root 1153 2022-09-08 13:48 client-k3s-controller.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-k3s-controller.key
-rw-r--r-- 1 root root 1181 2022-09-08 13:48 client-kube-apiserver.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-kube-apiserver.key
-rw-r--r-- 1 root root 1149 2022-09-08 13:48 client-kube-proxy.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-kube-proxy.key
-rw------- 1 root root  227 2022-09-08 13:48 client-kubelet.key
-rw-r--r-- 1 root root 1153 2022-09-08 13:48 client-scheduler.crt
-rw------- 1 root root  227 2022-09-08 13:48 client-scheduler.key
-rw-r--r-- 1 root root 3789 2022-09-08 13:48 dynamic-cert.json
drwxr-xr-x 2 root root 4096 2022-09-08 13:48 etcd
-rw-r--r-- 1 root root  591 2022-09-08 13:48 request-header-ca.crt
-rw------- 1 root root  227 2022-09-08 13:48 request-header-ca.key
-rw-r--r-- 1 root root  570 2022-09-08 13:48 server-ca.crt
-rw------- 1 root root  227 2022-09-08 13:48 server-ca.key
-rw------- 1 root root 1675 2022-09-08 13:48 service.key
-rw-r--r-- 1 root root 1368 2022-09-08 13:48 serving-kube-apiserver.crt
-rw------- 1 root root  227 2022-09-08 13:48 serving-kube-apiserver.key
-rw------- 1 root root  227 2022-09-08 13:48 serving-kubelet.key
drwx------ 2 root root   84 2022-09-08 13:48 temporary-certs		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id2397"></a>107.5.6.Â åå»º Token</h3></div></div></div>
		
		<pre class="screen">
		
[root@master ~]#kubectl create serviceaccount secrets
serviceaccount/gitlab created

[root@master ~]# kubectl create token secrets
eyJhbGciOiJSUzI1NiIsImtpZCI6IktCOHRvYlZOLXFPRmEyb1JWdlQxSzBvN0tvZF9HNFBGRnlraDR5UU1jakkifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiLCJrM3MiXSwiZXhwIjoxNjY2MTcyOTc4LCJpYXQiOjE2NjYxNjkzNzgsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJkZWZhdWx0Iiwic2VydmljZWFjY291bnQiOnsibmFtZSI6ImdpdGxhYiIsInVpZCI6IjAzNTdkOWIwLWY2YWEtNGFlMy05MDc0LWM2YzM5Y2Q1YTdiNiJ9fSwibmJmIjoxNjY2MTY5Mzc4LCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6ZGVmYXVsdDpnaXRsYWIifQ.oDWjQmVH7BOqHUp4AgjxNncfJ0Nz9oY_jS9DU5E-geKmX5GnchC96-t0ZsdtgPiWXFbieb0aUH1wZXCrkFAuGeM-XNDEvfhbK4UL9GiDl98KaYMjTSwXipp4bIZeSctL-Zpc0nSKwaWdWNwxmmlC30HwMwjQPdwBgCDM8SEr9aepUuJD9rHdclKWv8NcXlLq4t5c9sV3qEQRKbGOTnSeY3RokoAY-tYD7FT3jzFktbkTk4SHZAKYUeILlc2eaE0cOm9N4yhl8IYZvEcrBGZV_-Nl0XzGu5XpDrVVXlk2k2RdYQHj3Iw5l4sSFfnRVg1Q-1B45y7FJDEbXa-tCXeRKA

[root@master ~]# token=eyJhbGciOiJSUzI1NiIsImtpZCI6IktCOHRvYlZOLXFPRmEyb1JWdlQxSzBvN0tvZF9HNFBGRnlraDR5UU1jakkifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiLCJrM3MiXSwiZXhwIjoxNjY2MTcyOTc4LCJpYXQiOjE2NjYxNjkzNzgsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJkZWZhdWx0Iiwic2VydmljZWFjY291bnQiOnsibmFtZSI6ImdpdGxhYiIsInVpZCI6IjAzNTdkOWIwLWY2YWEtNGFlMy05MDc0LWM2YzM5Y2Q1YTdiNiJ9fSwibmJmIjoxNjY2MTY5Mzc4LCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6ZGVmYXVsdDpnaXRsYWIifQ.oDWjQmVH7BOqHUp4AgjxNncfJ0Nz9oY_jS9DU5E-geKmX5GnchC96-t0ZsdtgPiWXFbieb0aUH1wZXCrkFAuGeM-XNDEvfhbK4UL9GiDl98KaYMjTSwXipp4bIZeSctL-Zpc0nSKwaWdWNwxmmlC30HwMwjQPdwBgCDM8SEr9aepUuJD9rHdclKWv8NcXlLq4t5c9sV3qEQRKbGOTnSeY3RokoAY-tYD7FT3jzFktbkTk4SHZAKYUeILlc2eaE0cOm9N4yhl8IYZvEcrBGZV_-Nl0XzGu5XpDrVVXlk2k2RdYQHj3Iw5l4sSFfnRVg1Q-1B45y7FJDEbXa-tCXeRKA
[root@master ~]# curl -k https://127.0.0.1:6443/api --header "Authorization: bearer $token"
{
  "kind": "APIVersions",
  "versions": [
    "v1"
  ],
  "serverAddressByClientCIDRs": [
    {
      "clientCIDR": "0.0.0.0/0",
      "serverAddress": "172.18.200.5:6443"
    }
  ]
}		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k3s.faq"></a>107.5.7.Â FAQ</h3></div></div></div>
		
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2398"></a>107.5.7.1.Â ghcr.io éåä¸è½½é®é¢</h4></div></div></div>
			
			<p>åå»ºéç¾¤å§ç»åæ­¢å¨è¿éï¼è¿æ¯å ä¸º ghcr.io è¢«å¢ï¼æ æ³è®¿é®ã</p>
			<pre class="screen">
			
INFO[0004] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.4.4' 			
			
			</pre>
			<p>æ¾ä¸å°å¢å¤VPSå®è£K3Då¹¶åå»ºéç¾¤ï¼ç¶åè®² k3d-proxy éåä¿å­ä¸ºæä»¶ã</p>
			<pre class="screen">
			
[docker@netkiller ~]$ docker images
REPOSITORY                 TAG            IMAGE ID       CREATED        SIZE
ghcr.io/k3d-io/k3d-proxy   5.4.4          5a963719cb39   2 weeks ago    42.4MB
ghcr.io/k3d-io/k3d-tools   5.4.4          741f01cb5093   2 weeks ago    18.7MB
			
[docker@netkiller ~]$ docker save 5a963719cb39 -o k3d-proxy.tar			
			
			</pre>
			<p>å¤å¶å°å½åï¼å¯¼å¥éå</p>
			<pre class="screen">
			
docker load --input k3d-proxy.tar			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2399"></a>107.5.7.2.Â k3s 80/443 ç«¯å£é®é¢</h4></div></div></div>
			
			<pre class="screen">
			
[root@master ~]# kubectl get svc --namespace=kube_system
NAME             TYPE           CLUSTER-IP     EXTERNAL-IP                  PORT(S)                      AGE
kube-dns         ClusterIP      10.43.0.10     &lt;none&gt;                       53/UDP,53/TCP,9153/TCP       4d2h
metrics-server   ClusterIP      10.43.88.112   &lt;none&gt;                       443/TCP                      4d2h
traefik          LoadBalancer   10.43.125.52   172.18.200.5,172.18.200.51   80:32623/TCP,443:31516/TCP   4d2h			
			
			</pre>
			<p>æ¬å°æ²¡æ 80 å 443 ç«¯å£</p>
			<pre class="screen">
			
[root@master ~]# ss -tnlp | egrep "80|443"
LISTEN 0      1024               *:6443             *:*    users:(("k3s-server",pid=173779,fd=17)) 		

[root@master ~]# lsof -i :80
[root@master ~]# lsof -i :443	
			
			</pre>
			<p>telnet æµè¯åå¯å·¥ä½</p>
			<pre class="screen">
			
[root@master ~]# telnet 172.18.200.5 80
Trying 172.18.200.5...
Connected to 172.18.200.5.
Escape character is '^]'.			
			
			</pre>
			<p>80/443 æ¯ Iptable NATæ å°åºæ¥çç«¯å£</p>
			<pre class="screen">
			
[root@master ~]# iptables -nL -t nat | grep traefik
# Warning: iptables-legacy tables present, use iptables-legacy to see them
KUBE-MARK-MASQ  all  --  0.0.0.0/0            0.0.0.0/0            /* masquerade traffic for kube-system/traefik:websecure external destinations */
KUBE-MARK-MASQ  all  --  0.0.0.0/0            0.0.0.0/0            /* masquerade traffic for kube-system/traefik:web external destinations */
KUBE-EXT-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:websecure */ tcp dpt:31516
KUBE-EXT-UQMCRMJZLI3FTLDP  tcp  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:web */ tcp dpt:32623
KUBE-MARK-MASQ  all  --  10.42.2.3            0.0.0.0/0            /* kube-system/traefik:web */
DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:web */ tcp to:10.42.2.3:8000
KUBE-MARK-MASQ  all  --  10.42.2.3            0.0.0.0/0            /* kube-system/traefik:websecure */
DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:websecure */ tcp to:10.42.2.3:8443
KUBE-SVC-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            10.43.125.52         /* kube-system/traefik:websecure cluster IP */ tcp dpt:443
KUBE-EXT-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            172.18.200.5         /* kube-system/traefik:websecure loadbalancer IP */ tcp dpt:443
KUBE-EXT-CVG3OEGEH7H5P3HQ  tcp  --  0.0.0.0/0            172.18.200.51        /* kube-system/traefik:websecure loadbalancer IP */ tcp dpt:443
KUBE-SVC-UQMCRMJZLI3FTLDP  tcp  --  0.0.0.0/0            10.43.125.52         /* kube-system/traefik:web cluster IP */ tcp dpt:80
KUBE-EXT-UQMCRMJZLI3FTLDP  tcp  --  0.0.0.0/0            172.18.200.5         /* kube-system/traefik:web loadbalancer IP */ tcp dpt:80
KUBE-EXT-UQMCRMJZLI3FTLDP  tcp  --  0.0.0.0/0            172.18.200.51        /* kube-system/traefik:web loadbalancer IP */ tcp dpt:80
KUBE-MARK-MASQ  tcp  -- !10.42.0.0/16         10.43.125.52         /* kube-system/traefik:websecure cluster IP */ tcp dpt:443
KUBE-SEP-NTYW4CRSJDKN6UYK  all  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:websecure -&gt; 10.42.2.3:8443 */
KUBE-MARK-MASQ  tcp  -- !10.42.0.0/16         10.43.125.52         /* kube-system/traefik:web cluster IP */ tcp dpt:80
KUBE-SEP-M4A3OJBNTWBZ5ISS  all  --  0.0.0.0/0            0.0.0.0/0            /* kube-system/traefik:web -&gt; 10.42.2.3:8000 */			
			
			</pre>
			<p>NAT ç«¯å£å¯ä»¥éè¿ nmap æ«æåºæ¥</p>
			<pre class="screen">
			
[root@master ~]# nmap localhost
Starting Nmap 7.91 ( https://nmap.org ) at 2022-09-01 10:04 CST
Nmap scan report for localhost (127.0.0.1)
Host is up (0.0000050s latency).
Other addresses for localhost (not scanned): ::1
Not shown: 996 closed ports
PORT      STATE    SERVICE
22/tcp    open     ssh
80/tcp    filtered http
443/tcp   filtered https
10010/tcp open     rxapi

Nmap done: 1 IP address (1 host up) scanned in 1.26 seconds			
			
			</pre>
			<p></p>
			<pre class="screen">
			
[root@master ~]# iptables-save | grep "CNI-DN" | grep "to-destination"
# Warning: iptables-legacy tables present, use iptables-legacy-save to see them
-A CNI-DN-485265bef43fea7142e9d -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.42.0.10:80
-A CNI-DN-485265bef43fea7142e9d -p tcp -m tcp --dport 443 -j DNAT --to-destination 10.42.0.10:443			
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2400"></a>107.5.7.3.Â flannel ä¸é</h4></div></div></div>
			
			<pre class="screen">
			
[root@netkiller ~]# systemctl disable firewalld
Removed /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.

[root@master ~]# ifconfig
br-6ac52d42db64: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 172.20.0.1  netmask 255.255.0.0  broadcast 172.20.255.255
        inet6 fe80::42:94ff:fefd:1fc3  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 02:42:94:fd:1f:c3  txqueuelen 0  (Ethernet)
        RX packets 782783  bytes 200925233 (191.6 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 625170  bytes 194933933 (185.9 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

cni0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450
        inet 10.42.0.1  netmask 255.255.255.0  broadcast 10.42.0.255
        inet6 fe80::6448:6dff:fe75:5e8d  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 66:48:6d:75:5e:8d  txqueuelen 1000  (Ethernet)
        RX packets 2049669  bytes 371281787 (354.0 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 2235678  bytes 334579428 (319.0 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

docker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500
        inet 172.16.0.1  netmask 255.255.255.0  broadcast 172.16.0.255
        inet6 fe80::42:4cff:fe70:883  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 02:42:4c:70:08:83  txqueuelen 0  (Ethernet)
        RX packets 14  bytes 616 (616.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 8  bytes 788 (788.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

enp3s0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 172.18.200.5  netmask 255.255.255.0  broadcast 172.18.200.255
        inet6 fe80::2ef0:5dff:fec7:387  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 2c:f0:5d:c7:03:87  txqueuelen 1000  (Ethernet)
        RX packets 782783  bytes 200925233 (191.6 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 625171  bytes 194934547 (185.9 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450
        inet 10.42.0.0  netmask 255.255.255.255  broadcast 0.0.0.0
        inet6 fe80::c051:5cff:fe09:4e18  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether c2:51:5c:09:4e:18  txqueuelen 0  (Ethernet)
        RX packets 180007  bytes 21310049 (20.3 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 222507  bytes 39026179 (37.2 MiB)
        TX errors 0  dropped 5 overruns 0  carrier 0  collisions 0


[root@master ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         172.18.200.254  0.0.0.0         UG    100    0        0 enp3s0
10.42.0.0       0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.42.1.0       10.42.1.0       255.255.255.0   UG    0      0        0 flannel.1
172.16.0.0      0.0.0.0         255.255.255.0   U     0      0        0 docker0
172.18.200.0    0.0.0.0         255.255.255.0   U     100    0        0 enp3s0
172.20.0.0      0.0.0.0         255.255.0.0     U     0      0        0 br-6ac52d42db64

[root@master ~]# cat /proc/sys/net/ipv4/ip_forward
1
[root@master ~]# sysctl net.ipv4.ip_forward
net.ipv4.ip_forward = 1

[root@master ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS        AGE   IP           NODE      NOMINATED NODE   READINESS GATES
nacos-1                  1/1     Running   5 (12h ago)     35h   10.42.0.50   master    &lt;none&gt;           &lt;none&gt;
elasticsearch-data-1     1/1     Running   5 (12h ago)     35h   10.42.0.44   master    &lt;none&gt;           &lt;none&gt;
nacos-2                  1/1     Running   7 (6m39s ago)   35h   10.42.1.49   agent-1   &lt;none&gt;           &lt;none&gt;
nacos-0                  1/1     Running   7 (6m32s ago)   35h   10.42.1.50   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-master-0   1/1     Running   6 (6m32s ago)   35h   10.42.1.47   agent-1   &lt;none&gt;           &lt;none&gt;
busybox                  0/1     Error     0               11h   10.42.1.46   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-data-2     1/1     Running   6 (6m32s ago)   35h   10.42.1.48   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-data-0     1/1     Running   6 (6m32s ago)   35h   10.42.1.51   agent-1   &lt;none&gt;           &lt;none&gt;
[root@master ~]# ping 10.42.0.50
PING 10.42.0.50 (10.42.0.50) 56(84) bytes of data.
64 bytes from 10.42.0.50: icmp_seq=1 ttl=64 time=0.039 ms
64 bytes from 10.42.0.50: icmp_seq=2 ttl=64 time=0.031 ms
64 bytes from 10.42.0.50: icmp_seq=3 ttl=64 time=0.042 ms
64 bytes from 10.42.0.50: icmp_seq=4 ttl=64 time=0.038 ms
^C
--- 10.42.0.50 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3054ms
rtt min/avg/max/mdev = 0.031/0.037/0.042/0.004 ms

[root@master ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS      AGE   IP           NODE      NOMINATED NODE   READINESS GATES
nacos-1                  1/1     Running   5 (12h ago)   35h   10.42.0.50   master    &lt;none&gt;           &lt;none&gt;
elasticsearch-data-1     1/1     Running   5 (12h ago)   35h   10.42.0.44   master    &lt;none&gt;           &lt;none&gt;
nacos-2                  1/1     Running   7 (29m ago)   35h   10.42.1.49   agent-1   &lt;none&gt;           &lt;none&gt;
nacos-0                  1/1     Running   7 (29m ago)   35h   10.42.1.50   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-master-0   1/1     Running   6 (29m ago)   35h   10.42.1.47   agent-1   &lt;none&gt;           &lt;none&gt;
busybox                  0/1     Error     0             11h   10.42.1.46   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-data-2     1/1     Running   6 (29m ago)   35h   10.42.1.48   agent-1   &lt;none&gt;           &lt;none&gt;
elasticsearch-data-0     1/1     Running   6 (29m ago)   35h   10.42.1.51   agent-1   &lt;none&gt;           &lt;none&gt;
[root@master ~]# ping 10.42.1.51 -c 5
PING 10.42.1.51 (10.42.1.51) 56(84) bytes of data.
64 bytes from 10.42.1.51: icmp_seq=1 ttl=63 time=0.402 ms
64 bytes from 10.42.1.51: icmp_seq=2 ttl=63 time=0.171 ms
64 bytes from 10.42.1.51: icmp_seq=3 ttl=63 time=0.170 ms
64 bytes from 10.42.1.51: icmp_seq=4 ttl=63 time=0.410 ms
64 bytes from 10.42.1.51: icmp_seq=5 ttl=63 time=0.414 ms

--- 10.42.1.51 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4105ms
rtt min/avg/max/mdev = 0.170/0.313/0.414/0.116 ms

[root@agent-1 ~]# ping 10.42.0.50 -c 5
PING 10.42.0.50 (10.42.0.50) 56(84) bytes of data.
64 bytes from 10.42.0.50: icmp_seq=1 ttl=63 time=0.154 ms
64 bytes from 10.42.0.50: icmp_seq=2 ttl=63 time=0.206 ms
64 bytes from 10.42.0.50: icmp_seq=3 ttl=63 time=0.213 ms
64 bytes from 10.42.0.50: icmp_seq=4 ttl=63 time=0.218 ms
64 bytes from 10.42.0.50: icmp_seq=5 ttl=63 time=0.220 ms

--- 10.42.0.50 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4125ms
rtt min/avg/max/mdev = 0.154/0.202/0.220/0.024 ms

[root@master ~]# kubectl exec -it nacos-1 -- ping nacos-0.nacos.default.svc.cluster.local -c 5
PING nacos-0.nacos.default.svc.cluster.local (10.42.1.50) 56(84) bytes of data.
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=1 ttl=62 time=0.440 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=2 ttl=62 time=0.429 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=3 ttl=62 time=0.431 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=4 ttl=62 time=0.343 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=5 ttl=62 time=0.229 ms

--- nacos-0.nacos.default.svc.cluster.local ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4127ms
rtt min/avg/max/mdev = 0.229/0.374/0.440/0.082 ms
[root@master ~]# kubectl exec -it nacos-2 -- ping nacos-0.nacos.default.svc.cluster.local -c 5
PING nacos-0.nacos.default.svc.cluster.local (10.42.1.50) 56(84) bytes of data.
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=1 ttl=64 time=0.053 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=2 ttl=64 time=0.039 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=3 ttl=64 time=0.038 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=4 ttl=64 time=0.077 ms
64 bytes from nacos-0.nacos.default.svc.cluster.local (10.42.1.50): icmp_seq=5 ttl=64 time=0.039 ms

--- nacos-0.nacos.default.svc.cluster.local ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4113ms
rtt min/avg/max/mdev = 0.038/0.049/0.077/0.015 ms

[root@master ~]# kubectl delete pod busybox 
[root@master ~]# kubectl run -i --tty busybox --image=busybox --restart=Never
If you don't see a command prompt, try pressing enter.
/ # ping nacos-0.nacos.default.svc.cluster.local -c 3
PING nacos-0.nacos.default.svc.cluster.local (10.42.1.50): 56 data bytes
64 bytes from 10.42.1.50: seq=0 ttl=64 time=0.052 ms
64 bytes from 10.42.1.50: seq=1 ttl=64 time=0.049 ms
64 bytes from 10.42.1.50: seq=2 ttl=64 time=0.047 ms

--- nacos-0.nacos.default.svc.cluster.local ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.047/0.049/0.052 ms
/ # 

			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id2401"></a>107.5.7.4.Â Failed to allocate directory watch: Too many open files</h4></div></div></div>
			
			<pre class="screen">
			
[root@netkiller ~]# ulimit -a
real-time non-blocking time  (microseconds, -R) unlimited
core file size              (blocks, -c) 0
data seg size               (kbytes, -d) unlimited
scheduling priority                 (-e) 0
file size                   (blocks, -f) unlimited
pending signals                     (-i) 254690
max locked memory           (kbytes, -l) 64
max memory size             (kbytes, -m) unlimited
open files                          (-n) 6553500
pipe size                (512 bytes, -p) 8
POSIX message queues         (bytes, -q) 819200
real-time priority                  (-r) 0
stack size                  (kbytes, -s) 8192
cpu time                   (seconds, -t) unlimited
max user processes                  (-u) 254690
virtual memory              (kbytes, -v) unlimited
file locks                          (-x) unlimited			
			
			</pre>
			<pre class="screen">
	
[root@netkiller ~]# sysctl fs.inotify.max_user_instances fs.inotify.max_user_watches
fs.inotify.max_user_instances = 128
fs.inotify.max_user_watches = 508881

[root@netkiller ~]# sysctl -w fs.inotify.max_user_watches=5088800
fs.inotify.max_user_watches = 5088800

[root@netkiller ~]# sysctl -w fs.inotify.max_user_instances=4096
fs.inotify.max_user_instances = 4096
	
			</pre>
		</div>
	</div>
</div><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="rancher.cli.html">ä¸ä¸é¡µ</a>Â </td><td width="20%" align="center"><a accesskey="u" href="index.html">ä¸ä¸çº§</a></td><td width="40%" align="right">Â <a accesskey="n" href="ch107s06.html">ä¸ä¸é¡µ</a></td></tr><tr><td width="40%" align="left" valign="top">107.4.Â Rancher CLIÂ </td><td width="20%" align="center"><a accesskey="h" href="../index.html">èµ·å§é¡µ</a></td><td width="40%" align="right" valign="top">Â 107.6.Â Rancher Demo</td></tr></table></div><script xmlns="">
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-11694057-1', 'auto');
			ga('send', 'pageview');

		</script><script xmlns="" async="async">
			var _hmt = _hmt || [];
			(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
			})();
</script><script xmlns="" async="async">
			(function(){
			var bp = document.createElement('script');
			var curProtocol = window.location.protocol.split(':')[0];
			if (curProtocol === 'https') {
			bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
			}
			else {
			bp.src = 'http://push.zhanzhang.baidu.com/push.js';
			}
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(bp, s);
			})();
</script></body></html>