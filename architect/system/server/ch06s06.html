<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>6.6. 瓶颈分析</title><link rel="stylesheet" type="text/css" href="../../docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><link rel="home" href="../../index.html" title="Netkiller Architect 手札" /><link rel="up" href="index.html" title="第 6 章 Server" /><link rel="prev" href="oscm.html" title="6.5. 环境安装模板化" /><link rel="next" href="ntp.html" title="6.7. 时间同步" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> |
		<a xmlns="" href="//netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="/journal/index.html">杂文</a> |
	    <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> |
   	    <a xmlns="" href="https://edu.51cto.com/lecturer/1703915.html">51CTO学院</a> |
	    <a xmlns="" href="https://edu.csdn.net/lecturer/6423">CSDN程序员研修院</a> |
	    <a xmlns="" href="https://github.com/netkiller">Github</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://cloud.tencent.com/developer/column/2078">腾讯云社区</a> |
	    <a xmlns="" href="https://yq.aliyun.com/u/netkiller/">阿里云栖社区</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="https://www.youtube.com/user/bg7nyt/videos">Youtube</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/about.html">About</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">6.6. 瓶颈分析</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="oscm.html">上一页</a> </td><th width="60%" align="center">第 6 章 Server</th><td width="20%" align="right"> <a accesskey="n" href="ntp.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td><td></td><td><a href="https://zhuanlan.zhihu.com/netkiller"><img src="/images/logo/zhihu-card-default.svg" height="25" /></a></td><td valign="middle"><a href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> ｜ <a href="https://www.zhihu.com/club/1241768772601950208">多维度架构</a></td><td></td><td></td><td></td><td></td></tr></table><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="idm306398740976"></a>6.6. 瓶颈分析</h2></div></div></div>
	
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="server.tpc"></a>6.6.1. TPC</h3></div></div></div>
		
		<p>
			<a class="ulink" href="http://www.tpc.org/" target="_top">http://www.tpc.org/</a>
		</p>
		<div class="orderedlist"><p class="title"><strong> Transaction Processing Performance Council</strong></p><ol class="orderedlist" type="1"><li class="listitem">
				<p>TPC-C：是在线事务处理(OLTP)的基准程序</p>
			</li><li class="listitem">
				<p>TPC-D：是决策支持(Decision Support) 的基准程序</p>
			</li><li class="listitem">
				<p>TPC-E：作为大型企业(Enterprise)信息服务的基准程序</p>
			</li><li class="listitem">
				<p>TPC-H：DecisionSupportforAdHocQueries基于特定查询的决策支持</p>
			</li><li class="listitem">
				<p>TPC-W：Webe-Commerce（互联网及电子商务）</p>
			</li><li class="listitem">
				<p>TPC-R：DecisionSupportforBusinessReporting（基于商业报告的决策支持）</p>
			</li></ol></div>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="server.iops"></a>6.6.2. IOPS (Input/Output Operations Per Second, pronounced i-ops)</h3></div></div></div>
		
		<p>
			<a class="ulink" href="http://www.storageperformance.org/home/" target="_top">http://www.storageperformance.org/home/</a>
		</p>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="server.rperf"></a>6.6.3. rPerf</h3></div></div></div>
		
		<p>http://www-03.ibm.com/systems/power/hardware/notices/rperf.html</p>
		<pre class="screen">
		

服务器所需要的rPerf值=SUM(NU * TX * CS/PP) / MC

NU:高峰时并发的用户数

TX:高峰时每个用户的交易数量

CS:在rPerf=1的服务器上，每个交易所需要的CPU秒

PP:高峰持续的时间

MC:最大的CPU利用率（推荐&lt; 70%）

下面举例说明如何计算所需的rPerf值，假定某公司的情况如下：

业务高峰时间：  10:00-11:00=1Hour=3600秒

交易类型：      无复杂查询的简单应用

相对交易类型，用户数目分布:轻的=2000,   一般=50,   重的=5

在高峰时，每个用户的交易数量：

   轻的=120交易/用户

   一般=60交易/用户

   重的=15交易/用户

对于rPerf=1的服务器，每个交易响应的CPU秒

   轻的=1

   一般=3

   重的=15

最大的CPU利用率：60%

根据上述公式，可推算出不同交易类型所对应的rPerf值。

轻的交易：NU*TX*CS/PP=2000*120*1/3600=66.0

一般交易：NU*TX*CS/PP=50*60*3/3600=2.5

重的交易：NU*TX*CS/PP=5*15*15/3600=0.3

所需的总的rPerf/MC=(66.0+2.5+0.3)/0.7=98.3 rPerf
		
		</pre>
	</div>

	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm306399295104"></a>6.6.4. Springboot</h3></div></div></div>
		
		<pre class="screen">
		
/ # cat /proc/1/status | grep Threads
Threads:        61		
		
		</pre>
		<p>另一中方式，记得数值要 -1 因为ls -l 第一行是 total 0 统计文件数量。</p>
		<pre class="screen">
		
/ # ls -l /proc/1/task/ | wc -l
61		
		
		</pre>

	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm306399292848"></a>6.6.5. Redis 连接池不生效</h3></div></div></div>
		
		<p>压力测试中，系统出现瓶颈，流量始终无法达到数据库。</p>
		<p>开发小伙伴这样配置 Redis 由于太久脱离一线，我也不清楚配置是否正确，只能验证一下。</p>
		<pre class="screen">
		
spring.redis.host=172.18.200.5
spring.redis.port=6379
spring.redis.password=passw0rd
spring.redis.database=0

spring.redis.pool.max-active=1000
spring.redis.pool.max-idle=10
spring.redis.pool.max-wait=-1
spring.redis.pool.min-idle=5
spring.redis.pool.timeout=1000		
		
		</pre>
		<p>查看客户端连接数是 2</p>
		<pre class="screen">
		
127.0.0.1:6379&gt; info Clients
# Clients
connected_clients:2
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:8
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0		
		
		</pre>
		<p>创建一个空的 Springboot 项目，写一个最简单的接口，接口中做 set/get 操作。</p>
		<pre class="screen">
		
	@Autowired
	private RedisTemplate&lt;String, String&gt; redisTemplate;

	@GetMapping("/redis")
	public String redis() {
		redisTemplate.opsForValue().set("name","neo",10, TimeUnit.SECONDS);
		String name = (String) redisTemplate.opsForValue().get("name");
		return name;
	}		
		
		</pre>
		<p>使用 ab 命令压测一下</p>
		<pre class="screen">
		
ab -c 100 -n 10000 http://localhost:8080/redis
		
		</pre>
		<p>观看连接池的状态</p>
		<pre class="screen">
		
127.0.0.1:6379&gt; info Clients
# Clients
connected_clients:2
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:8
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0			
		
		</pre>
		<p>connected_clients:2 数值没有变化，我的猜测果然是对的，这种配置我记得是 Spring 1.5 之前的。</p>
		<p>网上说 Springboot 默认使用 lettuce</p>
		<pre class="screen">
		
spring.redis.host=172.18.200.5
spring.redis.port=6379
spring.redis.password=passw0rd
spring.redis.database=0
		
spring.redis.lettuce.pool.enabled=true
spring.redis.lettuce.pool.max-active=1000
spring.redis.lettuce.pool.max-idle=80
spring.redis.lettuce.pool.min-idle=20
spring.redis.lettuce.pool.max-wait=-1ms
spring.redis.lettuce.shutdown-timeout=100ms
spring.cache.redis.cache-null-values=false	
		
		</pre>
		<p>配置后使用 ab 压测，connected_clients:2 没有任何变化。</p>
		<pre class="screen">
		
127.0.0.1:6379&gt; info Clients
# Clients
connected_clients:2
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:8
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0			
		
		</pre>
		<p>开启 Springboot 调试模式 debug=true，启动需要引入 commons-pool2</p>
		<pre class="screen">
		
		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
		&lt;/dependency&gt;	
		
		</pre>
		<p>启动提示</p>
		<pre class="screen">
		
Caused by: java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig		
		
		</pre>
		<p>引入 commons-pool2 后启动成功</p>
		<pre class="screen">
		
		&lt;dependency&gt;
			&lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
			&lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;
		&lt;/dependency&gt;			
		
		</pre>
		<p>虽然启动成功，但是 ab 压测仍然 connected_clients:2 </p>
		<pre class="screen">
		
127.0.0.1:6379&gt; info Clients
# Clients
connected_clients:2
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:20480
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0		
		
		</pre>
		<p>只能在debug信息中找线索，发现 JedisConnectionConfiguration</p>
		<pre class="screen">
		
   JedisConnectionConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.apache.commons.pool2.impl.GenericObjectPool', 'redis.clients.jedis.Jedis' (OnClassCondition)
		
		</pre>
		<p>改为 jedis 试试，pom.xml</p>
		<pre class="screen">
		
		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
			&lt;exclusions&gt;
				&lt;exclusion&gt;
					&lt;groupId&gt;io.lettuce&lt;/groupId&gt;
					&lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
				&lt;/exclusion&gt;
			&lt;/exclusions&gt;
		&lt;/dependency&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;redis.clients&lt;/groupId&gt;
			&lt;artifactId&gt;jedis&lt;/artifactId&gt;
		&lt;/dependency&gt;	
		
		</pre>
		<p>配置文件做响应调整</p>
		<pre class="screen">
		
spring.redis.jedis.pool.max-active=1000
spring.redis.jedis.pool.max-idle=80
spring.redis.jedis.pool.min-idle=20
spring.redis.jedis.pool.max-wait=-1
		
		</pre>
		<p>使用 ab 压测一轮，终于 connected_clients:190 上去了。</p>
		<pre class="screen">
		
127.0.0.1:6379&gt; info Clients
# Clients
connected_clients:190
cluster_connections:0
maxclients:10000
client_recent_max_input_buffer:20480
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0	
		
		</pre>
		<p>lettuce 连接池，始终还没有解决，目前先用 jedis，其实连接池是同质化产品，虽有性能差异，但差距非常小，对于项目整体而言可以说微乎其微。就如同 Tomcat 跟 Undertow 差距，有时我们需要整理考虑架构方案，并不是所有好工具组合后就一定是好产品。</p>

	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm306399273248"></a>6.6.6. 数据库链接池</h3></div></div></div>
		
		<p>很多时候人们从网上找到 springboot 文章，文章中说这样配置连接池，于是就复制站台到自己的配置文件中，也没有去深究，最终流到生产环境。</p>
		<pre class="screen">
		
spring.datasource.max-idle=10
spring.datasource.max-wait=10000
spring.datasource.min-idle=5
spring.datasource.initial-size=5
spring.datasource.validation-query=SELECT 1
spring.datasource.test-on-borrow=false
spring.datasource.test-while-idle=true
spring.datasource.time-between-eviction-runs-millis=18800
spring.datasource.jdbc-interceptors=ConnectionState;SlowQueryReport(threshold=0)		
		
		</pre>
		<p>上面的配置已经作废，目前 Springboot 默认使用 hikari 链接池，他的正确配置如下</p>
		<pre class="screen">
		
spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.maximum-pool-size=200
spring.datasource.hikari.auto-commit=true
spring.datasource.hikari.idle-timeout=30000
spring.datasource.hikari.pool-name=Hikari
spring.datasource.hikari.max-lifetime=55000
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.connection-test-query=SELECT 1
		
		</pre>
		<p>测试方法，写一个测试接口，里面运行一条 SQL 即可</p>
		<pre class="screen">
		
	@Autowired
	private JdbcTemplate jdbcTemplate;

	@GetMapping("/jdbc")
	public String jdbc() {
		String query = "SELECT * from test where id = 10";
		return jdbcTemplate.queryForObject(query, (resultSet, i) -&gt; {
			System.out.println(resultSet.getString(1) + "," + resultSet.getString(2) + "," + resultSet.getString(3));
			return ("OK");
		});
	}		
		
		</pre>
		<p>然后压测这个接口，观察 show full processlist; 正常会不停的变化，如果没有任何变化，例如只启动了 8 个链接，就说明链接池配置没有生效。</p>
		<pre class="screen">
		
mysql&gt; show status like 'Threads%';
+-------------------+-------+
| Variable_name     | Value |
+-------------------+-------+
| Threads_cached    | 8     |
| Threads_connected | 40    |
| Threads_created   | 111   |
| Threads_running   | 1     |
+-------------------+-------+
4 rows in set (0.00 sec)

mysql&gt; show full processlist;
+--------+------+-------------------+------+---------+------+----------+-----------------------+
| Id     | User | Host              | db   | Command | Time | State    | Info                  |
+--------+------+-------------------+------+---------+------+----------+-----------------------+
| 507077 | root | 172.20.0.1:50129  | NULL | Query   |    0 | starting | show full processlist |
| 507638 | root | 172.18.5.89:49605 | test | Sleep   |    0 |          | NULL                  |
| 507639 | root | 172.18.5.89:49707 | test | Sleep   |    0 |          | NULL                  |
| 507640 | root | 172.18.5.89:49734 | test | Sleep   |    0 |          | NULL                  |
| 507641 | root | 172.18.5.89:49744 | test | Sleep   |    0 |          | NULL                  |
| 507642 | root | 172.18.5.89:49766 | test | Sleep   |    0 |          | NULL                  |
| 507643 | root | 172.18.5.89:49817 | test | Sleep   |    0 |          | NULL                  |
| 507644 | root | 172.18.5.89:49900 | test | Sleep   |    0 |          | NULL                  |
| 507645 | root | 172.18.5.89:49994 | test | Sleep   |    0 |          | NULL                  |
| 507647 | root | 172.18.5.89:50153 | test | Sleep   |    0 |          | NULL                  |
| 507648 | root | 172.18.5.89:50355 | test | Sleep   |    0 |          | NULL                  |
| 507649 | root | 172.18.5.89:50507 | test | Sleep   |    0 |          | NULL                  |
| 507650 | root | 172.18.5.89:50627 | test | Sleep   |    0 |          | NULL                  |
| 507651 | root | 172.18.5.89:50796 | test | Sleep   |    0 |          | NULL                  |
| 507652 | root | 172.18.5.89:51105 | test | Sleep   |    0 |          | NULL                  |
| 507653 | root | 172.18.5.89:51373 | test | Sleep   |    0 |          | NULL                  |
| 507654 | root | 172.18.5.89:51598 | test | Sleep   |    0 |          | NULL                  |
| 507655 | root | 172.18.5.89:52063 | test | Sleep   |    0 |          | NULL                  |
| 507656 | root | 172.18.5.89:52605 | test | Sleep   |    0 |          | NULL                  |
| 507657 | root | 172.18.5.89:53186 | test | Sleep   |    0 |          | NULL                  |
| 507658 | root | 172.18.5.89:53621 | test | Sleep   |    0 |          | NULL                  |
| 507659 | root | 172.18.5.89:53955 | test | Sleep   |    0 |          | NULL                  |
| 507660 | root | 172.18.5.89:54126 | test | Sleep   |    0 |          | NULL                  |
| 507661 | root | 172.18.5.89:54946 | test | Sleep   |    0 |          | NULL                  |
| 507662 | root | 172.18.5.89:55164 | test | Sleep   |    0 |          | NULL                  |
| 507663 | root | 172.18.5.89:55517 | test | Sleep   |    0 |          | NULL                  |
| 507666 | root | 172.18.5.89:56070 | test | Sleep   |    0 |          | NULL                  |
| 507667 | root | 172.18.5.89:56431 | test | Sleep   |    0 |          | NULL                  |
| 507668 | root | 172.18.5.89:56828 | test | Sleep   |    0 |          | NULL                  |
| 507669 | root | 172.18.5.89:57421 | test | Sleep   |    0 |          | NULL                  |
| 507670 | root | 172.18.5.89:57801 | test | Sleep   |    0 |          | NULL                  |
| 507671 | root | 172.18.5.89:58105 | test | Sleep   |    0 |          | NULL                  |
| 507672 | root | 172.18.5.89:58541 | test | Sleep   |    0 |          | NULL                  |
| 507675 | root | 172.18.5.89:59031 | test | Sleep   |    0 |          | NULL                  |
| 507676 | root | 172.18.5.89:59504 | test | Sleep   |    0 |          | NULL                  |
+--------+------+-------------------+------+---------+------+----------+-----------------------+
35 rows in set (0.00 sec)
		
		</pre>
		<p></p>
		<pre class="screen">
		
		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm306399272992"></a>6.6.7. 回访管理</h3></div></div></div>
		
		<pre class="screen">
		
		
		
		</pre>
	</div>
	<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idm306399266000"></a>6.6.8. 站内消息</h3></div></div></div>
		
		<pre class="screen">
		
		
		
		</pre>
	</div>
</div><div xmlns="" id="SOHUCS"></div><script xmlns="" charset="utf-8" type="text/javascript" src="https://cy-cdn.kuaizhan.com/upload/changyan.js"></script><script xmlns="" type="text/javascript">
window.changyan.api.config({
appid: 'cyvwjQUG3',
conf: 'prod_ef966242df3d8b5acb1e0ee9fc01cafe'
});
</script><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="oscm.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="index.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ntp.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">6.5. 环境安装模板化 </td><td width="20%" align="center"><a accesskey="h" href="../../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 6.7. 时间同步</td></tr></table></div><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11694057-1', 'auto');
  ga('send', 'pageview');

</script><script xmlns="" async="async">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script xmlns="" async="async">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script></body></html>